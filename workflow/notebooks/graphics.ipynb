{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c38cfb6",
   "metadata": {},
   "source": [
    "### PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770acfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import logging\n",
    "import pypsa\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import LineString\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from cartopy import crs as ccrs\n",
    "from pypsa.plot import add_legend_circles, add_legend_lines, add_legend_patches\n",
    "import os\n",
    "import xarray as xr\n",
    "import cartopy\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import sys\n",
    "import matplotlib.lines as mlines\n",
    "from matplotlib.patches import Wedge\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import matplotlib.dates as mdates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da76caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger(\"pypsa.io\").setLevel(logging.ERROR)\n",
    "warnings.simplefilter(action='ignore', category=ResourceWarning)\n",
    "\n",
    "# Load the UHS and woUHS networks\n",
    "# uhs = pypsa.Network(\"../../../pypsa-earth/results/UHSwoexport/postnetworks/elec_s_24_ec_lcopt_Co2L0.15_3H_2050_0.094_NZ_0export.nc\")\n",
    "# woUHS = pypsa.Network(\"../../../pypsa-earth/results/woUHSwoexport/postnetworks/elec_s_24_ec_lcopt_Co2L0.15_3H_2050_0.094_NZ_0export.nc\")\n",
    "uhs = pypsa.Network(\"../../../pypsa-earth/results/UHS/postnetworks/elec_s_24_ec_lcopt_Co2L0.15_3H_2050_0.094_NZ_199.8export.nc\")\n",
    "woUHS = pypsa.Network(\"../../../pypsa-earth/results/woUHS/postnetworks/elec_s_24_ec_lcopt_Co2L0.15_3H_2050_0.094_NZ_199.8export.nc\")\n",
    "\n",
    "# Load geographic data for onshore regions and ports\n",
    "regions_onshore = gpd.read_file(\"../../../pypsa-earth/resources/shapes/country_shapes.geojson\")\n",
    "ports = pd.read_csv(\"../../../pypsa-earth/resources/UHS/ports.csv\")\n",
    "\n",
    "# Create a GeoDataFrame for ports with point geometries\n",
    "ports = gpd.GeoDataFrame(\n",
    "    ports,\n",
    "    geometry=gpd.points_from_xy(ports[\"x\"], ports[\"y\"]),\n",
    "    crs=\"EPSG:4326\"  # Coordinates are in WGS84\n",
    ")\n",
    "\n",
    "# Load GADM shapes and configuration file\n",
    "gadm_shapes = gpd.read_file(\"../../../pypsa-earth/resources/shapes/gadm_shapes.geojson\")\n",
    "config = yaml.safe_load(open(\"../../../pypsa-earth/config.yaml\"))\n",
    "\n",
    "# Define paths for network and renewable profiles\n",
    "network_path = \"../../../pypsa-earth/networks/UHS/elec.nc\"\n",
    "solar_path = \"../../../pypsa-earth/resources/UHS/renewable_profiles/profile_solar.nc\"\n",
    "onwind_path = \"../../../pypsa-earth/resources/UHS/renewable_profiles/profile_onwind.nc\"\n",
    "\n",
    "# Get the bounding box for the onshore regions\n",
    "country_coordinates = regions_onshore.total_bounds[[0, 2, 1, 3]]\n",
    "\n",
    "# Define colors for scenarios\n",
    "SCENARIO_COLORS = {\"UHS\": \"#1f77b4\", \"woUHS\": \"#ff7f0e\"}\n",
    "tech_colors = config[\"plotting\"][\"tech_colors\"]\n",
    "\n",
    "# Normalize the carrier column/index to lowercase for easier matching\n",
    "def get_color(carrier):\n",
    "    # First, check for an exact match\n",
    "    if carrier in tech_colors:\n",
    "        return tech_colors[carrier]\n",
    "    # Try matching with lowercase\n",
    "    if carrier.lower() in tech_colors:\n",
    "        return tech_colors[carrier.lower()]\n",
    "    # Default color if no match is found\n",
    "    return \"lightgrey\"\n",
    "\n",
    "# Map colors to carriers in the UHS network\n",
    "uhs.carriers[\"color\"] = uhs.carriers.index.map(get_color)\n",
    "woUHS.carriers[\"color\"] = woUHS.carriers.index.map(get_color)\n",
    "\n",
    "warnings.simplefilter(action='default', category=ResourceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d531f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uhs1 = pypsa.Network(\"results/UHS1/postnetworks/elec_s_1_ec_lcopt_Co2L0.15-3h_3h_2050_0.094_NZ_199.8export.nc\")\n",
    "# woUHS1 = pypsa.Network(\"results/woUHS1/postnetworks/elec_s_1_ec_lcopt_Co2L0.15_3H_2050_0.094_NZ_199.8export.nc\")\n",
    "# uhs10 = pypsa.Network(\"results/UHS10/postnetworks/elec_s_10_ec_lcopt_Co2L0.15-3h_3h_2050_0.094_NZ_199.8export.nc\")\n",
    "# woUHS10 = pypsa.Network(\"results/woUHS10/postnetworks/elec_s_10_ec_lcopt_Co2L0.15_3H_2050_0.094_NZ_199.8export.nc\")\n",
    "# uhs100 = pypsa.Network(\"results/UHS100/postnetworks/elec_s_100_ec_lcopt_Co2L0.15-3h_3h_2050_0.094_NZ_199.8export.nc\")\n",
    "# woUHS100 = pypsa.Network(\"results/woUHS100/postnetworks/elec_s_100_ec_lcopt_Co2L0.15_3H_2050_0.094_NZ_199.8export.nc\")\n",
    "# uhswotm = pypsa.Network(\"results/UHSwotm/postnetworks/elec_s_24_ec_lcopt_Co2L0.15-3h_3h_2050_0.094_NZ_199.8export.nc\")\n",
    "# woUHSwotm = pypsa.Network(\"results/woUHSwotm/postnetworks/elec_s_24_ec_lcopt_Co2L0.15_3H_2050_0.094_NZ_199.8export.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff904e55",
   "metadata": {},
   "source": [
    "#### Show initial energy system design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87825fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "# -----------------------------\n",
    "# Carrier mapping (IMPORTANT)\n",
    "# -----------------------------\n",
    "CARRIER_AGG_MAP = {\n",
    "    \"CCGT\": \"gas\",   # Combined-Cycle Gas -> gas\n",
    "}\n",
    "\n",
    "def map_carrier(c):\n",
    "    return CARRIER_AGG_MAP.get(c, c)\n",
    "\n",
    "# -----------------------------\n",
    "# Ensure all carriers have color and nice_name\n",
    "# -----------------------------\n",
    "missing_carriers = [\n",
    "    'lignite', 'coal', 'solar rooftop', 'oil', 'gas',\n",
    "    'residential rural solar thermal',\n",
    "    'residential urban decentral solar thermal',\n",
    "    'services rural solar thermal',\n",
    "    'services urban decentral solar thermal',\n",
    "    'urban central solar thermal',\n",
    "    'CCGT'\n",
    "]\n",
    "\n",
    "carrier_color_mapping = {\n",
    "    'lignite': 'coal',\n",
    "    'solar rooftop': 'solar',\n",
    "    'residential rural solar thermal': 'solar',\n",
    "    'residential urban decentral solar thermal': 'solar',\n",
    "    'services rural solar thermal': 'solar',\n",
    "    'services urban decentral solar thermal': 'solar',\n",
    "    'urban central solar thermal': 'solar',\n",
    "    'CCGT': 'gas'\n",
    "}\n",
    "\n",
    "\n",
    "def apply_carrier_styling(n, missing_carriers, carrier_color_mapping):\n",
    "    # create rows if missing\n",
    "    for c in missing_carriers:\n",
    "        if c not in n.carriers.index:\n",
    "            n.carriers.loc[c, :] = np.nan\n",
    "\n",
    "    # colors\n",
    "    for c, ref in carrier_color_mapping.items():\n",
    "        if ref in n.carriers.index and pd.notna(n.carriers.loc[ref, \"color\"]):\n",
    "            n.carriers.loc[c, \"color\"] = n.carriers.loc[ref, \"color\"]\n",
    "        else:\n",
    "            n.carriers.loc[c, \"color\"] = \"gray\"\n",
    "\n",
    "    # nice_names\n",
    "    if \"coal\" in n.carriers.index:\n",
    "        n.carriers.loc[\"coal\", \"nice_name\"] = \"Coal\"\n",
    "    if \"oil\" in n.carriers.index:\n",
    "        n.carriers.loc[\"oil\", \"nice_name\"] = \"Oil\"\n",
    "    if \"gas\" in n.carriers.index:\n",
    "        n.carriers.loc[\"gas\", \"nice_name\"] = \"Gas\"\n",
    "    if \"CCGT\" in n.carriers.index:\n",
    "        # still exists as a carrier, but will be aggregated to 'gas'\n",
    "        n.carriers.loc[\"CCGT\", \"nice_name\"] = \"Gas\"\n",
    "\n",
    "    for c, ref in carrier_color_mapping.items():\n",
    "        if c != \"CCGT\" and ref in n.carriers.index:\n",
    "            n.carriers.loc[c, \"nice_name\"] = n.carriers.loc[ref, \"nice_name\"]\n",
    "\n",
    "    # fallbacks\n",
    "    n.carriers[\"color\"] = n.carriers[\"color\"].replace(\"\", np.nan).fillna(\"gray\")\n",
    "    n.carriers[\"nice_name\"] = (\n",
    "        n.carriers[\"nice_name\"]\n",
    "        .replace(\"\", np.nan)\n",
    "        .fillna(pd.Series(n.carriers.index, index=n.carriers.index))\n",
    "    )\n",
    "\n",
    "    # remove load shedding\n",
    "    for cand in [\"load shedding\", \"Load shedding\"]:\n",
    "        if cand in n.carriers.index:\n",
    "            n.carriers.drop(cand, inplace=True)\n",
    "\n",
    "# Apply to both\n",
    "apply_carrier_styling(uhs, missing_carriers, carrier_color_mapping)\n",
    "apply_carrier_styling(woUHS, missing_carriers, carrier_color_mapping)\n",
    "\n",
    "# -----------------------------\n",
    "# Scale settings\n",
    "# -----------------------------\n",
    "bus_scale = 6e3\n",
    "line_scale = 6e3\n",
    "bus_sizes = [100, 1000]   # MW\n",
    "line_sizes = [100, 1000]  # MW\n",
    "\n",
    "# -----------------------------\n",
    "# Aggregate generator and storage capacities by bus and *aggregated* carrier\n",
    "# -----------------------------\n",
    "gen = uhs.generators[uhs.generators.carrier != \"load shedding\"].copy()\n",
    "gen[\"carrier_agg\"] = gen[\"carrier\"].map(map_carrier)\n",
    "gen = gen.groupby([\"bus\", \"carrier_agg\"]).p_nom.sum()\n",
    "\n",
    "sto = uhs.storage_units.copy()\n",
    "sto[\"carrier_agg\"] = sto[\"carrier\"].map(map_carrier)\n",
    "sto = sto.groupby([\"bus\", \"carrier_agg\"]).p_nom.sum()\n",
    "\n",
    "buses = pd.concat([gen, sto])\n",
    "\n",
    "# -----------------------------\n",
    "# Plotting\n",
    "# -----------------------------\n",
    "fig, ax = plt.subplots(figsize=(12, 8), subplot_kw={\"projection\": ccrs.PlateCarree()})\n",
    "\n",
    "# Filter Links: only those that lie within GADM regions\n",
    "link_bus0_base = uhs.links.bus0.str.split(\"_AC\").str[0]\n",
    "link_bus1_base = uhs.links.bus1.str.split(\"_AC\").str[0]\n",
    "\n",
    "valid_links = uhs.links[\n",
    "    link_bus0_base.isin(gadm_shapes.index) &\n",
    "    link_bus1_base.isin(gadm_shapes.index) &\n",
    "    (uhs.links.p_nom > 0)\n",
    "]\n",
    "\n",
    "links_backup = uhs.links\n",
    "uhs.links = valid_links\n",
    "\n",
    "with plt.rc_context({\"patch.linewidth\": 0.}):\n",
    "    uhs.plot(\n",
    "        bus_sizes=buses / bus_scale,\n",
    "        bus_alpha=0.7,\n",
    "        line_widths=uhs.lines.s_nom / line_scale,\n",
    "        link_widths=uhs.links.p_nom / line_scale,\n",
    "        line_colors=\"teal\",\n",
    "        ax=ax,\n",
    "        margin=0.2,\n",
    "        color_geomap=None,\n",
    "    )\n",
    "\n",
    "regions_onshore.plot(\n",
    "    ax=ax,\n",
    "    facecolor=\"whitesmoke\",\n",
    "    edgecolor=\"white\",\n",
    "    aspect=\"equal\",\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    linewidth=0,\n",
    ")\n",
    "\n",
    "ax.set_extent(regions_onshore.total_bounds[[0, 2, 1, 3]])\n",
    "\n",
    "# -----------------------------\n",
    "# Legends\n",
    "# -----------------------------\n",
    "legend_kwargs = {\"loc\": \"upper left\", \"frameon\": False}\n",
    "legend_circles_dict = {\"bbox_to_anchor\": (1, 0.67), \"labelspacing\": 2.5, **legend_kwargs}\n",
    "\n",
    "add_legend_circles(\n",
    "    ax,\n",
    "    [s / bus_scale for s in bus_sizes],\n",
    "    [f\"{s / 1000} GW\" for s in bus_sizes],\n",
    "    legend_kw=legend_circles_dict,\n",
    ")\n",
    "add_legend_lines(\n",
    "    ax,\n",
    "    [s / line_scale for s in line_sizes],\n",
    "    [f\"{s / 1000} GW\" for s in line_sizes],\n",
    "    legend_kw={\"bbox_to_anchor\": (1, 0.8), **legend_kwargs},\n",
    ")\n",
    "\n",
    "# Carrier legend: build from carriers actually used after aggregation\n",
    "used_carriers_agg = buses.index.get_level_values(1).unique()\n",
    "\n",
    "colors_legend = []\n",
    "labels_legend = []\n",
    "seen = set()\n",
    "\n",
    "for c in used_carriers_agg:\n",
    "    # use aggregated carrier's style (e.g., 'gas' not 'CCGT')\n",
    "    if c in uhs.carriers.index:\n",
    "        name = uhs.carriers.loc[c, 'nice_name']\n",
    "        color = uhs.carriers.loc[c, 'color']\n",
    "    else:\n",
    "        name = str(c)\n",
    "        color = \"gray\"\n",
    "\n",
    "    val_total = buses.xs(c, level=1).sum() if c in used_carriers_agg else 0\n",
    "\n",
    "    if name not in seen and val_total > 0:\n",
    "        seen.add(name)\n",
    "        colors_legend.append(color)\n",
    "        labels_legend.append(name)\n",
    "\n",
    "add_legend_patches(\n",
    "    ax,\n",
    "    colors_legend,\n",
    "    labels_legend,\n",
    "    legend_kw={\"bbox_to_anchor\": (1, 0), **legend_kwargs, \"loc\": \"lower left\"},\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Restore original links\n",
    "uhs.links = links_backup\n",
    "warnings.simplefilter(action='default', category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fc4492",
   "metadata": {},
   "source": [
    "#### Current Capacities of Energy Carriers and Usage of Storages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5d733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Extract data for current energy carriers ---\n",
    "energy_carriers = pd.concat([uhs.generators[~uhs.generators.carrier.str.contains(\"load\", case=False)][[\"carrier\", \"p_nom\"]], uhs.storage_units[[\"carrier\", \"p_nom\"]]]).groupby(\"carrier\").p_nom.sum().div(1e3).sort_values(ascending=False)\n",
    "\n",
    "\n",
    "# --- Extract data for current storages ---\n",
    "storages = (\n",
    "    uhs.stores.groupby(\"carrier\")\n",
    "    .e_nom.sum()\n",
    "    .div(1e3)  # Convert to GWh\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "# --- Filter: keep only entries > 0 ---\n",
    "energy_carriers = energy_carriers[energy_carriers > 0]\n",
    "storages = storages[storages > 0]\n",
    "storages = storages[~storages.index.isin([\"solid biomass\", \"biogas\"])]\n",
    "\n",
    "# --- Plotting ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
    "\n",
    "# --- Energy carriers ---\n",
    "energy_colors = [get_color(c) for c in energy_carriers.index]\n",
    "wedges1, _ = axes[0].pie(\n",
    "    energy_carriers,\n",
    "    labels=None,   # no labels directly in the chart\n",
    "    startangle=90,\n",
    "    colors=energy_colors\n",
    ")\n",
    "axes[0].set_title(\"Current Energy Carriers (GW)\")\n",
    "\n",
    "# Legend with capacity + share\n",
    "labels1 = [\n",
    "    f\"{c} ({v:.1f} GW, {100*v/energy_carriers.sum():.1f}%)\"\n",
    "    for c, v in zip(energy_carriers.index, energy_carriers.values)\n",
    "]\n",
    "axes[0].legend(\n",
    "    wedges1,\n",
    "    labels1,\n",
    "    loc=\"center left\",\n",
    "    bbox_to_anchor=(1, 0, 0.5, 1)\n",
    ")\n",
    "\n",
    "# --- Storages ---\n",
    "storage_colors = [get_color(c) for c in storages.index]\n",
    "wedges2, _ = axes[1].pie(\n",
    "    storages,\n",
    "    labels=None,\n",
    "    startangle=90,\n",
    "    colors=storage_colors\n",
    ")\n",
    "axes[1].set_title(\"Current Storages (GWh)\")\n",
    "\n",
    "# Legend with capacity + share\n",
    "labels2 = [\n",
    "    f\"{c} ({v:.1f} GWh, {100*v/storages.sum():.1f}%)\"\n",
    "    for c, v in zip(storages.index, storages.values)\n",
    "]\n",
    "axes[1].legend(\n",
    "    wedges2,\n",
    "    labels2,\n",
    "    loc=\"center left\",\n",
    "    bbox_to_anchor=(1, 0, 0.5, 1)\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996eaca0",
   "metadata": {},
   "source": [
    "#### Where is it possible to build UHS in salt caverns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb4b3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_uhs_regions(n, gadm_shapes):\n",
    "    \"\"\"\n",
    "    Extract UHS storage regions and capacities and merge them with GADM shapes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : PyPSA Network\n",
    "        The network containing UHS storage units in uhs.stores.\n",
    "    gadm_shapes : GeoDataFrame\n",
    "        GADM regions with column 'GADM_ID' for merging.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    GeoDataFrame\n",
    "        GADM shapes enriched with:\n",
    "        - 'Capacity': summed UHS capacity per region\n",
    "        - 'UHS': boolean flag if region has UHS\n",
    "    \"\"\"\n",
    "\n",
    "    # Filter UHS stores\n",
    "    n_stores = n.stores[n.stores.carrier == \"H2 UHS\"].copy()\n",
    "\n",
    "    # Extract region name from store index\n",
    "    n_stores[\"region\"] = n_stores.index.str.split(\"_AC\").str[0]\n",
    "\n",
    "    # Summed installed capacity (MW) by region\n",
    "    n_capacity = (\n",
    "        n_stores.groupby(\"region\")[\"e_nom_opt\"]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"e_nom_opt\": \"Capacity\"})\n",
    "    )\n",
    "\n",
    "    # Merge with GADM shapes\n",
    "    n_gadm = gadm_shapes.merge(\n",
    "        n_capacity,\n",
    "        how=\"left\",\n",
    "        left_on=\"GADM_ID\",\n",
    "        right_on=\"region\"\n",
    "    )\n",
    "\n",
    "    # Mark regions that have UHS\n",
    "    n_regions = n_stores[\"region\"].unique()\n",
    "    n_gadm[\"UHS\"] = n_gadm[\"GADM_ID\"].isin(n_regions)\n",
    "\n",
    "    return n_gadm\n",
    "\n",
    "uhs_gadm = extract_uhs_regions(uhs, gadm_shapes)\n",
    "woUHS_gadm = extract_uhs_regions(woUHS, gadm_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eea856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the map\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "uhs_gadm.plot(ax=ax, color=\"lightgrey\", edgecolor=\"black\", linewidth=0.5)\n",
    "\n",
    "# Highlight regions with UHS\n",
    "if not uhs_gadm[uhs_gadm[\"UHS\"]].empty:\n",
    "    uhs_gadm[uhs_gadm[\"UHS\"]].plot(ax=ax, color=\"blue\", label=\"UHS Regions\")\n",
    "\n",
    "# Add legend and title\n",
    "blue_patch = mpatches.Patch(color='blue', label='UHS Regions')\n",
    "grey_patch = mpatches.Patch(color='lightgrey', label='Other Regions')\n",
    "ax.legend(handles=[grey_patch, blue_patch], loc=\"upper left\")\n",
    "ax.set_title(\"GADM Shapes with UHS Highlighted\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5ec070",
   "metadata": {},
   "source": [
    "#### Which hydrogen infrastructure does the model have in 2050?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd72bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Select, what should be shown ---\n",
    "show_uhs = True\n",
    "show_ports = True\n",
    "show_pipelines = True\n",
    "show_electrolyzers = True\n",
    "show_woUHS = True\n",
    "\n",
    "size_factor = 0.3\n",
    "\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "def plot_infrastructure(ax, gadm, net, ports, show_uhs, show_pipelines,\n",
    "                        show_electrolyzers, show_ports):\n",
    "    \"\"\"\n",
    "    Draws the full hydrogen infrastructure on a given axis.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ax : matplotlib axis\n",
    "        The axis to draw on.\n",
    "    gadm : GeoDataFrame\n",
    "        Regional shapes (uhs_gadm or woUHS_gadm).\n",
    "    net : PyPSA network\n",
    "        The network used for plotting (uhs or woUHS).\n",
    "    ports : GeoDataFrame\n",
    "        Port locations.\n",
    "    show_uhs : bool\n",
    "        Whether to show UHS capacities.\n",
    "    show_pipelines : bool\n",
    "        Whether to show pipelines.\n",
    "    show_electrolyzers : bool\n",
    "        Whether to show electrolyzers.\n",
    "    show_ports : bool\n",
    "        Whether to show ports.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Base map ---\n",
    "    gadm.plot(ax=ax, color=\"whitesmoke\", edgecolor=\"black\", linewidth=0.5)\n",
    "\n",
    "    # --- UHS Capacities ---\n",
    "    if show_uhs and \"Capacity\" in gadm.columns:\n",
    "        gadm.dropna(subset=[\"Capacity\"]).plot(\n",
    "            ax=ax,\n",
    "            column=\"Capacity\",\n",
    "            cmap=\"YlGnBu\",\n",
    "            edgecolor=\"black\",\n",
    "            linewidth=0.5,\n",
    "            legend=False\n",
    "        )\n",
    "\n",
    "    # --- Pipelines ---\n",
    "    if show_pipelines:\n",
    "        h2_pipelines = net.links[net.links.carrier.str.contains(\"H2 pipeline\", case=False, na=False)]\n",
    "\n",
    "        if not h2_pipelines.empty:  # <-- check if there are pipelines\n",
    "            # Build pipeline geometries\n",
    "            def build_pipeline_geometry(row):\n",
    "                x0, y0 = net.buses.loc[row.bus0, [\"x\", \"y\"]]\n",
    "                x1, y1 = net.buses.loc[row.bus1, [\"x\", \"y\"]]\n",
    "                return LineString([(x0, y0), (x1, y1)])\n",
    "\n",
    "            pipelines = h2_pipelines.copy()\n",
    "            pipelines[\"geometry\"] = pipelines.apply(build_pipeline_geometry, axis=1)\n",
    "\n",
    "            lines_gdf = gpd.GeoDataFrame(pipelines, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "\n",
    "            if \"p_nom_opt\" in lines_gdf.columns:\n",
    "                capacity = lines_gdf[\"p_nom_opt\"]\n",
    "                widths = np.interp(capacity, (capacity.min(), capacity.max()), (1.5, 7.0))\n",
    "            else:\n",
    "                widths = [1.5] * len(lines_gdf)\n",
    "\n",
    "            # Draw pipelines\n",
    "            for geom, w in zip(lines_gdf.geometry, widths):\n",
    "                ax.plot(*geom.xy, color=\"#206bc7\", linewidth=w, zorder=2)\n",
    "        else:\n",
    "            # No pipelines in this network, skip\n",
    "            pass\n",
    "        \n",
    "    # --- Electrolyzers ---\n",
    "    if show_electrolyzers:\n",
    "    # Select electrolyzer links\n",
    "        electrolysis_links = net.links[net.links.carrier == \"H2 Electrolysis\"]\n",
    "\n",
    "        if not electrolysis_links.empty:\n",
    "            # Installed capacity per link [MW]\n",
    "            p_nom = electrolysis_links[\"p_nom_opt\"]\n",
    "\n",
    "            # Aggregate by bus (typically bus0)\n",
    "            bus_map = electrolysis_links.bus0\n",
    "            p_nom_by_bus = p_nom.groupby(bus_map).sum()  # [MW]\n",
    "\n",
    "            # Coordinates\n",
    "            coords = net.buses.loc[p_nom_by_bus.index, [\"x\", \"y\"]]\n",
    "\n",
    "            # Visual scaling only\n",
    "            sizes = p_nom_by_bus * size_factor\n",
    "\n",
    "            ax.scatter(\n",
    "                coords[\"x\"], coords[\"y\"],\n",
    "                s=sizes,\n",
    "                c=\"lightblue\",\n",
    "                alpha=0.8,\n",
    "                edgecolor=\"k\",\n",
    "                zorder=3\n",
    "            )\n",
    "\n",
    "    # --- Ports ---\n",
    "    if show_ports:\n",
    "        # Select ports inside the region shapes\n",
    "        ports_within = gpd.sjoin(ports, gadm, how=\"inner\", predicate=\"within\")\n",
    "        ports_within.plot(ax=ax, color=\"red\", markersize=40, marker=\"o\")\n",
    "\n",
    "        # Draw port labels\n",
    "        for x, y, name in zip(ports_within.geometry.x,\n",
    "                              ports_within.geometry.y,\n",
    "                              ports_within[\"name\"]):\n",
    "            ax.annotate(name, (x + 0.1, y + 0.1),\n",
    "                        fontsize=9, color=\"red\", ha=\"left\", va=\"bottom\")\n",
    "\n",
    "    ax.set_axis_off()\n",
    "\n",
    "# --- AUTOMATIC: one or two subplots ---\n",
    "if show_woUHS:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(26, 12))\n",
    "    ax_left = axes[0]\n",
    "    ax_right = axes[1]\n",
    "\n",
    "    # --- LEFT PANEL: UHS network ---\n",
    "    plot_infrastructure(\n",
    "        ax_left, uhs_gadm, uhs, ports,\n",
    "        show_uhs, show_pipelines, show_electrolyzers, show_ports\n",
    "    )\n",
    "    ax_left.set_title(\"Hydrogen Infrastructure (UHS Network)\", fontsize=16)\n",
    "\n",
    "    # --- RIGHT PANEL: network without UHS ---\n",
    "    plot_infrastructure(\n",
    "        ax_right, woUHS_gadm, woUHS, ports,\n",
    "        False, show_pipelines, show_electrolyzers, show_ports\n",
    "    )\n",
    "    ax_right.set_title(\"Hydrogen Infrastructure (Without UHS)\", fontsize=16)\n",
    "\n",
    "else:\n",
    "    # Single plot case\n",
    "    fig, ax = plt.subplots(figsize=(14, 12))\n",
    "    plot_infrastructure(\n",
    "        ax, uhs_gadm, uhs, ports,\n",
    "        show_uhs, show_pipelines, show_electrolyzers, show_ports\n",
    "    )\n",
    "    ax.set_title(\"Hydrogen Infrastructure\", fontsize=16)\n",
    "\n",
    "# --- Determine global min/max pipeline capacity from both networks ---\n",
    "def get_pipeline_caps(net):\n",
    "    df = net.links[net.links.carrier.str.contains(\"H2 pipeline\", case=False, na=False)]\n",
    "    if df.empty:\n",
    "        return []\n",
    "    return df[\"p_nom_opt\"].values\n",
    "\n",
    "all_caps = np.concatenate([\n",
    "    get_pipeline_caps(uhs),\n",
    "    get_pipeline_caps(woUHS)\n",
    "]) if show_woUHS else get_pipeline_caps(uhs)\n",
    "\n",
    "if len(all_caps) > 0:\n",
    "    min_cap = all_caps.min()\n",
    "    max_cap = all_caps.max()\n",
    "else:\n",
    "    min_cap, max_cap = 1, 10\n",
    "\n",
    "\n",
    "# --- starting y-position for legends\n",
    "legend_y = 0.9\n",
    "spacing = 0.11\n",
    "\n",
    "# Pipeline legend\n",
    "if show_pipelines:\n",
    "    legend_caps = [500, 1000, 5000, 10000]\n",
    "    min_cap, max_cap = min(legend_caps), max(legend_caps)\n",
    "    legend_widths = np.interp(legend_caps, (min_cap, max_cap), (1.5, 7.0))\n",
    "    pipeline_handles = [\n",
    "        mlines.Line2D([], [], color=\"#206bc7\", linewidth=w, label=f\"{cap/1000:.1f} GW\")\n",
    "        for cap, w in zip(legend_caps, legend_widths)\n",
    "    ]\n",
    "    leg1 = axes[1].legend(handles=pipeline_handles, title=\"Pipeline Capacity\",\n",
    "                           loc=\"upper left\", bbox_to_anchor=(1.02, legend_y), fontsize=10)\n",
    "    fig.add_artist(leg1)\n",
    "    legend_y -= spacing\n",
    "\n",
    "# Electrolyzer legend\n",
    "if show_electrolyzers:\n",
    "    example_caps = [100, 500, 1000]  # MW\n",
    "    example_sizes = [c * size_factor for c in example_caps]\n",
    "\n",
    "    bubble_handles = [\n",
    "        plt.scatter([], [], s=s, facecolors=\"none\", edgecolors=\"k\",\n",
    "                    label=f\"{cap} MW\")\n",
    "        for s, cap in zip(example_sizes, example_caps)\n",
    "    ]\n",
    "\n",
    "    leg2 = axes[1].legend(\n",
    "        handles=bubble_handles,\n",
    "        title=\"Installed Electrolysis Capacity\",\n",
    "        loc=\"upper left\",\n",
    "        bbox_to_anchor=(1.02, 0.75),\n",
    "        fontsize=11,\n",
    "        scatterpoints=1,\n",
    "        handletextpad=2,\n",
    "        borderpad=1.5,\n",
    "        labelspacing=1.5\n",
    "    )\n",
    "\n",
    "    fig.add_artist(leg2)\n",
    "    legend_y -= spacing\n",
    "\n",
    "   \n",
    "\n",
    "# Ports legend\n",
    "if show_ports:\n",
    "    port_handle = [mlines.Line2D([], [], color=\"red\", marker=\"o\", linestyle=\"None\",\n",
    "                                 markersize=8, label=\"Port\")]\n",
    "    leg3 = axes[1].legend(handles=port_handle,\n",
    "        loc=\"upper left\",\n",
    "        bbox_to_anchor=(1.02, 0.55),\n",
    "        borderaxespad=0,\n",
    "        fontsize=11)\n",
    "    fig.add_artist(leg3)\n",
    "    legend_y -= spacing\n",
    "\n",
    "# UHS colorbar\n",
    "if show_uhs and \"Capacity\" in uhs_gadm.columns and not uhs_gadm[\"Capacity\"].dropna().empty:\n",
    "    import matplotlib as mpl\n",
    "    cmap = mpl.cm.YlGnBu\n",
    "    norm = mpl.colors.Normalize(vmin=uhs_gadm[\"Capacity\"].min(),\n",
    "                               vmax=uhs_gadm[\"Capacity\"].max())\n",
    "    sm = mpl.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "\n",
    "    # Create a new axes for the colorbar on the right side\n",
    "    cbar_ax = fig.add_axes([0.92, 0.15, 0.015, 0.7])  # [left, bottom, width, height]\n",
    "    cbar = fig.colorbar(sm, cax=cbar_ax)\n",
    "    cbar.set_label(\"UHS Capacity (MWh)\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8153d413",
   "metadata": {},
   "source": [
    "#### Compare energy system with uhs and without"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831ae80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)\n",
    "\n",
    "# -----------------------------\n",
    "# Carrier preparation (colors + nice_name)\n",
    "# -----------------------------\n",
    "carrier_color_mapping = {\n",
    "    \"lignite\": \"coal\",\n",
    "    \"solar rooftop\": \"solar\",\n",
    "    \"residential rural solar thermal\": \"solar\",\n",
    "    \"residential urban decentral solar thermal\": \"solar\",\n",
    "    \"services rural solar thermal\": \"solar\",\n",
    "    \"services urban decentral solar thermal\": \"solar\",\n",
    "    \"urban central solar thermal\": \"solar\",\n",
    "    \"ccgt\": \"gas\",\n",
    "}\n",
    "\n",
    "CARRIER_AGG_MAP = {\n",
    "    \"CCGT\": \"gas\",   # Combined-Cycle Gas -> gas\n",
    "}\n",
    "\n",
    "def prepare_carriers(n):\n",
    "    n = n.copy()\n",
    "\n",
    "    if \"color\" not in n.carriers.columns:\n",
    "        n.carriers[\"color\"] = np.nan\n",
    "    if \"nice_name\" not in n.carriers.columns:\n",
    "        n.carriers[\"nice_name\"] = n.carriers.index\n",
    "\n",
    "    for c, ref in carrier_color_mapping.items():\n",
    "        if c not in n.carriers.index:\n",
    "            n.carriers.loc[c, [\"color\", \"nice_name\"]] = [np.nan, c.replace(\"_\", \" \").capitalize()]\n",
    "\n",
    "        if ref in n.carriers.index and pd.notna(n.carriers.loc[ref, \"color\"]) and n.carriers.loc[ref, \"color\"] != \"\":\n",
    "            n.carriers.loc[c, \"color\"] = n.carriers.loc[ref, \"color\"]\n",
    "        else:\n",
    "            n.carriers.loc[c, \"color\"] = \"gray\"\n",
    "\n",
    "        if c != \"ccgt\" and ref in n.carriers.index and pd.notna(n.carriers.loc[ref, \"nice_name\"]):\n",
    "            n.carriers.loc[c, \"nice_name\"] = n.carriers.loc[ref, \"nice_name\"]\n",
    "\n",
    "    if \"coal\" in n.carriers.index:\n",
    "        n.carriers.loc[\"coal\", \"nice_name\"] = \"Coal\"\n",
    "    if \"oil\" in n.carriers.index:\n",
    "        n.carriers.loc[\"oil\", \"nice_name\"] = \"Oil\"\n",
    "    if \"gas\" in n.carriers.index:\n",
    "        n.carriers.loc[\"gas\", \"nice_name\"] = \"Gas\"\n",
    "    if \"ccgt\" in n.carriers.index:\n",
    "        n.carriers.loc[\"ccgt\", \"nice_name\"] = \"Gas\"\n",
    "        if (pd.isna(n.carriers.loc[\"ccgt\", \"color\"]) or n.carriers.loc[\"ccgt\", \"color\"] == \"\") and \"gas\" in n.carriers.index:\n",
    "            gcol = n.carriers.loc[\"gas\", \"color\"]\n",
    "            if pd.notna(gcol) and gcol != \"\":\n",
    "                n.carriers.loc[\"ccgt\", \"color\"] = gcol\n",
    "\n",
    "    n.carriers[\"color\"] = n.carriers[\"color\"].replace(\"\", np.nan).fillna(\"gray\")\n",
    "    n.carriers[\"nice_name\"] = (\n",
    "        n.carriers[\"nice_name\"]\n",
    "        .replace(\"\", np.nan)\n",
    "        .fillna(pd.Series(n.carriers.index, index=n.carriers.index))\n",
    "    )\n",
    "\n",
    "    for cand in [\"Load shedding\", \"load shedding\"]:\n",
    "        if cand in n.carriers.index:\n",
    "            n.carriers = n.carriers.drop(cand)\n",
    "\n",
    "    return n\n",
    "\n",
    "# -----------------------------\n",
    "# Hub mapping via coordinates (generalized)\n",
    "# -----------------------------\n",
    "def build_hub_mapping(n, min_cluster_size=2):\n",
    "    \"\"\"\n",
    "    A hub is defined as a coordinate cluster (x,y) that contains at least min_cluster_size buses.\n",
    "    This automatically excludes global / non-spatial buses that don't share coordinates with others.\n",
    "\n",
    "    Returns:\n",
    "      bus_to_hub: Series mapping bus -> hub_id\n",
    "      hub_coords: DataFrame mapping hub_id -> x,y\n",
    "    \"\"\"\n",
    "    buses_xy = n.buses[[\"x\", \"y\"]].copy()\n",
    "\n",
    "    # Ensure numeric and drop missing coordinates\n",
    "    buses_xy[\"x\"] = pd.to_numeric(buses_xy[\"x\"], errors=\"coerce\")\n",
    "    buses_xy[\"y\"] = pd.to_numeric(buses_xy[\"y\"], errors=\"coerce\")\n",
    "    buses_xy = buses_xy.dropna(subset=[\"x\", \"y\"])\n",
    "\n",
    "    grouped = buses_xy.groupby([\"x\", \"y\"], sort=False)\n",
    "\n",
    "    bus_to_hub = {}\n",
    "    hub_coords = {}\n",
    "    hub_id = 0\n",
    "\n",
    "    for (x, y), df in grouped:\n",
    "        if len(df) < min_cluster_size:\n",
    "            continue\n",
    "        hid = f\"hub_{hub_id}\"\n",
    "        hub_id += 1\n",
    "\n",
    "        for bus in df.index:\n",
    "            bus_to_hub[bus] = hid\n",
    "        hub_coords[hid] = {\"x\": x, \"y\": y}\n",
    "\n",
    "    bus_to_hub = pd.Series(bus_to_hub, dtype=\"object\")\n",
    "    hub_coords = pd.DataFrame.from_dict(hub_coords, orient=\"index\")\n",
    "\n",
    "    return bus_to_hub, hub_coords\n",
    "\n",
    "# -----------------------------\n",
    "# Aggregation: Generators + StorageUnits by hub & carrier\n",
    "# -----------------------------\n",
    "def aggregate_gen_sto_by_hub(n, bus_to_hub):\n",
    "    parts = []\n",
    "\n",
    "    if len(n.generators):\n",
    "        gen = n.generators[n.generators.carrier != \"load shedding\"].copy()\n",
    "        gen[\"hub\"] = gen[\"bus\"].map(bus_to_hub)\n",
    "        gen = gen.dropna(subset=[\"hub\"])\n",
    "\n",
    "        # <-- entscheidend: carrier fÃ¼r Aggregation mappen\n",
    "        gen[\"carrier_agg\"] = gen[\"carrier\"].replace(CARRIER_AGG_MAP)\n",
    "\n",
    "        parts.append(gen.groupby([\"hub\", \"carrier_agg\"])[\"p_nom_opt\"].sum())\n",
    "\n",
    "    if len(n.storage_units):\n",
    "        sto = n.storage_units.copy()\n",
    "        sto[\"hub\"] = sto[\"bus\"].map(bus_to_hub)\n",
    "        sto = sto.dropna(subset=[\"hub\"])\n",
    "\n",
    "        sto[\"carrier_agg\"] = sto[\"carrier\"].replace(CARRIER_AGG_MAP)\n",
    "\n",
    "        parts.append(sto.groupby([\"hub\", \"carrier_agg\"])[\"p_nom_opt\"].sum())\n",
    "\n",
    "    if not parts:\n",
    "        return pd.Series(dtype=float)\n",
    "\n",
    "    return pd.concat(parts).groupby(level=[0, 1]).sum()\n",
    "\n",
    "# -----------------------------\n",
    "# Draw one pie per hub\n",
    "# -----------------------------\n",
    "def draw_pies(ax, hubs_caps, hub_coords, carriers_df, bus_scale, alpha=0.7, radius_mode=\"linear\"):\n",
    "    if hubs_caps.empty or hub_coords.empty:\n",
    "        return\n",
    "\n",
    "    hub_totals = hubs_caps.groupby(level=0).sum()\n",
    "\n",
    "    for hub, total in hub_totals.items():\n",
    "        if total <= 0 or hub not in hub_coords.index:\n",
    "            continue\n",
    "\n",
    "        x, y = hub_coords.loc[hub, [\"x\", \"y\"]]\n",
    "\n",
    "        if radius_mode == \"sqrt\":\n",
    "            r = np.sqrt(total / bus_scale)\n",
    "        else:\n",
    "            r = total / bus_scale\n",
    "\n",
    "        s = hubs_caps.xs(hub, level=0)\n",
    "        s = s[s > 0].sort_values(ascending=False)\n",
    "        if s.empty:\n",
    "            continue\n",
    "\n",
    "        start = 0.0\n",
    "        denom = s.sum()\n",
    "\n",
    "        for carrier, val in s.items():\n",
    "            end = start + (val / denom) * 360.0\n",
    "\n",
    "            color = \"gray\"\n",
    "            if carrier in carriers_df.index and \"color\" in carriers_df.columns:\n",
    "                c = carriers_df.loc[carrier, \"color\"]\n",
    "                if pd.notna(c) and c != \"\":\n",
    "                    color = c\n",
    "\n",
    "            ax.add_patch(\n",
    "                Wedge(\n",
    "                    (x, y), r, start, end,\n",
    "                    facecolor=color, edgecolor=\"none\", alpha=alpha,\n",
    "                    transform=ccrs.PlateCarree(),\n",
    "                )\n",
    "            )\n",
    "            start = end\n",
    "\n",
    "# -----------------------------\n",
    "# Plot routine: network lines/links via PyPSA, pies drawn manually\n",
    "# -----------------------------\n",
    "def plot_network_one_pie_per_location(\n",
    "    n, ax, title, gadm_shapes, regions_onshore,\n",
    "    bus_scale, line_scale, min_cluster_size=2, pie_alpha=0.7, pie_radius_mode=\"linear\"\n",
    "):\n",
    "    bus_to_hub, hub_coords = build_hub_mapping(n, min_cluster_size=min_cluster_size)\n",
    "    hubs_caps = aggregate_gen_sto_by_hub(n, bus_to_hub)\n",
    "\n",
    "    # Suppress PyPSA bus glyphs; we draw pies ourselves\n",
    "    zero_bus_sizes = pd.Series(0.0, index=n.buses.index)\n",
    "\n",
    "    # Filter links for plotting ONLY (still excluded from pies)\n",
    "    link_bus0_base = n.links.bus0.str.split(\"_AC\").str[0]\n",
    "    link_bus1_base = n.links.bus1.str.split(\"_AC\").str[0]\n",
    "    valid_links = n.links[\n",
    "        link_bus0_base.isin(gadm_shapes.index)\n",
    "        & link_bus1_base.isin(gadm_shapes.index)\n",
    "        & (n.links.p_nom_opt > 0)\n",
    "    ]\n",
    "\n",
    "    n_plot = n.copy()\n",
    "    n_plot.links = valid_links\n",
    "\n",
    "    # Background\n",
    "    regions_onshore.plot(\n",
    "        ax=ax,\n",
    "        facecolor=\"whitesmoke\",\n",
    "        edgecolor=\"white\",\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        linewidth=0,\n",
    "    )\n",
    "\n",
    "    with plt.rc_context({\"patch.linewidth\": 0.0}):\n",
    "        n_plot.plot(\n",
    "            bus_sizes=zero_bus_sizes,\n",
    "            bus_alpha=0.0,\n",
    "            line_widths=n_plot.lines.s_nom_opt / line_scale,\n",
    "            link_widths=n_plot.links.p_nom_opt / line_scale,\n",
    "            line_colors=\"teal\",\n",
    "            ax=ax,\n",
    "            margin=0.2,\n",
    "            color_geomap=None,\n",
    "        )\n",
    "\n",
    "    ax.set_extent(regions_onshore.total_bounds[[0, 2, 1, 3]])\n",
    "    ax.set_title(title, fontsize=14)\n",
    "\n",
    "    # Pies overlay\n",
    "    draw_pies(\n",
    "        ax, hubs_caps, hub_coords, n.carriers,\n",
    "        bus_scale=bus_scale, alpha=pie_alpha, radius_mode=pie_radius_mode\n",
    "    )\n",
    "\n",
    "    # Return used carriers for legend building\n",
    "    used_carriers = set()\n",
    "    if len(n.generators):\n",
    "        used_carriers |= set(n.generators.carrier.replace(CARRIER_AGG_MAP))\n",
    "    if len(n.storage_units):\n",
    "        used_carriers |= set(n.storage_units.carrier.replace(CARRIER_AGG_MAP))\n",
    "    used_carriers.discard(\"load shedding\")\n",
    "    return used_carriers\n",
    "\n",
    "# -----------------------------\n",
    "# USER SETTINGS\n",
    "# -----------------------------\n",
    "bus_scale  = 6e4\n",
    "line_scale = 6e3\n",
    "bus_sizes_legend  = [1000, 10000]  # MW (legend only)\n",
    "line_sizes_legend = [100, 1000]      # MW (legend only)\n",
    "\n",
    "# Pie hub definition:\n",
    "# - min_cluster_size=2 excludes coordinate singletons (typical global buses)\n",
    "min_cluster_size = 2\n",
    "\n",
    "# -----------------------------\n",
    "# Run (two scenarios side-by-side)\n",
    "# -----------------------------\n",
    "uhs_p   = prepare_carriers(uhs)\n",
    "woUHS_p = prepare_carriers(woUHS)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8), subplot_kw={\"projection\": ccrs.PlateCarree()})\n",
    "\n",
    "used_0 = plot_network_one_pie_per_location(\n",
    "    uhs_p, axes[0], \"Scenario with UHS (2050)\",\n",
    "    gadm_shapes, regions_onshore,\n",
    "    bus_scale, line_scale,\n",
    "    min_cluster_size=min_cluster_size,\n",
    "    pie_alpha=0.7,\n",
    "    pie_radius_mode=\"linear\",\n",
    ")\n",
    "used_1 = plot_network_one_pie_per_location(\n",
    "    woUHS_p, axes[1], \"Scenario without UHS (2050)\",\n",
    "    gadm_shapes, regions_onshore,\n",
    "    bus_scale, line_scale,\n",
    "    min_cluster_size=min_cluster_size,\n",
    "    pie_alpha=0.7,\n",
    "    pie_radius_mode=\"linear\",\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Legends (reuse your helpers)\n",
    "# -----------------------------\n",
    "legend_kwargs = {\"loc\": \"upper left\", \"frameon\": False}\n",
    "\n",
    "add_legend_circles(\n",
    "    axes[1],\n",
    "    [s / bus_scale for s in bus_sizes_legend],\n",
    "    [f\"{s / 1000} GW\" for s in bus_sizes_legend],\n",
    "    legend_kw={\"bbox_to_anchor\": (1.05, 0.67), \"labelspacing\": 2.5, **legend_kwargs},\n",
    ")\n",
    "add_legend_lines(\n",
    "    axes[1],\n",
    "    [s / line_scale for s in line_sizes_legend],\n",
    "    [f\"{s / 1000} GW\" for s in line_sizes_legend],\n",
    "    legend_kw={\"bbox_to_anchor\": (1.05, 0.8), **legend_kwargs},\n",
    ")\n",
    "\n",
    "# Carrier legend: union across both scenarios, from generators + storage_units only\n",
    "used_carriers = {CARRIER_AGG_MAP.get(c, c) for c in used_0.union(used_1)}\n",
    "\n",
    "colors_legend, labels_legend, seen = [], [], set()\n",
    "for c in uhs_p.carriers.index:\n",
    "    if c not in used_carriers:\n",
    "        continue\n",
    "\n",
    "    name = uhs_p.carriers.loc[c, \"nice_name\"] if \"nice_name\" in uhs_p.carriers.columns else c\n",
    "    if pd.isna(name) or name == \"\":\n",
    "        name = c.replace(\"_\", \" \").capitalize()\n",
    "\n",
    "    color = uhs_p.carriers.loc[c, \"color\"] if \"color\" in uhs_p.carriers.columns else \"gray\"\n",
    "    if pd.isna(color) or color == \"\":\n",
    "        color = \"gray\"\n",
    "\n",
    "    if name not in seen:\n",
    "        seen.add(name)\n",
    "        colors_legend.append(color)\n",
    "        labels_legend.append(name)\n",
    "\n",
    "add_legend_patches(\n",
    "    axes[1],\n",
    "    colors_legend,\n",
    "    labels_legend,\n",
    "    legend_kw={\"bbox_to_anchor\": (1.05, 0), **legend_kwargs, \"loc\": \"lower left\"},\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "warnings.simplefilter(action=\"default\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89e85d3",
   "metadata": {},
   "source": [
    "#### Capacity extension of energy carriers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f068c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generator_capacity_expansion(n, to_gw=True, drop_zeros=True, eps=1e-6):\n",
    "    \"\"\"\n",
    "    Returns Series indexed by carrier with expansion = sum(p_nom_opt - p_nom).\n",
    "    \"\"\"\n",
    "    g = n.generators.copy()\n",
    "\n",
    "    # p_nom exists for extendable and non-extendable gens; fill missing with 0\n",
    "    if \"p_nom\" not in g.columns:\n",
    "        g[\"p_nom\"] = 0.0\n",
    "    g[\"p_nom\"] = g[\"p_nom\"].fillna(0.0)\n",
    "\n",
    "    # Optional: exclude load shedding if present\n",
    "    g = g[g.carrier != \"load shedding\"]\n",
    "\n",
    "    exp = (g[\"p_nom_opt\"] - g[\"p_nom\"]).groupby(g[\"carrier\"]).sum()\n",
    "\n",
    "    if to_gw:\n",
    "        exp = exp / 1e3  # MW -> GW\n",
    "\n",
    "    if drop_zeros:\n",
    "        exp = exp[exp.abs() > eps]\n",
    "\n",
    "    return exp.sort_values(ascending=False)\n",
    "\n",
    "# --- Compute expansions ---\n",
    "exp_uhs   = generator_capacity_expansion(uhs, to_gw=True, drop_zeros=False)\n",
    "exp_woUHS = generator_capacity_expansion(woUHS, to_gw=True, drop_zeros=False)\n",
    "\n",
    "# Align carriers across scenarios\n",
    "df_expansion = pd.concat(\n",
    "    [exp_uhs.rename(\"Scenario with UHS\"), exp_woUHS.rename(\"Scenario without UHS\")],\n",
    "    axis=1\n",
    ").fillna(0.0)\n",
    "\n",
    "# (Optional) drop carriers with ~0 in both scenarios\n",
    "eps = 1e-6\n",
    "df_expansion = df_expansion[(df_expansion.abs().max(axis=1) > eps)]\n",
    "\n",
    "# --- Plot ---\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "width = 0.35\n",
    "x = np.arange(len(df_expansion.index))\n",
    "\n",
    "ax.bar(x - width/2, df_expansion[\"Scenario with UHS\"], width, color=SCENARIO_COLORS[\"UHS\"], label=\"Scenario with UHS\")\n",
    "ax.bar(x + width/2, df_expansion[\"Scenario without UHS\"], width, color=SCENARIO_COLORS[\"woUHS\"], label=\"Scenario without UHS\")\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(df_expansion.index, rotation=45, ha=\"right\")\n",
    "ax.set_ylabel(\"Capacity Expansion (GW)\")\n",
    "ax.set_title(\"Generator Capacity Expansion Comparison\")\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b0d439",
   "metadata": {},
   "source": [
    "#### Capacity extension of storages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de38edfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1e-1\n",
    "\n",
    "def storage_extension_GWh(n):\n",
    "    stores = n.stores.copy()\n",
    "    # If e_nom exists, compute added capacity; else fall back to e_nom_opt\n",
    "    if \"e_nom\" in stores.columns:\n",
    "        ext_MWh = (stores[\"e_nom_opt\"] - stores[\"e_nom\"]).clip(lower=0)\n",
    "    else:\n",
    "        ext_MWh = stores[\"e_nom_opt\"].fillna(0)\n",
    "    return ext_MWh.groupby(stores[\"carrier\"]).sum() / 1e3  # GWh\n",
    "\n",
    "uhs_storage_extension = storage_extension_GWh(uhs)\n",
    "woUHS_storage_extension = storage_extension_GWh(woUHS)\n",
    "\n",
    "# --- Filter unwanted carriers ---\n",
    "exclude_carriers = [\"gas\", \"co2\", \"oil\", \"solid biomass\", \"H2\", \"coal\", \"biomass\", \"biogas\", \"co2 stored\"]\n",
    "uhs_storage_extension = uhs_storage_extension[~uhs_storage_extension.index.isin(exclude_carriers)]\n",
    "woUHS_storage_extension = woUHS_storage_extension[~woUHS_storage_extension.index.isin(exclude_carriers)]\n",
    "\n",
    "# Filter out carriers with zero capacity extension\n",
    "uhs_storage_extension = uhs_storage_extension[uhs_storage_extension > threshold]\n",
    "woUHS_storage_extension = woUHS_storage_extension[woUHS_storage_extension > threshold]\n",
    "\n",
    "# Combine for consistent order\n",
    "all_carriers = sorted(set(uhs_storage_extension.index) | set(woUHS_storage_extension.index))\n",
    "uhs_storage_extension = uhs_storage_extension.reindex(all_carriers, fill_value=0)\n",
    "woUHS_storage_extension = woUHS_storage_extension.reindex(all_carriers, fill_value=0)\n",
    "\n",
    "# --- Plot ---\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "width = 0.35  # Width of the bars\n",
    "x = np.arange(len(all_carriers))  # Carrier positions on x-axis\n",
    "\n",
    "# Bars for UHS scenario\n",
    "ax.bar(x - width/2, uhs_storage_extension, width, color=SCENARIO_COLORS[\"UHS\"], label=\"Scenario with UHS\")\n",
    "\n",
    "# Bars for woUHS scenario\n",
    "ax.bar(x + width/2, woUHS_storage_extension, width, color=SCENARIO_COLORS[\"woUHS\"], label=\"Scenario without UHS\")\n",
    "\n",
    "# Axis labels and title\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(all_carriers, rotation=45, ha=\"right\")\n",
    "ax.set_ylabel(\"Capacity Extension (GWh)\")\n",
    "ax.set_title(\"Storage Capacity Extension Comparison\")\n",
    "\n",
    "# Legend\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11d7591",
   "metadata": {},
   "source": [
    "#### Hydrogen related extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6572b3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1e-1\n",
    "# --- Extract hydrogen-related capacities ---#\n",
    "# Extract hydrogen-related energy balances for UHS and woUHS\n",
    "uhs_hydrogen_balance = uhs.statistics.energy_balance().loc[:, :, \"H2\"].groupby(\"carrier\").sum().div(1e6)  # Convert to TWh\n",
    "woUHS_hydrogen_balance = woUHS.statistics.energy_balance().loc[:, :, \"H2\"].groupby(\"carrier\").sum().div(1e6)  # Convert to TWh\n",
    "# Combine for consistent order\n",
    "all_hydrogen_carriers = sorted(set(uhs_hydrogen_balance.index) | set(woUHS_hydrogen_balance.index))\n",
    "uhs_hydrogen_balance = uhs_hydrogen_balance.reindex(all_hydrogen_carriers, fill_value=0)\n",
    "woUHS_hydrogen_balance = woUHS_hydrogen_balance.reindex(all_hydrogen_carriers, fill_value=0)\n",
    "\n",
    "# --- Filter: keep only carriers with actual (non-zero) energy flows in either scenario ---\n",
    "combined_balance = uhs_hydrogen_balance.abs() + woUHS_hydrogen_balance.abs()\n",
    "\n",
    "mask = combined_balance > threshold\n",
    "\n",
    "uhs_hydrogen_balance = uhs_hydrogen_balance[mask]\n",
    "woUHS_hydrogen_balance = woUHS_hydrogen_balance[mask]\n",
    "all_hydrogen_carriers = uhs_hydrogen_balance.index.tolist()\n",
    "\n",
    "# --- Plot ---\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "width = 0.35  # Width of the bars\n",
    "x = np.arange(len(all_hydrogen_carriers))  # Carrier positions on x-axis\n",
    "\n",
    "# Bars for UHS scenario\n",
    "ax.bar(x - width/2, uhs_hydrogen_balance, width, color=SCENARIO_COLORS[\"UHS\"], label=\"Scenario with UHS\")\n",
    "\n",
    "# Bars for woUHS scenario\n",
    "ax.bar(x + width/2, woUHS_hydrogen_balance, width, color=SCENARIO_COLORS[\"woUHS\"], label=\"Scenario without UHS\")\n",
    "\n",
    "# Axis labels and title\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(all_hydrogen_carriers, rotation=45, ha=\"right\")\n",
    "ax.set_ylabel(\"Supply and Demand (TWh)\")\n",
    "ax.set_title(\"Hydrogen Supply and Demand Comparison\")\n",
    "\n",
    "# Legend\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb70a35",
   "metadata": {},
   "source": [
    "##### Energy Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7455eff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# User-adjustable threshold\n",
    "# =========================\n",
    "THRESHOLD_TWH = 0   # hide carriers with |value| < 0.1 TWh in BOTH scenarios\n",
    "LEGEND_THRESHOLD_TWH = 0  # show only carriers >= 10 TWh in legend\n",
    "\n",
    "def compute_energy_balance(n: pypsa.Network) -> pd.Series:\n",
    "    rename_cols = {\n",
    "        \"-\": \"Load\",\n",
    "        \"load\": \"load shedding\",\n",
    "    }\n",
    "\n",
    "    # Aggregate energy balance by carrier and convert MWh -> TWh\n",
    "    eb = (\n",
    "        n.statistics.energy_balance()\n",
    "        .loc[:, :, \"Ac\"]\n",
    "        .groupby(\"carrier\")\n",
    "        .sum()\n",
    "        .div(1e6)  # MWh -> TWh\n",
    "        .rename(index=rename_cols)\n",
    "    )\n",
    "\n",
    "    # If result is a DataFrame (multiple columns), reduce to a single number per carrier\n",
    "    if isinstance(eb, pd.DataFrame):\n",
    "        eb = eb.sum(axis=1)\n",
    "\n",
    "    return eb.fillna(0.0)\n",
    "\n",
    "\n",
    "# --- Compute data (as Series) ---\n",
    "s_uhs = compute_energy_balance(uhs)\n",
    "s_woUHS = compute_energy_balance(woUHS)\n",
    "\n",
    "# Harmonize index (carriers) between scenarios\n",
    "all_carriers = sorted(set(s_uhs.index) | set(s_woUHS.index))\n",
    "s_uhs = s_uhs.reindex(all_carriers, fill_value=0.0)\n",
    "s_woUHS = s_woUHS.reindex(all_carriers, fill_value=0.0)\n",
    "\n",
    "# --- Apply threshold: keep only carriers with meaningful flows in either scenario ---\n",
    "mask = (s_uhs.abs() >= THRESHOLD_TWH) | (s_woUHS.abs() >= THRESHOLD_TWH)\n",
    "s_uhs = s_uhs.loc[mask]\n",
    "s_woUHS = s_woUHS.loc[mask]\n",
    "\n",
    "# Sort carriers by combined absolute magnitude (more stable than raw sum if signs mix)\n",
    "order = (s_uhs.abs() + s_woUHS.abs()).sort_values(ascending=False).index.tolist()\n",
    "s_uhs = s_uhs.reindex(order)\n",
    "s_woUHS = s_woUHS.reindex(order)\n",
    "\n",
    "# Convert to 1-row DataFrames for your bar plotting style\n",
    "df_uhs = s_uhs.to_frame().T\n",
    "df_woUHS = s_woUHS.to_frame().T\n",
    "\n",
    "# --- Assign colors ---\n",
    "colors = [get_color(c) for c in order]\n",
    "\n",
    "# --- Plot ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6), sharey=True)\n",
    "\n",
    "df_uhs.plot.bar(\n",
    "    stacked=True,\n",
    "    ax=axes[0],\n",
    "    legend=False,\n",
    "    title=\"Scenario with uhs â Electricity Balance (TWh)\",\n",
    "    color=colors\n",
    ")\n",
    "axes[0].set_xlabel(\"\")\n",
    "axes[0].set_ylabel(\"TWh\")\n",
    "\n",
    "df_woUHS.plot.bar(\n",
    "    stacked=True,\n",
    "    ax=axes[1],\n",
    "    legend=False,\n",
    "    title=\"Scenario without uhs â Electricity Balance (TWh)\",\n",
    "    color=colors\n",
    ")\n",
    "axes[1].set_xlabel(\"\")\n",
    "axes[1].set_ylabel(\"\")\n",
    "\n",
    "# --- Manually build the legend (threshold-controlled) ---\n",
    "labels, handles = [], []\n",
    "for c, col in zip(order, colors):\n",
    "    val_uhs = float(df_uhs.iloc[0][c])\n",
    "    val_woUHS = float(df_woUHS.iloc[0][c])\n",
    "\n",
    "    if (abs(val_uhs) >= LEGEND_THRESHOLD_TWH) or (abs(val_woUHS) >= LEGEND_THRESHOLD_TWH):\n",
    "        labels.append(f\"{c} ({val_uhs:.1f}, {val_woUHS:.1f} TWh)\")\n",
    "        handles.append(plt.Rectangle((0, 0), 1, 1, color=col))\n",
    "\n",
    "axes[1].legend(\n",
    "    handles,\n",
    "    labels,\n",
    "    bbox_to_anchor=(1.02, 1),\n",
    "    loc=\"upper left\",\n",
    "    borderaxespad=0,\n",
    "    title=f\"Carriers (â¥ {LEGEND_THRESHOLD_TWH} TWh)\"\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057aa2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# User-adjustable threshold\n",
    "# =========================\n",
    "THRESHOLD_TWH = 0   # hide carriers with |value| < 0.1 TWh in BOTH scenarios\n",
    "LEGEND_THRESHOLD_TWH = 0  # show only carriers >= 10 TWh in legend\n",
    "\n",
    "def compute_energy_balance(n: pypsa.Network) -> pd.Series:\n",
    "    rename_cols = {\n",
    "        \"-\": \"Load\",\n",
    "        \"load\": \"load shedding\",\n",
    "    }\n",
    "\n",
    "    # Aggregate energy balance by carrier and convert MWh -> TWh\n",
    "    eb = (\n",
    "        n.statistics.energy_balance()\n",
    "        .loc[:, :, \"H2\"]\n",
    "        .groupby(\"carrier\")\n",
    "        .sum()\n",
    "        .div(1e6)  # MWh -> TWh\n",
    "        .rename(index=rename_cols)\n",
    "    )\n",
    "\n",
    "    # If result is a DataFrame (multiple columns), reduce to a single number per carrier\n",
    "    if isinstance(eb, pd.DataFrame):\n",
    "        eb = eb.sum(axis=1)\n",
    "\n",
    "    return eb.fillna(0.0)\n",
    "\n",
    "\n",
    "# --- Compute data (as Series) ---\n",
    "s_uhs = compute_energy_balance(uhs)\n",
    "s_woUHS = compute_energy_balance(woUHS)\n",
    "\n",
    "# Harmonize index (carriers) between scenarios\n",
    "all_carriers = sorted(set(s_uhs.index) | set(s_woUHS.index))\n",
    "s_uhs = s_uhs.reindex(all_carriers, fill_value=0.0)\n",
    "s_woUHS = s_woUHS.reindex(all_carriers, fill_value=0.0)\n",
    "\n",
    "# --- Apply threshold: keep only carriers with meaningful flows in either scenario ---\n",
    "mask = (s_uhs.abs() >= THRESHOLD_TWH) | (s_woUHS.abs() >= THRESHOLD_TWH)\n",
    "s_uhs = s_uhs.loc[mask]\n",
    "s_woUHS = s_woUHS.loc[mask]\n",
    "\n",
    "# Sort carriers by combined absolute magnitude (more stable than raw sum if signs mix)\n",
    "order = (s_uhs.abs() + s_woUHS.abs()).sort_values(ascending=False).index.tolist()\n",
    "s_uhs = s_uhs.reindex(order)\n",
    "s_woUHS = s_woUHS.reindex(order)\n",
    "\n",
    "# Convert to 1-row DataFrames for your bar plotting style\n",
    "df_uhs = s_uhs.to_frame().T\n",
    "df_woUHS = s_woUHS.to_frame().T\n",
    "\n",
    "# --- Assign colors ---\n",
    "colors = [get_color(c) for c in order]\n",
    "\n",
    "# --- Plot ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6), sharey=True)\n",
    "\n",
    "df_uhs.plot.bar(\n",
    "    stacked=True,\n",
    "    ax=axes[0],\n",
    "    legend=False,\n",
    "    title=\"Scenario with uhs â Hydrogen Balance (TWh)\",\n",
    "    color=colors\n",
    ")\n",
    "axes[0].set_xlabel(\"\")\n",
    "axes[0].set_ylabel(\"TWh\")\n",
    "\n",
    "df_woUHS.plot.bar(\n",
    "    stacked=True,\n",
    "    ax=axes[1],\n",
    "    legend=False,\n",
    "    title=\"Scenario without uhs â Hydrogen Balance (TWh)\",\n",
    "    color=colors\n",
    ")\n",
    "axes[1].set_xlabel(\"\")\n",
    "axes[1].set_ylabel(\"\")\n",
    "\n",
    "# --- Manually build the legend (threshold-controlled) ---\n",
    "labels, handles = [], []\n",
    "for c, col in zip(order, colors):\n",
    "    val_uhs = float(df_uhs.iloc[0][c])\n",
    "    val_woUHS = float(df_woUHS.iloc[0][c])\n",
    "\n",
    "    if (abs(val_uhs) >= LEGEND_THRESHOLD_TWH) or (abs(val_woUHS) >= LEGEND_THRESHOLD_TWH):\n",
    "        labels.append(f\"{c} ({val_uhs:.1f}, {val_woUHS:.1f} TWh)\")\n",
    "        handles.append(plt.Rectangle((0, 0), 1, 1, color=col))\n",
    "\n",
    "axes[1].legend(\n",
    "    handles,\n",
    "    labels,\n",
    "    bbox_to_anchor=(1.02, 1),\n",
    "    loc=\"upper left\",\n",
    "    borderaxespad=0,\n",
    "    title=f\"Carriers (â¥ {LEGEND_THRESHOLD_TWH} TWh)\"\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc1f725",
   "metadata": {},
   "source": [
    "##### Heating Supply Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72754bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger(\"pypsa.statistics\").setLevel(logging.ERROR)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "# Adjustable settings\n",
    "heating_map = {\n",
    "    \"Gas Boiler\": [\"gas boiler\", \"boiler\"],\n",
    "    \"Heat Pump\": [\"heat pump\"],\n",
    "    \"Resistive Heater\": [\"resistive heater\", \"resistive\"],\n",
    "    \"CHP\": [\"chp\"],\n",
    "}\n",
    "\n",
    "TO_TWH = True  # False -> MWh\n",
    "\n",
    "def heating_distribution(n: pypsa.Network, tech_map=heating_map) -> pd.Series:\n",
    "    s = (\n",
    "        n.statistics.supply(comps=[\"Link\"], aggregate_time=\"sum\")\n",
    "        .loc[lambda x: x.index.get_level_values(\"carrier\")\n",
    "             .str.contains(\"heat|boiler|pump|chp\", case=False, na=False)]\n",
    "    )\n",
    "\n",
    "    carriers = pd.Index(s.index.get_level_values(\"carrier\"))\n",
    "\n",
    "    def sum_for_patterns(patterns) -> float:\n",
    "        mask = np.zeros(len(carriers), dtype=bool)\n",
    "        for p in patterns:\n",
    "            mask |= np.asarray(carriers.str.contains(p, case=False, na=False))\n",
    "        if not mask.any():\n",
    "            return 0.0\n",
    "        return float(s.loc[mask].sum(numeric_only=True).sum())\n",
    "\n",
    "    data = {label: sum_for_patterns(patterns) for label, patterns in tech_map.items()}\n",
    "    return pd.Series(data, index=list(tech_map.keys())).fillna(0.0)\n",
    "\n",
    "\n",
    "# --- Compute totals ---\n",
    "uhs_mwh = heating_distribution(uhs)\n",
    "woUHS_mwh = heating_distribution(woUHS)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Scenario with UHS\": uhs_mwh,\n",
    "    \"Scenario without UHS\": woUHS_mwh\n",
    "})\n",
    "\n",
    "# Unit conversion\n",
    "if TO_TWH:\n",
    "    df = df / 1e6\n",
    "    y_label = \"TWh\"\n",
    "    value_fmt = \"{:.2f}\"\n",
    "else:\n",
    "    y_label = \"MWh\"\n",
    "    value_fmt = \"{:,.0f}\"\n",
    "# --- Plot: grouped bar chart ---\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "x = np.arange(len(df.index))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(\n",
    "    x - width / 2,\n",
    "    df[\"Scenario with UHS\"].values,\n",
    "    width,\n",
    "    label=\"Scenario with UHS\",\n",
    "    color=SCENARIO_COLORS[\"UHS\"],\n",
    ")\n",
    "\n",
    "ax.bar(\n",
    "    x + width / 2,\n",
    "    df[\"Scenario without UHS\"].values,\n",
    "    width,\n",
    "    label=\"Scenario without UHS\",\n",
    "    color=SCENARIO_COLORS[\"woUHS\"],\n",
    ")\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(df.index, rotation=20, ha=\"right\")\n",
    "ax.set_ylabel(y_label)\n",
    "ax.set_title(\"Heating Supply Distribution by Technology\")\n",
    "ax.legend()\n",
    "\n",
    "# --- Y-axis alignment ---\n",
    "ymax = max(df.values.max(), 1e-9)\n",
    "ax.set_ylim(0, ymax * 1.15)\n",
    "\n",
    "# --- Value labels ---\n",
    "for i, tech in enumerate(df.index):\n",
    "    v1 = df.loc[tech, \"Scenario with UHS\"]\n",
    "    v2 = df.loc[tech, \"Scenario without UHS\"]\n",
    "\n",
    "    ax.text(i - width / 2, v1, value_fmt.format(v1),\n",
    "            ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "    ax.text(i + width / 2, v2, value_fmt.format(v2),\n",
    "            ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "warnings.simplefilter(action='default', category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f67c346",
   "metadata": {},
   "source": [
    "#### Hydrogen prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7ed2a0",
   "metadata": {},
   "source": [
    "##### LCOH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a046b0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def snapshot_weights(net) -> pd.Series:\n",
    "    \"\"\"Return snapshot weights (defaults to 1.0 if not available).\"\"\"\n",
    "    sw = getattr(net, \"snapshot_weightings\", None)\n",
    "    if sw is not None:\n",
    "        try:\n",
    "            if \"generators\" in sw:\n",
    "                return sw[\"generators\"]\n",
    "        except Exception:\n",
    "            pass\n",
    "    return pd.Series(1.0, index=net.snapshots)\n",
    "\n",
    "\n",
    "def capex_links(net, carriers) -> float:\n",
    "    \"\"\"Annualized CAPEX contribution for link carriers (already annualized in capital_cost).\"\"\"\n",
    "    links = net.links[net.links.carrier.isin(carriers)]\n",
    "    if links.empty:\n",
    "        return 0.0\n",
    "    p_nom = links[\"p_nom_opt\"] if \"p_nom_opt\" in links.columns else links[\"p_nom\"]\n",
    "    return float((p_nom * links[\"capital_cost\"]).fillna(0.0).sum())\n",
    "\n",
    "\n",
    "def vopex_links(net, carriers) -> float:\n",
    "    \"\"\"Variable OPEX for link carriers using marginal_cost * annual energy throughput.\"\"\"\n",
    "    links = net.links[net.links.carrier.isin(carriers)]\n",
    "    if links.empty:\n",
    "        return 0.0\n",
    "    w = snapshot_weights(net)\n",
    "    mc = links[\"marginal_cost\"].fillna(0.0)\n",
    "    p0 = net.links_t.p0[links.index]  # snapshots x links (MW)\n",
    "    e_mwh = (p0.abs().mul(w, axis=0)).sum()  # MWh per link-year\n",
    "    return float((e_mwh * mc).sum())\n",
    "\n",
    "\n",
    "def annual_h2_output_kg_from_link_p1(net, carrier: str, h2_lhv_kwh_per_kg: float = 33.33) -> float:\n",
    "    \"\"\"Annual H2 output [kg] from links with H2 on bus1 using p1 time series.\"\"\"\n",
    "    idx = net.links.index[net.links.carrier == carrier]\n",
    "    if len(idx) == 0:\n",
    "        return 0.0\n",
    "    w = snapshot_weights(net)\n",
    "    p1 = net.links_t.p1[idx]  # MW (sign may vary)\n",
    "    e_mwh = (p1.abs().mul(w, axis=0)).sum().sum()\n",
    "    return float(e_mwh) * 1000.0 / h2_lhv_kwh_per_kg\n",
    "\n",
    "\n",
    "def bus_price_cost_for_link_port(\n",
    "    net,\n",
    "    link_idx,\n",
    "    port: str = \"p0\",\n",
    "    bus_col: str = \"bus0\",\n",
    "    price_sign: float = +1.0,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Annual cost [â¬] = sum_t (consumption_MW * weight * (price_sign * marginal_price(bus))).\n",
    "\n",
    "    Sign-robust: chooses p vs -p such that aggregate positive consumption is maximized.\n",
    "    price_sign flips the sign if the dual variable convention is inverted (CO2 in PyPSA-Earth).\n",
    "    \"\"\"\n",
    "    if not hasattr(net, \"buses_t\") or not hasattr(net.buses_t, \"marginal_price\"):\n",
    "        raise ValueError(\"net.buses_t.marginal_price not found (no dual prices stored).\")\n",
    "\n",
    "    w = snapshot_weights(net)\n",
    "    p = getattr(net.links_t, port)[link_idx]  # snapshots x links\n",
    "\n",
    "    cons_pos = (p.clip(lower=0).mul(w, axis=0)).sum().sum()\n",
    "    cons_neg = ((-p).clip(lower=0).mul(w, axis=0)).sum().sum()\n",
    "    cons = p.clip(lower=0) if cons_pos >= cons_neg else (-p).clip(lower=0)\n",
    "\n",
    "    buses = net.links.loc[link_idx, bus_col]\n",
    "    price_mat = pd.DataFrame({lid: net.buses_t.marginal_price[bus] for lid, bus in buses.items()})\n",
    "    return float(((cons.mul(w, axis=0)) * (price_sign * price_mat)).sum().sum())\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Technology cost components\n",
    "# ============================================================\n",
    "\n",
    "def electricity_cost_for_electrolysis(net, electrolysis_carrier: str = \"H2 Electrolysis\") -> float:\n",
    "    \"\"\"Annual electricity cost [â¬] for electrolysis priced at bus0.\"\"\"\n",
    "    idx = net.links.index[net.links.carrier == electrolysis_carrier]\n",
    "    if len(idx) == 0:\n",
    "        return 0.0\n",
    "    return bus_price_cost_for_link_port(net, idx, port=\"p0\", bus_col=\"bus0\", price_sign=+1.0)\n",
    "\n",
    "\n",
    "def gas_cost_for_smr(net, smr_carrier: str = \"SMR\") -> float:\n",
    "    \"\"\"Annual gas cost [â¬] for SMR priced at bus0.\"\"\"\n",
    "    idx = net.links.index[net.links.carrier == smr_carrier]\n",
    "    if len(idx) == 0:\n",
    "        return 0.0\n",
    "    return bus_price_cost_for_link_port(net, idx, port=\"p0\", bus_col=\"bus0\", price_sign=+1.0)\n",
    "\n",
    "\n",
    "def co2_cost_for_smr(net, smr_carrier: str = \"SMR\") -> float:\n",
    "    \"\"\"\n",
    "    Annual CO2 cost [â¬] for SMR priced at bus2 (co2 atmosphere).\n",
    "\n",
    "    PyPSA-Earth convention: Carrier 'co2' has co2_emissions = -1.0,\n",
    "    which flips the sign of the dual. Hence price_sign = -1.0.\n",
    "    \"\"\"\n",
    "    idx = net.links.index[net.links.carrier == smr_carrier]\n",
    "    if len(idx) == 0 or not hasattr(net.links_t, \"p2\"):\n",
    "        return 0.0\n",
    "    return bus_price_cost_for_link_port(net, idx, port=\"p2\", bus_col=\"bus2\", price_sign=-1.0)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Infrastructure definition\n",
    "# ============================================================\n",
    "\n",
    "def infra_carriers(\n",
    "    net,\n",
    "    electrolysis_carrier: str = \"H2 Electrolysis\",\n",
    "    smr_carrier: str = \"SMR\",\n",
    "    include_all_h2_infrastructure: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Infrastructure carriers: all H2-like link carriers except production technologies,\n",
    "    plus explicit H2 pipelines.\n",
    "    \"\"\"\n",
    "    pipelines = {\"H2 pipeline\"}\n",
    "    if include_all_h2_infrastructure:\n",
    "        h2_like = set(\n",
    "            net.links.loc[\n",
    "                net.links.carrier.astype(str).str.contains(\"H2\", case=False, na=False),\n",
    "                \"carrier\",\n",
    "            ].unique()\n",
    "        )\n",
    "        return (h2_like - {electrolysis_carrier} - {smr_carrier}) | pipelines\n",
    "    return set(pipelines)\n",
    "\n",
    "\n",
    "def infra_cost_annual(\n",
    "    net,\n",
    "    electrolysis_carrier: str = \"H2 Electrolysis\",\n",
    "    smr_carrier: str = \"SMR\",\n",
    "    include_all_h2_infrastructure: bool = True,\n",
    ") -> float:\n",
    "    \"\"\"Annual infrastructure cost [â¬] (CAPEX + variable OPEX).\"\"\"\n",
    "    infra = infra_carriers(net, electrolysis_carrier, smr_carrier, include_all_h2_infrastructure)\n",
    "    return capex_links(net, infra) + vopex_links(net, infra)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# LCOH breakdowns (â¬/kg H2)\n",
    "# ============================================================\n",
    "\n",
    "def lcoh_electrolysis_breakdown(\n",
    "    net,\n",
    "    electrolysis_carrier: str = \"H2 Electrolysis\",\n",
    "    smr_carrier: str = \"SMR\",\n",
    "    include_all_h2_infrastructure: bool = True,\n",
    ") -> dict:\n",
    "    \"\"\"Electrolysis LCOH breakdown: Electricity, Electrolysis, Infrastructure.\"\"\"\n",
    "    h2_kg = annual_h2_output_kg_from_link_p1(net, electrolysis_carrier)\n",
    "    if h2_kg <= 0:\n",
    "        return {\"Electricity\": 0.0, \"Electrolysis\": 0.0, \"Infrastructure\": 0.0}\n",
    "\n",
    "    elec = electricity_cost_for_electrolysis(net, electrolysis_carrier)\n",
    "    el = capex_links(net, {electrolysis_carrier}) + vopex_links(net, {electrolysis_carrier})\n",
    "    infra = infra_cost_annual(net, electrolysis_carrier, smr_carrier, include_all_h2_infrastructure)\n",
    "\n",
    "    return {\"Electricity\": elec / h2_kg, \"Electrolysis\": el / h2_kg, \"Infrastructure\": infra / h2_kg}\n",
    "\n",
    "\n",
    "def lcoh_smr_breakdown(\n",
    "    net,\n",
    "    smr_carrier: str = \"SMR\",\n",
    "    electrolysis_carrier: str = \"H2 Electrolysis\",\n",
    "    include_all_h2_infrastructure: bool = True,\n",
    ") -> dict:\n",
    "    \"\"\"SMR LCOH breakdown: Gas, SMR, Infrastructure, CO2.\"\"\"\n",
    "    h2_kg = annual_h2_output_kg_from_link_p1(net, smr_carrier)\n",
    "    if h2_kg <= 0:\n",
    "        return {\"Gas\": 0.0, \"SMR\": 0.0, \"Infrastructure\": 0.0, \"CO2\": 0.0}\n",
    "\n",
    "    gas = gas_cost_for_smr(net, smr_carrier)\n",
    "    co2 = co2_cost_for_smr(net, smr_carrier)\n",
    "    smr = capex_links(net, {smr_carrier}) + vopex_links(net, {smr_carrier})\n",
    "    infra = infra_cost_annual(net, electrolysis_carrier, smr_carrier, include_all_h2_infrastructure)\n",
    "\n",
    "    return {\"Gas\": gas / h2_kg, \"SMR\": smr / h2_kg, \"Infrastructure\": infra / h2_kg, \"CO2\": co2 / h2_kg}\n",
    "\n",
    "\n",
    "def system_lcoh_breakdown(\n",
    "    net,\n",
    "    electrolysis_carrier: str = \"H2 Electrolysis\",\n",
    "    smr_carrier: str = \"SMR\",\n",
    "    include_all_h2_infrastructure: bool = True,\n",
    ") -> dict:\n",
    "    \"\"\"System-average LCOH (weighted by total H2 output).\"\"\"\n",
    "    h2_el = annual_h2_output_kg_from_link_p1(net, electrolysis_carrier)\n",
    "    h2_smr = annual_h2_output_kg_from_link_p1(net, smr_carrier)\n",
    "    h2_total = h2_el + h2_smr\n",
    "\n",
    "    if h2_total <= 0:\n",
    "        return {\"Electricity\": 0.0, \"Electrolysis\": 0.0, \"Gas\": 0.0, \"SMR\": 0.0, \"CO2\": 0.0, \"Infrastructure\": 0.0}\n",
    "\n",
    "    elec = electricity_cost_for_electrolysis(net, electrolysis_carrier)\n",
    "    el = capex_links(net, {electrolysis_carrier}) + vopex_links(net, {electrolysis_carrier})\n",
    "\n",
    "    gas = gas_cost_for_smr(net, smr_carrier)\n",
    "    co2 = co2_cost_for_smr(net, smr_carrier)\n",
    "    smr = capex_links(net, {smr_carrier}) + vopex_links(net, {smr_carrier})\n",
    "\n",
    "    infra = infra_cost_annual(net, electrolysis_carrier, smr_carrier, include_all_h2_infrastructure)\n",
    "\n",
    "    return {\n",
    "        \"Electricity\": elec / h2_total,\n",
    "        \"Electrolysis\": el / h2_total,\n",
    "        \"Gas\": gas / h2_total,\n",
    "        \"SMR\": smr / h2_total,\n",
    "        \"CO2\": co2 / h2_total,\n",
    "        \"Infrastructure\": infra / h2_total,\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Plotting (legends below axes)\n",
    "# ============================================================\n",
    "\n",
    "def legend_with_values_and_shares_below(\n",
    "    ax,\n",
    "    df: pd.DataFrame,\n",
    "    order: list,\n",
    "    title_prefix: str = \"Total\",\n",
    "    ncol: int | None = None,\n",
    "    y_offset: float = -0.28,\n",
    "    fontsize: int = 10,\n",
    "    title_fontsize: int = 11,\n",
    "):\n",
    "    \"\"\"\n",
    "    Place a legend below the axis with values and shares for both scenarios.\n",
    "    df index: categories; df columns: ['uhs', 'woUHS'].\n",
    "    \"\"\"\n",
    "    total_uhs = float(df[\"uhs\"].sum())\n",
    "    total_wo = float(df[\"woUHS\"].sum())\n",
    "\n",
    "    handles, labels = [], []\n",
    "    for i, cat in enumerate(order):\n",
    "        u = float(df.loc[cat, \"uhs\"])\n",
    "        w = float(df.loc[cat, \"woUHS\"])\n",
    "        u_pct = 100 * u / total_uhs if total_uhs > 0 else 0.0\n",
    "        w_pct = 100 * w / total_wo if total_wo > 0 else 0.0\n",
    "\n",
    "        handles.append(ax.patches[i * 2])  # first bar patch of this stack\n",
    "        labels.append(f\"{cat} ({u:.2f} â¬/kg, {u_pct:.1f}% / {w:.2f} â¬/kg, {w_pct:.1f}%)\")\n",
    "\n",
    "    if ncol is None:\n",
    "        ncol = min(len(order), 3)\n",
    "\n",
    "    ax.legend(\n",
    "        handles,\n",
    "        labels,\n",
    "        title=f\"{title_prefix}: uhs {total_uhs:.2f} â¬/kg / woUHS {total_wo:.2f} â¬/kg\",\n",
    "        loc=\"upper center\",\n",
    "        bbox_to_anchor=(0.5, y_offset),\n",
    "        ncol=ncol,\n",
    "        frameon=True,\n",
    "        fontsize=fontsize,\n",
    "        title_fontsize=title_fontsize,\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_stacked_two_scenarios(\n",
    "    ax,\n",
    "    data_uhs: dict,\n",
    "    data_wo: dict,\n",
    "    categories: list,\n",
    "    title: str,\n",
    "    ylabel: str | None = None,\n",
    "):\n",
    "    \"\"\"Draw a stacked bar chart for uhs vs woUHS with totals annotated.\"\"\"\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"uhs\": pd.Series(data_uhs).reindex(categories).fillna(0.0),\n",
    "            \"woUHS\": pd.Series(data_wo).reindex(categories).fillna(0.0),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    x = np.arange(2)\n",
    "    bottom = np.zeros(2)\n",
    "\n",
    "    for cat in categories:\n",
    "        vals = df.loc[cat, [\"uhs\", \"woUHS\"]].values.astype(float)\n",
    "        ax.bar(x, vals, bottom=bottom)\n",
    "        bottom += vals\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([\"uhs\", \"woUHS\"])\n",
    "    ax.set_title(title)\n",
    "    ax.grid(axis=\"y\", alpha=0.30)\n",
    "    if ylabel:\n",
    "        ax.set_ylabel(ylabel)\n",
    "\n",
    "    ax.text(0, bottom[0], f\"{bottom[0]:.2f}\", ha=\"center\", va=\"bottom\")\n",
    "    ax.text(1, bottom[1], f\"{bottom[1]:.2f}\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Run (expects: uhs and woUHS networks exist)\n",
    "# ============================================================\n",
    "\n",
    "# --- Compute breakdowns\n",
    "el_uhs = lcoh_electrolysis_breakdown(uhs, electrolysis_carrier=\"H2 Electrolysis\", smr_carrier=\"SMR\", include_all_h2_infrastructure=True)\n",
    "el_wo = lcoh_electrolysis_breakdown(woUHS, electrolysis_carrier=\"H2 Electrolysis\", smr_carrier=\"SMR\", include_all_h2_infrastructure=True)\n",
    "\n",
    "smr_uhs = lcoh_smr_breakdown(uhs, smr_carrier=\"SMR\", electrolysis_carrier=\"H2 Electrolysis\", include_all_h2_infrastructure=True)\n",
    "smr_wo = lcoh_smr_breakdown(woUHS, smr_carrier=\"SMR\", electrolysis_carrier=\"H2 Electrolysis\", include_all_h2_infrastructure=True)\n",
    "\n",
    "sys_uhs = system_lcoh_breakdown(uhs, electrolysis_carrier=\"H2 Electrolysis\", smr_carrier=\"SMR\", include_all_h2_infrastructure=True)\n",
    "sys_wo = system_lcoh_breakdown(woUHS, electrolysis_carrier=\"H2 Electrolysis\", smr_carrier=\"SMR\", include_all_h2_infrastructure=True)\n",
    "\n",
    "# ============================================================\n",
    "# Plot 1: two subplots (legends below each subplot)\n",
    "# ============================================================\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\n",
    "\n",
    "cats_el = [\"Electricity\", \"Electrolysis\", \"Infrastructure\"]\n",
    "df_el = plot_stacked_two_scenarios(\n",
    "    axes[0], el_uhs, el_wo, cats_el,\n",
    "    title=\"LCOH â H2 Electrolysis\",\n",
    "    ylabel=\"â¬/kg Hâ\",\n",
    ")\n",
    "legend_with_values_and_shares_below(axes[0], df_el, cats_el, ncol=1, y_offset=-0.30)\n",
    "\n",
    "cats_smr = [\"Gas\", \"SMR\", \"Infrastructure\", \"CO2\"]\n",
    "df_smr = plot_stacked_two_scenarios(\n",
    "    axes[1], smr_uhs, smr_wo, cats_smr,\n",
    "    title=\"LCOH â SMR\",\n",
    "    ylabel=None,\n",
    ")\n",
    "legend_with_values_and_shares_below(axes[1], df_smr, cats_smr, ncol=2, y_offset=-0.30)\n",
    "\n",
    "# Make room for legends beneath subplots\n",
    "fig.subplots_adjust(bottom=0.28, wspace=0.25)\n",
    "plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# Plot 2: system plot (legend below)\n",
    "# ============================================================\n",
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "\n",
    "cats_sys = [\"Electricity\", \"Electrolysis\", \"Gas\", \"SMR\", \"CO2\", \"Infrastructure\"]\n",
    "df_sys = plot_stacked_two_scenarios(\n",
    "    ax, sys_uhs, sys_wo, cats_sys,\n",
    "    title=\"System LCOH (Electrolysis + SMR)\",\n",
    "    ylabel=\"â¬/kg Hâ\",\n",
    ")\n",
    "\n",
    "legend_with_values_and_shares_below(ax, df_sys, cats_sys, ncol=3, y_offset=-0.32)\n",
    "\n",
    "# Make room for legend beneath the plot\n",
    "fig.subplots_adjust(bottom=0.30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a4f0b6",
   "metadata": {},
   "source": [
    "##### CAPEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb90f241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def snapshot_weights(net) -> pd.Series:\n",
    "    \"\"\"Return snapshot weights (defaults to 1.0 if not available).\"\"\"\n",
    "    sw = getattr(net, \"snapshot_weightings\", None)\n",
    "    if sw is not None:\n",
    "        try:\n",
    "            if \"generators\" in sw:\n",
    "                return sw[\"generators\"]\n",
    "        except Exception:\n",
    "            pass\n",
    "    return pd.Series(1.0, index=net.snapshots)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Generic CAPEX utilities\n",
    "# ============================================================\n",
    "\n",
    "def capex_links(net, carriers) -> float:\n",
    "    \"\"\"Annualized CAPEX contribution for link carriers (already annualized in capital_cost).\"\"\"\n",
    "    links = net.links[net.links.carrier.isin(carriers)]\n",
    "    if links.empty:\n",
    "        return 0.0\n",
    "    p_nom = links[\"p_nom_opt\"] if \"p_nom_opt\" in links.columns else links[\"p_nom\"]\n",
    "    return float((p_nom * links[\"capital_cost\"]).fillna(0.0).sum())\n",
    "\n",
    "\n",
    "def capex_generators(net) -> float:\n",
    "    \"\"\"Annualized CAPEX for all generators.\"\"\"\n",
    "    gens = net.generators\n",
    "    if gens.empty:\n",
    "        return 0.0\n",
    "    p_nom = gens[\"p_nom_opt\"] if \"p_nom_opt\" in gens.columns else gens[\"p_nom\"]\n",
    "    return float((p_nom * gens[\"capital_cost\"]).fillna(0.0).sum())\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Electricity CAPEX allocation by energy share\n",
    "# ============================================================\n",
    "\n",
    "def _electricity_consumption_mwh(net, link_idx, port=\"p0\") -> float:\n",
    "    \"\"\"\n",
    "    Return annual electricity consumption [MWh] for the given links at the given port.\n",
    "    Sign-robust: chooses p vs -p that yields larger aggregate positive consumption.\n",
    "    \"\"\"\n",
    "    if len(link_idx) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    w = snapshot_weights(net)\n",
    "    p = getattr(net.links_t, port)[link_idx]  # MW\n",
    "\n",
    "    cons_pos = (p.clip(lower=0).mul(w, axis=0)).sum().sum()\n",
    "    cons_neg = ((-p).clip(lower=0).mul(w, axis=0)).sum().sum()\n",
    "    cons = p.clip(lower=0) if cons_pos >= cons_neg else (-p).clip(lower=0)\n",
    "\n",
    "    return float((cons.mul(w, axis=0)).sum().sum())\n",
    "\n",
    "\n",
    "def electricity_capex_allocated(net, electricity_consumption_mwh: float) -> float:\n",
    "    \"\"\"\n",
    "    Allocate total generator CAPEX proportionally to a given electricity consumption [MWh].\n",
    "    Returns allocated generator CAPEX [â¬].\n",
    "    \"\"\"\n",
    "    if electricity_consumption_mwh <= 0:\n",
    "        return 0.0\n",
    "\n",
    "    w = snapshot_weights(net)\n",
    "    gens = net.generators\n",
    "    if gens.empty:\n",
    "        return 0.0\n",
    "\n",
    "    p = net.generators_t.p[gens.index]          # MW\n",
    "    e_gen = (p.mul(w, axis=0)).sum().sum()      # total MWh from all generators\n",
    "    if e_gen <= 0:\n",
    "        return 0.0\n",
    "\n",
    "    share = electricity_consumption_mwh / float(e_gen)\n",
    "    return capex_generators(net) * share\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Infrastructure carrier set (shared definition)\n",
    "# ============================================================\n",
    "\n",
    "def infra_carriers(\n",
    "    net,\n",
    "    electrolysis_carrier=\"H2 Electrolysis\",\n",
    "    smr_carrier=\"SMR\",\n",
    "    include_all_h2_infrastructure=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Infrastructure carriers: all H2-like link carriers except production technologies,\n",
    "    plus explicit H2 pipelines.\n",
    "    \"\"\"\n",
    "    pipelines = {\"H2 pipeline\"}\n",
    "    if include_all_h2_infrastructure:\n",
    "        h2_like = set(\n",
    "            net.links.loc[\n",
    "                net.links.carrier.astype(str).str.contains(\"H2\", case=False, na=False),\n",
    "                \"carrier\",\n",
    "            ].unique()\n",
    "        )\n",
    "        return (h2_like - {electrolysis_carrier} - {smr_carrier}) | pipelines\n",
    "    return set(pipelines)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CAPEX breakdowns (technology-specific and combined)\n",
    "# ============================================================\n",
    "\n",
    "def capex_breakdown_electrolysis(\n",
    "    net,\n",
    "    electrolysis_carrier=\"H2 Electrolysis\",\n",
    "    smr_carrier=\"SMR\",\n",
    "    include_all_h2_infrastructure=True,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    CAPEX breakdown attributed to electrolysis pathway:\n",
    "      - Electricity (allocated generator CAPEX via electrolysis electricity consumption)\n",
    "      - Electrolysis (electrolyser link CAPEX)\n",
    "      - Infrastructure (H2 infra link CAPEX)\n",
    "    \"\"\"\n",
    "    el_idx = net.links.index[net.links.carrier == electrolysis_carrier]\n",
    "    e_el_mwh = _electricity_consumption_mwh(net, el_idx, port=\"p0\")\n",
    "    elec_capex = electricity_capex_allocated(net, e_el_mwh)\n",
    "\n",
    "    infra = infra_carriers(net, electrolysis_carrier, smr_carrier, include_all_h2_infrastructure)\n",
    "\n",
    "    return {\n",
    "        \"Electricity\": elec_capex,\n",
    "        \"Electrolysis\": capex_links(net, {electrolysis_carrier}),\n",
    "        \"Infrastructure\": capex_links(net, infra),\n",
    "    }\n",
    "\n",
    "\n",
    "def capex_breakdown_smr(\n",
    "    net,\n",
    "    smr_carrier=\"SMR\",\n",
    "    electrolysis_carrier=\"H2 Electrolysis\",\n",
    "    include_all_h2_infrastructure=True,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    CAPEX breakdown attributed to SMR pathway:\n",
    "      - Gas supply (allocated generator CAPEX via SMR gas-bus consumption is NOT electricity;\n",
    "        therefore excluded here by design)\n",
    "      - SMR (SMR link CAPEX)\n",
    "      - Infrastructure (H2 infra link CAPEX)\n",
    "      - CO2 network/handling is excluded unless it is part of H2-like infra in your model\n",
    "    \"\"\"\n",
    "    infra = infra_carriers(net, electrolysis_carrier, smr_carrier, include_all_h2_infrastructure)\n",
    "\n",
    "    return {\n",
    "        \"SMR\": capex_links(net, {smr_carrier}),\n",
    "        \"Infrastructure\": capex_links(net, infra),\n",
    "    }\n",
    "\n",
    "\n",
    "def capex_breakdown_system(\n",
    "    net,\n",
    "    electrolysis_carrier=\"H2 Electrolysis\",\n",
    "    smr_carrier=\"SMR\",\n",
    "    include_all_h2_infrastructure=True,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Combined H2 system CAPEX breakdown:\n",
    "      - Electricity (allocated generator CAPEX via electrolysis electricity consumption)\n",
    "      - Electrolysis (electrolyser link CAPEX)\n",
    "      - SMR (SMR link CAPEX)\n",
    "      - Infrastructure (H2 infra link CAPEX)\n",
    "    \"\"\"\n",
    "    el = capex_breakdown_electrolysis(net, electrolysis_carrier, smr_carrier, include_all_h2_infrastructure)\n",
    "    smr = capex_breakdown_smr(net, smr_carrier, electrolysis_carrier, include_all_h2_infrastructure)\n",
    "\n",
    "    return {\n",
    "        \"Electricity\": el[\"Electricity\"],\n",
    "        \"Electrolysis\": el[\"Electrolysis\"],\n",
    "        \"SMR\": smr[\"SMR\"],\n",
    "        \"Infrastructure\": el[\"Infrastructure\"],  # same definition; do not double count\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Plotting utilities (legends below)\n",
    "# ============================================================\n",
    "\n",
    "def format_bn_eur(x, _pos):\n",
    "    return f\"{x/1e9:.0f}\"\n",
    "\n",
    "\n",
    "def plot_stacked_two_scenarios_capex(ax, data_uhs, data_wo, categories, title, ylabel=None):\n",
    "    \"\"\"\n",
    "    Stacked CAPEX bars for uhs vs woUHS.\n",
    "    Values are in â¬, legend reports bn â¬ and shares.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"uhs\": pd.Series(data_uhs).reindex(categories).fillna(0.0),\n",
    "            \"woUHS\": pd.Series(data_wo).reindex(categories).fillna(0.0),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    x = np.arange(2)\n",
    "    bottom = np.zeros(2)\n",
    "\n",
    "    for cat in categories:\n",
    "        vals = df.loc[cat, [\"uhs\", \"woUHS\"]].values.astype(float)\n",
    "        ax.bar(x, vals, bottom=bottom)\n",
    "        bottom += vals\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([\"uhs 2050\", \"woUHS 2050\"])\n",
    "    ax.set_title(title)\n",
    "    ax.grid(axis=\"y\", alpha=0.30)\n",
    "\n",
    "    if ylabel:\n",
    "        ax.set_ylabel(ylabel)\n",
    "\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(lambda x, _: f\"{x/1e9:.0f}\"))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def legend_with_values_and_shares_below(ax, df, order, title_prefix=\"Total\", ncol=None, y_offset=-0.28):\n",
    "    \"\"\"\n",
    "    Legend below the axis with absolute CAPEX (bn â¬) and shares.\n",
    "    df columns: ['uhs','woUHS'] in â¬.\n",
    "    \"\"\"\n",
    "    total_uhs = float(df[\"uhs\"].sum())\n",
    "    total_wo = float(df[\"woUHS\"].sum())\n",
    "\n",
    "    handles, labels = [], []\n",
    "    for i, cat in enumerate(order):\n",
    "        u = float(df.loc[cat, \"uhs\"])\n",
    "        w = float(df.loc[cat, \"woUHS\"])\n",
    "        u_pct = 100 * u / total_uhs if total_uhs > 0 else 0.0\n",
    "        w_pct = 100 * w / total_wo if total_wo > 0 else 0.0\n",
    "\n",
    "        handles.append(ax.patches[i * 2])\n",
    "        labels.append(f\"{cat} ({u/1e9:.1f} bn â¬, {u_pct:.1f}% / {w/1e9:.1f} bn â¬, {w_pct:.1f}%)\")\n",
    "\n",
    "    if ncol is None:\n",
    "        ncol = min(len(order), 3)\n",
    "\n",
    "    ax.legend(\n",
    "        handles,\n",
    "        labels,\n",
    "        title=f\"{title_prefix}: uhs {total_uhs/1e9:.1f} bn â¬ / woUHS {total_wo/1e9:.1f} bn â¬\",\n",
    "        loc=\"upper center\",\n",
    "        bbox_to_anchor=(0.5, y_offset),\n",
    "        ncol=ncol,\n",
    "        frameon=True,\n",
    "    )\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Compute CAPEX breakdowns for both scenarios\n",
    "# ============================================================\n",
    "\n",
    "# Electrolysis vs SMR (separate)\n",
    "capex_el_uhs = capex_breakdown_electrolysis(uhs, electrolysis_carrier=\"H2 Electrolysis\", smr_carrier=\"SMR\", include_all_h2_infrastructure=True)\n",
    "capex_el_wo  = capex_breakdown_electrolysis(woUHS, electrolysis_carrier=\"H2 Electrolysis\", smr_carrier=\"SMR\", include_all_h2_infrastructure=True)\n",
    "\n",
    "capex_smr_uhs = capex_breakdown_smr(uhs, smr_carrier=\"SMR\", electrolysis_carrier=\"H2 Electrolysis\", include_all_h2_infrastructure=True)\n",
    "capex_smr_wo  = capex_breakdown_smr(woUHS, smr_carrier=\"SMR\", electrolysis_carrier=\"H2 Electrolysis\", include_all_h2_infrastructure=True)\n",
    "\n",
    "# Combined system\n",
    "capex_sys_uhs = capex_breakdown_system(uhs, electrolysis_carrier=\"H2 Electrolysis\", smr_carrier=\"SMR\", include_all_h2_infrastructure=True)\n",
    "capex_sys_wo  = capex_breakdown_system(woUHS, electrolysis_carrier=\"H2 Electrolysis\", smr_carrier=\"SMR\", include_all_h2_infrastructure=True)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Plot A: Electrolysis and SMR side-by-side (two subplots)\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\n",
    "\n",
    "cats_el = [\"Electricity\", \"Electrolysis\", \"Infrastructure\"]\n",
    "df_el = plot_stacked_two_scenarios_capex(\n",
    "    axes[0], capex_el_uhs, capex_el_wo, cats_el,\n",
    "    title=\"CAPEX â H2 Electrolysis (incl. allocated electricity supply)\",\n",
    "    ylabel=\"CAPEX [bn â¬]\"\n",
    ")\n",
    "legend_with_values_and_shares_below(axes[0], df_el, cats_el, ncol=1, y_offset=-0.30)\n",
    "\n",
    "cats_smr = [\"SMR\", \"Infrastructure\"]\n",
    "df_smr = plot_stacked_two_scenarios_capex(\n",
    "    axes[1], capex_smr_uhs, capex_smr_wo, cats_smr,\n",
    "    title=\"CAPEX â SMR (H2-related CAPEX only)\",\n",
    "    ylabel=None\n",
    ")\n",
    "legend_with_values_and_shares_below(axes[1], df_smr, cats_smr, ncol=1, y_offset=-0.30)\n",
    "\n",
    "fig.subplots_adjust(bottom=0.30, wspace=0.25)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Plot B: Combined system CAPEX (single plot)\n",
    "# ============================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "\n",
    "cats_sys = [\"Electricity\", \"Electrolysis\", \"SMR\", \"Infrastructure\"]\n",
    "df_sys = plot_stacked_two_scenarios_capex(\n",
    "    ax, capex_sys_uhs, capex_sys_wo, cats_sys,\n",
    "    title=\"CAPEX â H2 System (Electrolysis + SMR)\",\n",
    "    ylabel=\"CAPEX [bn â¬]\"\n",
    ")\n",
    "legend_with_values_and_shares_below(ax, df_sys, cats_sys, ncol=2, y_offset=-0.32)\n",
    "\n",
    "fig.subplots_adjust(bottom=0.32)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd4cef8",
   "metadata": {},
   "source": [
    "##### OPEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9e1abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Snapshot weights\n",
    "# ============================================================\n",
    "\n",
    "def snapshot_weights(net) -> pd.Series:\n",
    "    \"\"\"Return snapshot weights (defaults to 1.0 if not available).\"\"\"\n",
    "    sw = getattr(net, \"snapshot_weightings\", None)\n",
    "    if sw is not None:\n",
    "        try:\n",
    "            if \"generators\" in sw:\n",
    "                return sw[\"generators\"]\n",
    "        except Exception:\n",
    "            pass\n",
    "    return pd.Series(1.0, index=net.snapshots)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Generic: price * consumption at a link port (sign-robust)\n",
    "# ============================================================\n",
    "\n",
    "def bus_price_cost_for_link_port(\n",
    "    net,\n",
    "    link_idx,\n",
    "    port: str = \"p0\",\n",
    "    bus_col: str = \"bus0\",\n",
    "    price_sign: float = +1.0,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Annual cost [â¬] = sum_t( consumption_MW * weight * (price_sign * marginal_price(bus)) )\n",
    "\n",
    "    Sign-robust: choose p vs -p with larger aggregate positive consumption.\n",
    "    price_sign flips sign if the dual convention is inverted (CO2 in PyPSA-Earth).\n",
    "    \"\"\"\n",
    "    if not hasattr(net, \"buses_t\") or not hasattr(net.buses_t, \"marginal_price\"):\n",
    "        raise ValueError(\"net.buses_t.marginal_price not found.\")\n",
    "\n",
    "    if len(link_idx) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    w = snapshot_weights(net)\n",
    "    p = getattr(net.links_t, port)[link_idx]  # MW, snapshots x links\n",
    "\n",
    "    cons_pos = (p.clip(lower=0).mul(w, axis=0)).sum().sum()\n",
    "    cons_neg = ((-p).clip(lower=0).mul(w, axis=0)).sum().sum()\n",
    "    cons = p.clip(lower=0) if cons_pos >= cons_neg else (-p).clip(lower=0)\n",
    "\n",
    "    buses = net.links.loc[link_idx, bus_col]\n",
    "    price_mat = pd.DataFrame({lid: net.buses_t.marginal_price[bus] for lid, bus in buses.items()})\n",
    "\n",
    "    return float(((cons.mul(w, axis=0)) * (price_sign * price_mat)).sum().sum())\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Link OPEX via marginal_cost * throughput\n",
    "# ============================================================\n",
    "\n",
    "def link_opex(net, carriers) -> float:\n",
    "    \"\"\"Variable link OPEX: marginal_cost [â¬/MWh] * |p0| throughput [MWh].\"\"\"\n",
    "    links = net.links[net.links.carrier.isin(carriers)]\n",
    "    if links.empty:\n",
    "        return 0.0\n",
    "\n",
    "    w = snapshot_weights(net)\n",
    "    mc = links[\"marginal_cost\"].fillna(0.0)     # â¬/MWh\n",
    "    p0 = net.links_t.p0[links.index]            # MW\n",
    "    e = (p0.abs().mul(w, axis=0)).sum()         # MWh per link-year\n",
    "\n",
    "    return float((e * mc).sum())\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Infrastructure definition\n",
    "# ============================================================\n",
    "\n",
    "def infra_carriers(\n",
    "    net,\n",
    "    electrolysis_carrier=\"H2 Electrolysis\",\n",
    "    smr_carrier=\"SMR\",\n",
    "    include_all_h2_infrastructure=True,\n",
    "):\n",
    "    \"\"\"H2-related infrastructure carriers excluding production technologies.\"\"\"\n",
    "    pipelines = {\"H2 pipeline\"}\n",
    "    if include_all_h2_infrastructure:\n",
    "        h2_like = set(\n",
    "            net.links.loc[\n",
    "                net.links.carrier.astype(str).str.contains(\"H2\", case=False, na=False),\n",
    "                \"carrier\",\n",
    "            ].unique()\n",
    "        )\n",
    "        return (h2_like - {electrolysis_carrier} - {smr_carrier}) | pipelines\n",
    "    return set(pipelines)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Electricity OPEX for electrolysis (price-based, consistent with LCOH)\n",
    "# ============================================================\n",
    "\n",
    "def electricity_opex_for_electrolysis_price(net, electrolysis_carrier=\"H2 Electrolysis\") -> float:\n",
    "    \"\"\"Annual electricity procurement cost [â¬] for electrolysis using nodal marginal prices at bus0.\"\"\"\n",
    "    idx = net.links.index[net.links.carrier == electrolysis_carrier]\n",
    "    if len(idx) == 0:\n",
    "        return 0.0\n",
    "    return bus_price_cost_for_link_port(net, idx, port=\"p0\", bus_col=\"bus0\", price_sign=+1.0)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Gas OPEX for SMR (price-based at gas bus0)\n",
    "# ============================================================\n",
    "\n",
    "def gas_opex_for_smr_price(net, smr_carrier=\"SMR\") -> float:\n",
    "    \"\"\"Annual gas procurement cost [â¬] for SMR using nodal marginal prices at gas bus0.\"\"\"\n",
    "    idx = net.links.index[net.links.carrier == smr_carrier]\n",
    "    if len(idx) == 0:\n",
    "        return 0.0\n",
    "    return bus_price_cost_for_link_port(net, idx, port=\"p0\", bus_col=\"bus0\", price_sign=+1.0)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# OPEX breakdowns\n",
    "# ============================================================\n",
    "\n",
    "def opex_breakdown_electrolysis(\n",
    "    net,\n",
    "    electrolysis_carrier=\"H2 Electrolysis\",\n",
    "    smr_carrier=\"SMR\",\n",
    "    include_all_h2_infrastructure=True,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    OPEX attributed to electrolysis pathway:\n",
    "      - Electricity: price-based procurement cost at bus0 (preferred for interpretability)\n",
    "      - Electrolysis: link marginal_cost-based OPEX\n",
    "      - Infrastructure: H2 infra marginal_cost-based OPEX\n",
    "    \"\"\"\n",
    "    infra = infra_carriers(net, electrolysis_carrier, smr_carrier, include_all_h2_infrastructure)\n",
    "\n",
    "    return {\n",
    "        \"Electricity\": electricity_opex_for_electrolysis_price(net, electrolysis_carrier),\n",
    "        \"Electrolysis\": link_opex(net, {electrolysis_carrier}),\n",
    "        \"Infrastructure\": link_opex(net, infra),\n",
    "    }\n",
    "\n",
    "\n",
    "def opex_breakdown_smr(\n",
    "    net,\n",
    "    smr_carrier=\"SMR\",\n",
    "    electrolysis_carrier=\"H2 Electrolysis\",\n",
    "    include_all_h2_infrastructure=True,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    OPEX attributed to SMR pathway:\n",
    "      - Gas: price-based gas procurement cost at SMR bus0\n",
    "      - SMR: link marginal_cost-based OPEX (typically variable O&M)\n",
    "      - Infrastructure: H2 infra marginal_cost-based OPEX\n",
    "    \"\"\"\n",
    "    infra = infra_carriers(net, electrolysis_carrier, smr_carrier, include_all_h2_infrastructure)\n",
    "\n",
    "    return {\n",
    "        \"Gas\": gas_opex_for_smr_price(net, smr_carrier),\n",
    "        \"SMR\": link_opex(net, {smr_carrier}),\n",
    "        \"Infrastructure\": link_opex(net, infra),\n",
    "    }\n",
    "\n",
    "\n",
    "def opex_breakdown_system(\n",
    "    net,\n",
    "    electrolysis_carrier=\"H2 Electrolysis\",\n",
    "    smr_carrier=\"SMR\",\n",
    "    include_all_h2_infrastructure=True,\n",
    ") -> dict:\n",
    "    \"\"\"Combined hydrogen system OPEX (no double counting of infrastructure).\"\"\"\n",
    "    el = opex_breakdown_electrolysis(net, electrolysis_carrier, smr_carrier, include_all_h2_infrastructure)\n",
    "    smr = opex_breakdown_smr(net, smr_carrier, electrolysis_carrier, include_all_h2_infrastructure)\n",
    "\n",
    "    return {\n",
    "        \"Electricity\": el[\"Electricity\"],\n",
    "        \"Electrolysis\": el[\"Electrolysis\"],\n",
    "        \"Gas\": smr[\"Gas\"],\n",
    "        \"SMR\": smr[\"SMR\"],\n",
    "        \"Infrastructure\": el[\"Infrastructure\"],\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Plot helpers (legends below, no labels on bars)\n",
    "# ============================================================\n",
    "\n",
    "def plot_stacked_two_scenarios_opex(ax, data_uhs, data_wo, categories, title, ylabel=None):\n",
    "    \"\"\"Stacked OPEX bars for uhs vs woUHS. Values in â¬.\"\"\"\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"uhs\": pd.Series(data_uhs).reindex(categories).fillna(0.0),\n",
    "            \"woUHS\": pd.Series(data_wo).reindex(categories).fillna(0.0),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    x = np.arange(2)\n",
    "    bottom = np.zeros(2)\n",
    "\n",
    "    for cat in categories:\n",
    "        vals = df.loc[cat, [\"uhs\", \"woUHS\"]].values.astype(float)\n",
    "        ax.bar(x, vals, bottom=bottom)\n",
    "        bottom += vals\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([\"uhs 2050\", \"woUHS 2050\"])\n",
    "    ax.set_title(title)\n",
    "    ax.grid(axis=\"y\", alpha=0.30)\n",
    "    if ylabel:\n",
    "        ax.set_ylabel(ylabel)\n",
    "\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(lambda x, _: f\"{x/1e6:.0f}\"))\n",
    "    return df\n",
    "\n",
    "\n",
    "def legend_with_values_and_shares_below(ax, df, order, title_prefix=\"Total\", ncol=None, y_offset=-0.28):\n",
    "    \"\"\"Legend below axis with absolute OPEX (Mio â¬) and shares.\"\"\"\n",
    "    total_uhs = float(df[\"uhs\"].sum())\n",
    "    total_wo = float(df[\"woUHS\"].sum())\n",
    "\n",
    "    handles, labels = [], []\n",
    "    for i, cat in enumerate(order):\n",
    "        u = float(df.loc[cat, \"uhs\"])\n",
    "        w = float(df.loc[cat, \"woUHS\"])\n",
    "        u_pct = 100 * u / total_uhs if total_uhs > 0 else 0.0\n",
    "        w_pct = 100 * w / total_wo if total_wo > 0 else 0.0\n",
    "\n",
    "        handles.append(ax.patches[i * 2])\n",
    "        labels.append(f\"{cat} ({u/1e6:.0f} Mio â¬, {u_pct:.1f}% / {w/1e6:.0f} Mio â¬, {w_pct:.1f}%)\")\n",
    "\n",
    "    if ncol is None:\n",
    "        ncol = min(len(order), 3)\n",
    "\n",
    "    ax.legend(\n",
    "        handles,\n",
    "        labels,\n",
    "        title=f\"{title_prefix}: uhs {total_uhs/1e6:.0f} Mio â¬ / woUHS {total_wo/1e6:.0f} Mio â¬\",\n",
    "        loc=\"upper center\",\n",
    "        bbox_to_anchor=(0.5, y_offset),\n",
    "        ncol=ncol,\n",
    "        frameon=True,\n",
    "    )\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Compute OPEX breakdowns\n",
    "# ============================================================\n",
    "\n",
    "opex_el_uhs = opex_breakdown_electrolysis(uhs)\n",
    "opex_el_wo  = opex_breakdown_electrolysis(woUHS)\n",
    "\n",
    "opex_smr_uhs = opex_breakdown_smr(uhs)\n",
    "opex_smr_wo  = opex_breakdown_smr(woUHS)\n",
    "\n",
    "opex_sys_uhs = opex_breakdown_system(uhs)\n",
    "opex_sys_wo  = opex_breakdown_system(woUHS)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Plot A: Electrolysis vs SMR\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\n",
    "\n",
    "cats_el = [\"Electricity\", \"Electrolysis\", \"Infrastructure\"]\n",
    "df_el = plot_stacked_two_scenarios_opex(\n",
    "    axes[0], opex_el_uhs, opex_el_wo, cats_el,\n",
    "    title=\"OPEX â H2 Electrolysis\",\n",
    "    ylabel=\"OPEX [Mio â¬]\"\n",
    ")\n",
    "legend_with_values_and_shares_below(axes[0], df_el, cats_el, ncol=1, y_offset=-0.30)\n",
    "\n",
    "cats_smr = [\"Gas\", \"SMR\", \"Infrastructure\"]\n",
    "df_smr = plot_stacked_two_scenarios_opex(\n",
    "    axes[1], opex_smr_uhs, opex_smr_wo, cats_smr,\n",
    "    title=\"OPEX â SMR\",\n",
    ")\n",
    "legend_with_values_and_shares_below(axes[1], df_smr, cats_smr, ncol=1, y_offset=-0.30)\n",
    "\n",
    "fig.subplots_adjust(bottom=0.30, wspace=0.25)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Plot B: Combined system OPEX\n",
    "# ============================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "\n",
    "cats_sys = [\"Electricity\", \"Electrolysis\", \"Gas\", \"SMR\", \"Infrastructure\"]\n",
    "df_sys = plot_stacked_two_scenarios_opex(\n",
    "    ax, opex_sys_uhs, opex_sys_wo, cats_sys,\n",
    "    title=\"OPEX â H2 System (Electrolysis + SMR)\",\n",
    "    ylabel=\"OPEX [Mio â¬]\"\n",
    ")\n",
    "legend_with_values_and_shares_below(ax, df_sys, cats_sys, ncol=2, y_offset=-0.32)\n",
    "\n",
    "fig.subplots_adjust(bottom=0.32)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c47b5c",
   "metadata": {},
   "source": [
    "##### Supply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe596dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _snapshot_weights(net):\n",
    "    if hasattr(net, \"snapshot_weightings\") and net.snapshot_weightings is not None:\n",
    "        try:\n",
    "            if \"generators\" in net.snapshot_weightings:\n",
    "                return net.snapshot_weightings[\"generators\"]\n",
    "        except Exception:\n",
    "            pass\n",
    "    return pd.Series(1.0, index=net.snapshots)\n",
    "\n",
    "def hydrogen_supply_by_tech(net, h2_lhv_kwh_per_kg=33.33):\n",
    "    \"\"\"\n",
    "    H2 supply by technology (carrier) from NON-H2 -> H2 links.\n",
    "    Robust to PyPSA link sign conventions.\n",
    "    \"\"\"\n",
    "    w = _snapshot_weights(net)\n",
    "\n",
    "    # Identify H2 buses\n",
    "    h2_buses = net.buses.index[net.buses.carrier == \"H2\"]\n",
    "    if len(h2_buses) == 0:\n",
    "        raise ValueError(\"No H2 buses found (carrier == 'H2').\")\n",
    "\n",
    "    # Links feeding into H2\n",
    "    cand = net.links[net.links.bus1.isin(h2_buses)].copy()\n",
    "\n",
    "    # Exclude H2->H2 transport (pipelines)\n",
    "    supply_links = cand[~cand.bus0.isin(h2_buses)].copy()\n",
    "    if supply_links.empty:\n",
    "        raise ValueError(\"No NON-H2 -> H2 supply links found.\")\n",
    "\n",
    "    # Annual H2 energy into H2 bus (ABS handles sign conventions)\n",
    "    p1 = net.links_t.p1[supply_links.index]     # MW\n",
    "    e_mwh = (p1.abs().mul(w, axis=0)).sum()     # MWh/a per link\n",
    "\n",
    "    # Aggregate by technology\n",
    "    e_mwh_by_carrier = e_mwh.groupby(supply_links[\"carrier\"]).sum()\n",
    "\n",
    "    # Convert units\n",
    "    e_twh = e_mwh_by_carrier / 1e6\n",
    "    e_kwh = e_mwh_by_carrier * 1_000.0\n",
    "    mt_h2 = (e_kwh / h2_lhv_kwh_per_kg) / 1e9\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"Supply [TWh_H2]\": e_twh,\n",
    "        \"Supply [Mt_H2]\": mt_h2,\n",
    "    }).sort_values(\"Supply [TWh_H2]\", ascending=False)\n",
    "\n",
    "\n",
    "supply_uhs = hydrogen_supply_by_tech(uhs)\n",
    "supply_woUHS = hydrogen_supply_by_tech(woUHS)\n",
    "\n",
    "techs = sorted(set(supply_uhs.index) | set(supply_woUHS.index))\n",
    "\n",
    "plot_df = pd.DataFrame({\n",
    "    \"uhs 2050 [TWh_H2]\": supply_uhs.reindex(techs)[\"Supply [TWh_H2]\"].fillna(0.0),\n",
    "    \"woUHS 2050 [TWh_H2]\": supply_woUHS.reindex(techs)[\"Supply [TWh_H2]\"].fillna(0.0),\n",
    "})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "x = np.arange(len(plot_df.index))\n",
    "width = 0.4\n",
    "\n",
    "vals_uhs = plot_df[\"uhs 2050 [TWh_H2]\"].values\n",
    "vals_woUHS = plot_df[\"woUHS 2050 [TWh_H2]\"].values\n",
    "\n",
    "bars_d = ax.bar(x - width/2, vals_uhs, width=width, label=\"uhs 2050\")\n",
    "bars_w = ax.bar(x + width/2, vals_woUHS, width=width, label=\"woUHS 2050\")\n",
    "\n",
    "# Axis formatting\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(plot_df.index, rotation=20, ha=\"right\")\n",
    "ax.set_ylabel(\"Hydrogen supply [TWh$_{H2}$/a]\")\n",
    "ax.set_title(\"Hydrogen supply by technology â 2050\")\n",
    "ymax = max(vals_uhs.max(), vals_woUHS.max())\n",
    "ax.set_ylim(0, ymax * 1.15)\n",
    "ax.legend()\n",
    "\n",
    "# Totals for percentages\n",
    "total_d = vals_uhs.sum()\n",
    "total_w = vals_woUHS.sum()\n",
    "\n",
    "# ---------- annotate bars ----------\n",
    "def annotate_bars(bars, total):\n",
    "    for b in bars:\n",
    "        height = b.get_height()\n",
    "        if height <= 0:\n",
    "            continue\n",
    "        pct = 100 * height / total if total > 0 else 0.0\n",
    "        ax.text(\n",
    "            b.get_x() + b.get_width() / 2,\n",
    "            height,\n",
    "            f\"{height:.2f} TWh\\n({pct:.1f}%)\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=10,\n",
    "        )\n",
    "\n",
    "annotate_bars(bars_d, total_d)\n",
    "annotate_bars(bars_w, total_w)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f33f82c",
   "metadata": {},
   "source": [
    "##### Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f4b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _snapshot_weights(net):\n",
    "    if hasattr(net, \"snapshot_weightings\") and net.snapshot_weightings is not None:\n",
    "        try:\n",
    "            if \"generators\" in net.snapshot_weightings:\n",
    "                return net.snapshot_weightings[\"generators\"]\n",
    "        except Exception:\n",
    "            pass\n",
    "    return pd.Series(1.0, index=net.snapshots)\n",
    "\n",
    "def hydrogen_revenue(net, h2_bus_carrier=\"H2\"):\n",
    "    \"\"\"\n",
    "    Hydrogen revenue [â¬] computed as:\n",
    "      Revenue = sum_t sum_{H2 loads} (H2_price_at_bus[t] * H2_load_power[t] * weight[t])\n",
    "\n",
    "    Assumptions:\n",
    "      - H2 price is net.buses_t.marginal_price at H2 buses [â¬/MWh_H2]\n",
    "      - H2 demand is net.loads_t.p at loads connected to H2 buses [MW_H2]\n",
    "      - Snapshot weights are hours, so MW * h = MWh\n",
    "\n",
    "    Returns:\n",
    "      total_revenue_eur, revenue_by_loadcarrier_eur (Series)\n",
    "    \"\"\"\n",
    "    if not hasattr(net, \"buses_t\") or not hasattr(net.buses_t, \"marginal_price\"):\n",
    "        raise ValueError(\"net.buses_t.marginal_price not found (no dual prices stored).\")\n",
    "\n",
    "    w = _snapshot_weights(net)\n",
    "\n",
    "    # --- identify H2 buses ---\n",
    "    h2_buses = net.buses.index[net.buses.carrier == h2_bus_carrier]\n",
    "    if len(h2_buses) == 0:\n",
    "        raise ValueError(f\"No buses with carrier == '{h2_bus_carrier}' found.\")\n",
    "\n",
    "    # --- identify loads on H2 buses ---\n",
    "    loads = net.loads.copy()\n",
    "    h2_loads = loads[loads.bus.isin(h2_buses)].copy()\n",
    "    if h2_loads.empty:\n",
    "        # Nothing to sell H2 to -> revenue 0\n",
    "        return 0.0, pd.Series(dtype=float)\n",
    "\n",
    "    # Load time series [MW_H2]\n",
    "    p_load = net.loads_t.p[h2_loads.index]\n",
    "\n",
    "    # Bus prices [â¬/MWh_H2] for each load's bus, expanded to load columns\n",
    "    price_mat = pd.DataFrame({ld: net.buses_t.marginal_price[bus] for ld, bus in h2_loads[\"bus\"].items()})\n",
    "\n",
    "    # Revenue per load [â¬]\n",
    "    rev_per_load = ((p_load.mul(w, axis=0)) * price_mat).sum(axis=0)  # MWh * â¬/MWh\n",
    "\n",
    "    # Group revenue by load carrier (or by load name if carrier missing)\n",
    "    if \"carrier\" in h2_loads.columns:\n",
    "        grp = h2_loads[\"carrier\"].fillna(\"H2 load\")\n",
    "    else:\n",
    "        grp = pd.Series(\"H2 load\", index=h2_loads.index)\n",
    "\n",
    "    rev_by_carrier = rev_per_load.groupby(grp).sum().sort_values(ascending=False)\n",
    "    total_rev = float(rev_by_carrier.sum())\n",
    "\n",
    "    return total_rev, rev_by_carrier\n",
    "\n",
    "# ============================\n",
    "# Compute revenues for both scenarios\n",
    "# ============================\n",
    "rev_uhs_total, rev_uhs_by = hydrogen_revenue(uhs, h2_bus_carrier=\"H2\")\n",
    "rev_woUHS_total, rev_woUHS_by = hydrogen_revenue(woUHS, h2_bus_carrier=\"H2\")\n",
    "\n",
    "# Align revenue categories (if you have multiple H2 demand types)\n",
    "cats = sorted(set(rev_uhs_by.index) | set(rev_woUHS_by.index))\n",
    "rev_df = pd.DataFrame({\n",
    "    \"uhs 2050\": rev_uhs_by.reindex(cats).fillna(0.0),\n",
    "    \"woUHS 2050\": rev_woUHS_by.reindex(cats).fillna(0.0),\n",
    "})\n",
    "\n",
    "# If there is only one category, it still plots cleanly.\n",
    "# Sort by mean revenue so the largest categories are first\n",
    "if len(cats) > 1:\n",
    "    rev_df = rev_df.loc[rev_df.mean(axis=1).sort_values(ascending=False).index]\n",
    "\n",
    "# ============================\n",
    "# Plot: stacked revenues (bn â¬) with values on bars\n",
    "# ============================\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "x = np.arange(2)\n",
    "bottom = np.zeros(2)\n",
    "\n",
    "colors = plt.cm.tab10.colors\n",
    "handles = []\n",
    "legend_labels = []\n",
    "\n",
    "for i, cat in enumerate(rev_df.index):\n",
    "    vals = rev_df.loc[cat, [\"uhs 2050\", \"woUHS 2050\"]].values.astype(float)\n",
    "    bars = ax.bar(x, vals, bottom=bottom, color=colors[i % len(colors)])\n",
    "    bottom += vals\n",
    "\n",
    "    # Legend: absolute revenues per category for both scenarios (bn â¬)\n",
    "    d_bn = rev_df.loc[cat, \"uhs 2050\"] / 1e9\n",
    "    w_bn = rev_df.loc[cat, \"woUHS 2050\"] / 1e9\n",
    "    legend_labels.append(f\"{cat} ({d_bn:.2f} / {w_bn:.2f} bn â¬)\")\n",
    "    handles.append(bars[0])\n",
    "\n",
    "# Bar annotations: totals on top\n",
    "totals = np.array([rev_uhs_total, rev_woUHS_total], dtype=float)\n",
    "for xi, total in zip(x, totals):\n",
    "    ax.text(xi, total, f\"{total/1e9:.2f} bn â¬\", ha=\"center\", va=\"bottom\", fontsize=11)\n",
    "\n",
    "# Add headroom so text isn't clipped\n",
    "ymax = max(totals.max(), 1.0)\n",
    "ax.set_ylim(0, ymax * 1.15)\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([\"uhs 2050\", \"woUHS 2050\"], fontsize=11)\n",
    "ax.set_ylabel(\"Hydrogen revenue [bn â¬]\")\n",
    "ax.yaxis.set_major_formatter(FuncFormatter(lambda v, pos: f\"{v/1e9:.0f}\"))\n",
    "ax.set_title(\"Hydrogen revenue â 2050\", fontsize=13)\n",
    "\n",
    "legend_title = f\"uhs total: {rev_uhs_total/1e9:.2f} bn â¬ / woUHS total: {rev_woUHS_total/1e9:.2f} bn â¬\"\n",
    "ax.legend(handles, legend_labels, title=legend_title,\n",
    "          bbox_to_anchor=(1.02, 1), loc=\"upper left\",\n",
    "          fontsize=10, title_fontsize=11, frameon=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605f4464",
   "metadata": {},
   "source": [
    "##### Hydrogen Market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094141a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _snapshot_weights(net):\n",
    "    if hasattr(net, \"snapshot_weightings\") and net.snapshot_weightings is not None:\n",
    "        try:\n",
    "            if \"generators\" in net.snapshot_weightings:\n",
    "                return net.snapshot_weightings[\"generators\"]\n",
    "        except Exception:\n",
    "            pass\n",
    "    return pd.Series(1.0, index=net.snapshots)\n",
    "\n",
    "def hydrogen_market_value(net, h2_bus_carrier=\"H2\", h2_lhv_kwh_per_kg=33.33):\n",
    "    \"\"\"\n",
    "    Hydrogen Market Value = revenue / quantity, computed primarily from H2 loads:\n",
    "      MV [â¬/MWh_H2] = sum_t (p_load * w * price_bus) / sum_t (p_load * w)\n",
    "\n",
    "    where price_bus is net.buses_t.marginal_price at the H2 bus (â¬/MWh_H2)\n",
    "    and p_load is net.loads_t.p of loads connected to H2 buses (MW_H2).\n",
    "\n",
    "    Returns:\n",
    "      mv_eur_per_mwh, mv_eur_per_kg, total_revenue_eur, total_quantity_mwh\n",
    "    \"\"\"\n",
    "    if not hasattr(net, \"buses_t\") or not hasattr(net.buses_t, \"marginal_price\"):\n",
    "        raise ValueError(\"net.buses_t.marginal_price not found (no dual prices stored).\")\n",
    "\n",
    "    w = _snapshot_weights(net)\n",
    "\n",
    "    # Identify H2 buses\n",
    "    h2_buses = net.buses.index[net.buses.carrier == h2_bus_carrier]\n",
    "    if len(h2_buses) == 0:\n",
    "        raise ValueError(f\"No buses with carrier == '{h2_bus_carrier}' found.\")\n",
    "\n",
    "    # H2 loads (buyers)\n",
    "    h2_loads = net.loads[net.loads.bus.isin(h2_buses)].copy()\n",
    "    if h2_loads.empty:\n",
    "        raise ValueError(\"No H2 loads found on H2 buses (cannot compute market value from demand).\")\n",
    "\n",
    "    p_load = net.loads_t.p[h2_loads.index]  # MW_H2\n",
    "\n",
    "    # Quantity [MWh_H2]\n",
    "    q_mwh = float((p_load.mul(w, axis=0)).sum().sum())\n",
    "    if q_mwh == 0:\n",
    "        raise ValueError(\"Total H2 load energy is zero (cannot compute market value).\")\n",
    "\n",
    "    # Per-load price time series at the corresponding H2 bus\n",
    "    price_mat = pd.DataFrame({ld: net.buses_t.marginal_price[bus] for ld, bus in h2_loads[\"bus\"].items()})\n",
    "\n",
    "    # Revenue [â¬]\n",
    "    revenue_eur = float(((p_load.mul(w, axis=0)) * price_mat).sum().sum())\n",
    "\n",
    "    mv_eur_per_mwh = revenue_eur / q_mwh\n",
    "\n",
    "    # Convert â¬/MWh -> â¬/kg via LHV:\n",
    "    # 1 MWh = 1000 kWh, kg = kWh / (kWh/kg) => kg per MWh = 1000 / LHV\n",
    "    kg_per_mwh = 1000.0 / h2_lhv_kwh_per_kg\n",
    "    mv_eur_per_kg = mv_eur_per_mwh / kg_per_mwh\n",
    "\n",
    "    return mv_eur_per_mwh, mv_eur_per_kg, revenue_eur, q_mwh\n",
    "\n",
    "# ============================\n",
    "# Compute for both scenarios\n",
    "# ============================\n",
    "mv_d_mwh, mv_d_kg, rev_d, q_d = hydrogen_market_value(uhs, h2_bus_carrier=\"H2\")\n",
    "mv_w_mwh, mv_w_kg, rev_w, q_w = hydrogen_market_value(woUHS, h2_bus_carrier=\"H2\")\n",
    "\n",
    "# ============================\n",
    "# Plot (â¬/kg H2) with values on bars\n",
    "# ============================\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "\n",
    "labels = [\"uhs 2050\", \"woUHS 2050\"]\n",
    "vals_kg = [mv_d_kg, mv_w_kg]\n",
    "\n",
    "bars = ax.bar(labels, vals_kg)\n",
    "\n",
    "ax.set_ylabel(\"Hydrogen market value [â¬/kg Hâ]\")\n",
    "ax.set_title(\"Hydrogen Market Value â 2050\")\n",
    "\n",
    "# annotate bars (also show â¬/MWh_H2 in the label)\n",
    "vals_mwh = [mv_d_mwh, mv_w_mwh]\n",
    "for b, vkg, vmwh in zip(bars, vals_kg, vals_mwh):\n",
    "    ax.text(\n",
    "        b.get_x() + b.get_width() / 2,\n",
    "        b.get_height(),\n",
    "        f\"{vkg:.2f} â¬/kg\\n({vmwh:.1f} â¬/MWh)\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "# add headroom to avoid clipping\n",
    "ymax = max(vals_kg) if max(vals_kg) > 0 else 1.0\n",
    "ax.set_ylim(0, ymax * 1.20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a806401f",
   "metadata": {},
   "source": [
    "##### Capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc3ca29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hydrogen_capacities_breakdown(net):\n",
    "    \"\"\"\n",
    "    Installed hydrogen-related capacities (using p_nom_opt if available) split into:\n",
    "      - Electrolysis (H2 Electrolysis links)  [MW_el or MW_link]\n",
    "      - H2 Pipelines (H2 pipeline links)      [MW_link]\n",
    "      - H2 Storage (stores + storage_units with carrier containing 'H2') [MWh for Stores, MW for StorageUnits]\n",
    "      - H2 Conversion (other links with carrier containing 'H2', excluding Electrolysis & pipelines) [MW_link]\n",
    "\n",
    "    Returns:\n",
    "      cap_MW: Series of MW-type capacities (Links + StorageUnits)\n",
    "      cap_MWh: Series of MWh-type capacities (Stores)\n",
    "    \"\"\"\n",
    "    # --- Links ---\n",
    "    links = net.links.copy()\n",
    "    pnom_col = \"p_nom_opt\" if \"p_nom_opt\" in links.columns else \"p_nom\"\n",
    "\n",
    "    h2_buses = net.buses.index[net.buses.carrier == \"H2\"]\n",
    "\n",
    "    # --- Electrolysis: electricity -> H2 ---\n",
    "    electrolysis = links[links.carrier == \"H2 Electrolysis\"]\n",
    "\n",
    "    # --- H2 pipelines: H2 -> H2 ---\n",
    "    pipelines = links[\n",
    "        (links.carrier == \"H2 pipeline\") &\n",
    "        (links.bus0.isin(h2_buses)) &\n",
    "        (links.bus1.isin(h2_buses))\n",
    "    ]\n",
    "\n",
    "    # --- H2 conversion: H2 <-> non-H2 (excluding electrolysis & pipelines) ---\n",
    "    conversion = links[\n",
    "        (\n",
    "            links.bus0.isin(h2_buses) ^ links.bus1.isin(h2_buses)\n",
    "        ) &\n",
    "        (~links.index.isin(electrolysis.index)) &\n",
    "        (~links.index.isin(pipelines.index))\n",
    "    ]\n",
    "\n",
    "    def sum_cap(df):\n",
    "        if df.empty:\n",
    "            return 0.0\n",
    "        return float(df[pnom_col].fillna(0.0).sum())\n",
    "\n",
    "    cap_MW = pd.Series({\n",
    "        \"Electrolysis\": sum_cap(electrolysis),\n",
    "        \"H2 Pipelines\": sum_cap(pipelines),\n",
    "        \"H2 Conversion\": sum_cap(conversion),\n",
    "    })\n",
    "\n",
    "    # --- H2 storage (power & energy) ---\n",
    "    cap_MW[\"H2 Storage (Power)\"] = 0.0\n",
    "    cap_MWh = pd.Series(dtype=float)\n",
    "\n",
    "    if hasattr(net, \"storage_units\") and not net.storage_units.empty:\n",
    "        su = net.storage_units\n",
    "        su_pnom = \"p_nom_opt\" if \"p_nom_opt\" in su.columns else \"p_nom\"\n",
    "        h2_su = su[su.bus.isin(h2_buses)]\n",
    "        cap_MW[\"H2 Storage (Power)\"] = float(h2_su[su_pnom].fillna(0.0).sum())\n",
    "\n",
    "    if hasattr(net, \"stores\") and not net.stores.empty:\n",
    "        st = net.stores\n",
    "        st_enom = \"e_nom_opt\" if \"e_nom_opt\" in st.columns else \"e_nom\"\n",
    "        h2_st = st[st.bus.isin(h2_buses)]\n",
    "        cap_MWh[\"H2 Storage (Energy)\"] = float(h2_st[st_enom].fillna(0.0).sum())\n",
    "\n",
    "    return cap_MW, cap_MWh\n",
    "\n",
    "\n",
    "# ============================\n",
    "# Compute capacities for both scenarios\n",
    "# ============================\n",
    "cap_MW_uhs, cap_MWh_uhs = hydrogen_capacities_breakdown(uhs)\n",
    "cap_MW_woUHS, cap_MWh_woUHS = hydrogen_capacities_breakdown(woUHS)\n",
    "\n",
    "# Align indices\n",
    "mw_cats = sorted(set(cap_MW_uhs.index) | set(cap_MW_woUHS.index))\n",
    "mwh_cats = sorted(set(cap_MWh_uhs.index) | set(cap_MWh_woUHS.index))\n",
    "\n",
    "mw_df = pd.DataFrame({\n",
    "    \"uhs 2050\": cap_MW_uhs.reindex(mw_cats).fillna(0.0),\n",
    "    \"woUHS 2050\": cap_MW_woUHS.reindex(mw_cats).fillna(0.0),\n",
    "})\n",
    "\n",
    "mwh_df = pd.DataFrame({\n",
    "    \"uhs 2050\": cap_MWh_uhs.reindex(mwh_cats).fillna(0.0),\n",
    "    \"woUHS 2050\": cap_MWh_woUHS.reindex(mwh_cats).fillna(0.0),\n",
    "})\n",
    "\n",
    "# ============================\n",
    "# Plot 1: MW capacities (GW) with values on bars\n",
    "# ============================\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "x = np.arange(len(mw_df.index))\n",
    "width = 0.4\n",
    "\n",
    "vals_d = mw_df[\"uhs 2050\"].values / 1000.0    # GW\n",
    "vals_w = mw_df[\"woUHS 2050\"].values / 1000.0  # GW\n",
    "\n",
    "bars_d = ax.bar(x - width/2, vals_d, width=width, label=\"uhs 2050\")\n",
    "bars_w = ax.bar(x + width/2, vals_w, width=width, label=\"woUHS 2050\")\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(mw_df.index, rotation=20, ha=\"right\")\n",
    "ax.set_ylabel(\"Installed capacity [GW]\")\n",
    "ax.set_title(\"Hydrogen-related capacities - 2050\")\n",
    "ax.legend()\n",
    "\n",
    "# ---- annotate bars ----\n",
    "def annotate(bars):\n",
    "    for b in bars:\n",
    "        h = b.get_height()\n",
    "        if h <= 0:\n",
    "            continue\n",
    "        ax.text(\n",
    "            b.get_x() + b.get_width()/2,\n",
    "            h,\n",
    "            f\"{h:.1f} GW\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=10\n",
    "        )\n",
    "\n",
    "annotate(bars_d)\n",
    "annotate(bars_w)\n",
    "\n",
    "# headroom\n",
    "ax.set_ylim(0, max(vals_d.max(), vals_w.max()) * 1.15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a3d2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_bars_no_overlap(ax, bars, fmt=\"{:.1f}\", min_rel_gap=0.06, y_pad_rel=0.012):\n",
    "    \"\"\"\n",
    "    Annotate bars while avoiding label overlap.\n",
    "    - min_rel_gap: minimal relative gap (as fraction of y-range) required to draw a label.\n",
    "    - y_pad_rel: padding above bar height relative to y-range.\n",
    "    \"\"\"\n",
    "    y0, y1 = ax.get_ylim()\n",
    "    yr = max(y1 - y0, 1e-9)\n",
    "\n",
    "    used_y = []\n",
    "    for b in bars:\n",
    "        h = float(b.get_height())\n",
    "        if h <= 0:\n",
    "            continue\n",
    "\n",
    "        y = h + y_pad_rel * yr\n",
    "\n",
    "        # Skip label if it would collide with an existing one\n",
    "        if any(abs(y - yy) < min_rel_gap * yr for yy in used_y):\n",
    "            continue\n",
    "\n",
    "        ax.text(\n",
    "            b.get_x() + b.get_width() / 2,\n",
    "            y,\n",
    "            fmt.format(h),\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=10,\n",
    "            clip_on=True,\n",
    "        )\n",
    "        used_y.append(y)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Classification helpers\n",
    "# ============================================================\n",
    "\n",
    "def is_h2_export_link(links: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Identify H2 export boundary links (robust heuristic).\n",
    "    Works for typical PyPSA-Earth naming patterns like:\n",
    "      - index contains 'H2 export'\n",
    "      - bus1 contains 'export'\n",
    "      - bus1 equals/contains 'export bus'\n",
    "    \"\"\"\n",
    "    idx = links.index.astype(str)\n",
    "    bus1 = links[\"bus1\"].astype(str) if \"bus1\" in links.columns else pd.Series(\"\", index=links.index)\n",
    "    bus0 = links[\"bus0\"].astype(str) if \"bus0\" in links.columns else pd.Series(\"\", index=links.index)\n",
    "\n",
    "    return (\n",
    "        idx.str.contains(r\"\\bh2\\s*export\\b|\\bexport\\b\", case=False, na=False) |\n",
    "        bus1.str.contains(r\"\\bexport\\b\", case=False, na=False) |\n",
    "        bus0.str.contains(r\"\\bexport\\b\", case=False, na=False)\n",
    "    )\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Main breakdown\n",
    "# ============================================================\n",
    "\n",
    "def hydrogen_capacities_breakdown(net):\n",
    "    \"\"\"\n",
    "    Installed hydrogen-related capacities split into:\n",
    "\n",
    "    Power (MW):\n",
    "      - Electrolysis (H2 Electrolysis links)\n",
    "      - SMR (SMR links)\n",
    "      - H2 Pipelines (H2 pipeline + repurposed, H2->H2)\n",
    "      - H2 Conversion (explicit conversion tech carriers, excluding export)\n",
    "        * Excludes generic carrier 'H2' which in your case represents H2 export boundary links.\n",
    "\n",
    "    Energy (MWh):\n",
    "      - H2 Storage (Energy) (Stores on H2 buses)\n",
    "\n",
    "    Additionally returns:\n",
    "      - conversion_by_carrier_MW: Series showing conversion capacity by carrier (MW)\n",
    "      - h2_export_MW: total export link capacity (MW) for transparency/debug\n",
    "    \"\"\"\n",
    "    links = net.links.copy()\n",
    "    pnom_col = \"p_nom_opt\" if \"p_nom_opt\" in links.columns else \"p_nom\"\n",
    "\n",
    "    # Keep your strict bus definition (carrier == \"H2\")\n",
    "    h2_buses = net.buses.index[net.buses.carrier == \"H2\"]\n",
    "\n",
    "    # ---- Production ----\n",
    "    electrolysis = links[links.carrier == \"H2 Electrolysis\"]\n",
    "    smr = links[links.carrier == \"SMR\"]\n",
    "\n",
    "    # ---- Pipelines (include repurposed) ----\n",
    "    pipelines = links[\n",
    "        (links.carrier.isin([\"H2 pipeline\", \"H2 pipeline repurposed\"])) &\n",
    "        (links.bus0.isin(h2_buses)) &\n",
    "        (links.bus1.isin(h2_buses))\n",
    "    ]\n",
    "\n",
    "    # ---- Conversion (explicit tech carriers only; exclude export boundary links) ----\n",
    "    conversion_carriers = {\n",
    "        \"H2 Fuel Cell\",\n",
    "        \"H2 turbine\",\n",
    "        \"Sabatier\",\n",
    "        \"Fischer-Tropsch\",\n",
    "    }\n",
    "    conversion = links[\n",
    "        links.carrier.isin(conversion_carriers) &\n",
    "        (~is_h2_export_link(links))\n",
    "    ]\n",
    "\n",
    "    def sum_cap(df):\n",
    "        if df.empty:\n",
    "            return 0.0\n",
    "        return float(df[pnom_col].fillna(0.0).sum())\n",
    "\n",
    "    cap_MW = pd.Series({\n",
    "        \"Electrolysis\": sum_cap(electrolysis),\n",
    "        \"SMR\": sum_cap(smr),\n",
    "        \"H2 Pipelines\": sum_cap(pipelines),\n",
    "        \"H2 Conversion\": sum_cap(conversion),\n",
    "    }, dtype=float)\n",
    "\n",
    "    conversion_by_carrier_MW = (\n",
    "        conversion.assign(_p=conversion[pnom_col].fillna(0.0))\n",
    "        .groupby(\"carrier\")[\"_p\"].sum()\n",
    "        .sort_values(ascending=False)\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "    # ---- Export capacity (for debug; not plotted by default) ----\n",
    "    h2_export = links[(links.carrier == \"H2\") & is_h2_export_link(links)]\n",
    "    h2_export_MW = sum_cap(h2_export)\n",
    "\n",
    "    # ---- Storage energy (MWh) ----\n",
    "    cap_MWh = pd.Series(dtype=float)\n",
    "    if hasattr(net, \"stores\") and not net.stores.empty:\n",
    "        st = net.stores\n",
    "        st_enom = \"e_nom_opt\" if \"e_nom_opt\" in st.columns else \"e_nom\"\n",
    "        h2_st = st[st.bus.isin(h2_buses)]\n",
    "        cap_MWh[\"H2 Storage (Energy)\"] = float(h2_st[st_enom].fillna(0.0).sum())\n",
    "    else:\n",
    "        cap_MWh[\"H2 Storage (Energy)\"] = 0.0\n",
    "\n",
    "    return cap_MW, cap_MWh, conversion_by_carrier_MW, h2_export_MW\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Run breakdown for both scenarios\n",
    "# ============================================================\n",
    "\n",
    "cap_MW_uhs, cap_MWh_uhs, conv_uhs, export_uhs_MW = hydrogen_capacities_breakdown(uhs)\n",
    "cap_MW_wo,  cap_MWh_wo,  conv_wo,  export_wo_MW  = hydrogen_capacities_breakdown(woUHS)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Build dataframes for plotting\n",
    "# ============================================================\n",
    "\n",
    "mw_cats = [\"Electrolysis\", \"SMR\", \"H2 Pipelines\", \"H2 Conversion\"]\n",
    "mw_df = pd.DataFrame({\n",
    "    \"uhs 2050\": cap_MW_uhs.reindex(mw_cats).fillna(0.0),\n",
    "    \"woUHS 2050\": cap_MW_wo.reindex(mw_cats).fillna(0.0),\n",
    "})\n",
    "\n",
    "mwh_cats = [\"H2 Storage (Energy)\"]\n",
    "mwh_df = pd.DataFrame({\n",
    "    \"uhs 2050\": cap_MWh_uhs.reindex(mwh_cats).fillna(0.0),\n",
    "    \"woUHS 2050\": cap_MWh_wo.reindex(mwh_cats).fillna(0.0),\n",
    "})\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Plot: power (GW) + stores energy (GWh) side-by-side\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# ---- Left: Power capacities (GW)\n",
    "ax = axes[0]\n",
    "x = np.arange(len(mw_df.index))\n",
    "width = 0.40\n",
    "\n",
    "vals_d = mw_df[\"uhs 2050\"].values / 1000.0  # MW -> GW\n",
    "vals_w = mw_df[\"woUHS 2050\"].values / 1000.0\n",
    "\n",
    "bars_d = ax.bar(x - width/2, vals_d, width=width, label=\"uhs 2050\")\n",
    "bars_w = ax.bar(x + width/2, vals_w, width=width, label=\"woUHS 2050\")\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(mw_df.index, rotation=20, ha=\"right\")\n",
    "ax.set_ylabel(\"Installed capacity [GW]\")\n",
    "ax.set_title(\"Hydrogen-related capacities â 2050\")\n",
    "ax.legend()\n",
    "ax.set_ylim(0, max(vals_d.max(), vals_w.max()) * 1.18)\n",
    "\n",
    "annotate_bars_no_overlap(ax, bars_d, fmt=\"{:.1f} GW\")\n",
    "annotate_bars_no_overlap(ax, bars_w, fmt=\"{:.1f} GW\")\n",
    "\n",
    "# ---- Right: Stores energy (GWh)\n",
    "ax2 = axes[1]\n",
    "x2 = np.arange(len(mwh_df.index))\n",
    "\n",
    "vals2_d = mwh_df[\"uhs 2050\"].values / 1000.0  # MWh -> GWh\n",
    "vals2_w = mwh_df[\"woUHS 2050\"].values / 1000.0\n",
    "\n",
    "bars2_d = ax2.bar(x2 - width/2, vals2_d, width=width, label=\"uhs 2050\")\n",
    "bars2_w = ax2.bar(x2 + width/2, vals2_w, width=width, label=\"woUHS 2050\")\n",
    "\n",
    "ax2.set_xticks(x2)\n",
    "ax2.set_xticklabels(mwh_df.index, rotation=0, ha=\"center\")\n",
    "ax2.set_ylabel(\"Installed energy capacity [GWh]\")\n",
    "ax2.set_title(\"Hydrogen storage  â 2050\")\n",
    "ax2.legend()\n",
    "ax2.set_ylim(0, max(vals2_d.max(), vals2_w.max()) * 1.18)\n",
    "\n",
    "annotate_bars_no_overlap(ax2, bars2_d, fmt=\"{:.1f} GWh\")\n",
    "annotate_bars_no_overlap(ax2, bars2_w, fmt=\"{:.1f} GWh\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3714d23",
   "metadata": {},
   "source": [
    "##### Hourly Export Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b39e934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def h2_export_buses(net) -> pd.Index:\n",
    "    \"\"\"\n",
    "    Identify H2 export buses (robust heuristic for PyPSA-Earth):\n",
    "    - bus name contains 'H2 export'\n",
    "    - OR contains 'export bus' and 'H2'\n",
    "    \"\"\"\n",
    "    names = pd.Index(net.buses.index.astype(str))\n",
    "    s = names.to_series(index=net.buses.index)\n",
    "\n",
    "    m1 = s.str.contains(r\"\\bh2\\s*export\\b\", case=False, na=False)\n",
    "    m2 = s.str.contains(r\"\\bexport\\s*bus\\b\", case=False, na=False) & s.str.contains(r\"\\bh2\\b\", case=False, na=False)\n",
    "\n",
    "    return net.buses.index[m1 | m2]\n",
    "\n",
    "\n",
    "def hourly_export_marginal_price(net, agg=\"mean\") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Hourly marginal price time series [â¬/MWh] at H2 export bus(es).\n",
    "    If multiple export buses exist, aggregate across buses per snapshot.\n",
    "    \"\"\"\n",
    "    if not hasattr(net, \"buses_t\") or not hasattr(net.buses_t, \"marginal_price\"):\n",
    "        raise ValueError(\"net.buses_t.marginal_price not found (no marginal prices stored).\")\n",
    "\n",
    "    buses = h2_export_buses(net)\n",
    "    if len(buses) == 0:\n",
    "        raise ValueError(\"No H2 export buses found. Adjust the heuristic in h2_export_buses().\")\n",
    "\n",
    "    mp = net.buses_t.marginal_price[buses]  # snapshots x buses (DataFrame or Series)\n",
    "\n",
    "    if isinstance(mp, pd.Series):\n",
    "        s = mp.copy()\n",
    "    else:\n",
    "        if agg == \"mean\":\n",
    "            s = mp.mean(axis=1)\n",
    "        elif agg == \"median\":\n",
    "            s = mp.median(axis=1)\n",
    "        elif agg == \"min\":\n",
    "            s = mp.min(axis=1)\n",
    "        elif agg == \"max\":\n",
    "            s = mp.max(axis=1)\n",
    "        else:\n",
    "            raise ValueError(\"agg must be one of: mean, median, min, max\")\n",
    "\n",
    "    s.name = f\"H2 export marginal price ({agg})\"\n",
    "    return s\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Build series for both scenarios and align\n",
    "# ============================================================\n",
    "\n",
    "# Compute (â¬/MWh)\n",
    "p_uhs = hourly_export_marginal_price(uhs, agg=\"mean\")\n",
    "p_wo  = hourly_export_marginal_price(woUHS, agg=\"mean\")\n",
    "\n",
    "# Align snapshots\n",
    "idx = p_uhs.index.intersection(p_wo.index)\n",
    "p_uhs = p_uhs.loc[idx]\n",
    "p_wo  = p_wo.loc[idx]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Dual-axis plot (â¬/MWh and â¬/kg via LHV)\n",
    "# ============================================================\n",
    "\n",
    "H2_LHV_KWH_PER_KG = 33.33\n",
    "KG_PER_MWH = 1000.0 / H2_LHV_KWH_PER_KG  # â 30.0 kg/MWh\n",
    "\n",
    "fig, ax_left = plt.subplots(figsize=(14, 5))\n",
    "\n",
    "# Left axis: â¬/MWh\n",
    "l1, = ax_left.plot(p_uhs.index, p_uhs.values, label=\"uhs 2050\", linewidth=1.8)\n",
    "l2, = ax_left.plot(p_wo.index,  p_wo.values,  label=\"woUHS 2050\", linewidth=1.8)\n",
    "\n",
    "ax_left.set_title(\"Hourly marginal prices at Hâ export buses â 2050\")\n",
    "ax_left.set_xlabel(\"Snapshot\")\n",
    "ax_left.set_ylabel(\"Marginal price [â¬/MWh Hâ]\")\n",
    "ax_left.grid(True, alpha=0.25)\n",
    "\n",
    "# Right axis: â¬/kg (LHV)\n",
    "ax_right = ax_left.twinx()\n",
    "ymin, ymax = ax_left.get_ylim()\n",
    "ax_right.set_ylim(ymin / KG_PER_MWH, ymax / KG_PER_MWH)\n",
    "ax_right.set_ylabel(\"Marginal price [â¬/kg Hâ (LHV)]\")\n",
    "\n",
    "# Legend below plot\n",
    "ax_left.legend(\n",
    "    handles=[l1, l2],\n",
    "    labels=[\"uhs 2050\", \"woUHS 2050\"],\n",
    "    loc=\"upper center\",\n",
    "    bbox_to_anchor=(0.5, -0.18),\n",
    "    ncol=2,\n",
    "    frameon=True\n",
    ")\n",
    "\n",
    "fig.subplots_adjust(bottom=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749eb420",
   "metadata": {},
   "source": [
    "##### Hourly Export Quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba83504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def h2_export_buses(net) -> pd.Index:\n",
    "    \"\"\"\n",
    "    Identify H2 export buses (robust heuristic for PyPSA-Earth):\n",
    "    - bus name contains 'H2 export'\n",
    "    - OR contains 'export bus' and 'H2'\n",
    "    \"\"\"\n",
    "    names = pd.Index(net.buses.index.astype(str))\n",
    "    s = names.to_series(index=net.buses.index)\n",
    "\n",
    "    m1 = s.str.contains(r\"\\bh2\\s*export\\b\", case=False, na=False)\n",
    "    m2 = s.str.contains(r\"\\bexport\\s*bus\\b\", case=False, na=False) & s.str.contains(r\"\\bh2\\b\", case=False, na=False)\n",
    "\n",
    "    return net.buses.index[m1 | m2]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Hourly H2 export quantity\n",
    "# ============================================================\n",
    "\n",
    "def hourly_h2_export_quantity(net, agg=\"sum\") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Hourly H2 export quantity time series [MWh/h].\n",
    "\n",
    "    Uses link flows feeding the H2 export bus.\n",
    "    If multiple export links exist, aggregates across them per snapshot.\n",
    "\n",
    "    agg:\n",
    "      - 'sum'  : total export (recommended)\n",
    "      - 'mean' : mean across export links\n",
    "    \"\"\"\n",
    "    buses = h2_export_buses(net)\n",
    "    if len(buses) == 0:\n",
    "        raise ValueError(\"No H2 export buses found. Adjust heuristic if needed.\")\n",
    "\n",
    "    # Export links: anything that feeds INTO the export bus\n",
    "    links = net.links.copy()\n",
    "\n",
    "    export_links = links[links.bus1.isin(buses)]\n",
    "    if export_links.empty:\n",
    "        raise ValueError(\"No links feeding the H2 export bus found.\")\n",
    "\n",
    "    # p1 is flow into bus1 by PyPSA convention\n",
    "    p1 = net.links_t.p1[export_links.index]  # MW\n",
    "\n",
    "    # Robust sign handling\n",
    "    cons_pos = p1.clip(lower=0).sum().sum()\n",
    "    cons_neg = (-p1).clip(lower=0).sum().sum()\n",
    "    flow = p1.clip(lower=0) if cons_pos >= cons_neg else (-p1).clip(lower=0)\n",
    "\n",
    "    if agg == \"sum\":\n",
    "        s = flow.sum(axis=1)\n",
    "    elif agg == \"mean\":\n",
    "        s = flow.mean(axis=1)\n",
    "    else:\n",
    "        raise ValueError(\"agg must be 'sum' or 'mean'\")\n",
    "\n",
    "    s.name = \"H2 export quantity\"\n",
    "    return s\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Build series for both scenarios and align\n",
    "# ============================================================\n",
    "\n",
    "# Export quantity in MW (= MWh/h)\n",
    "q_uhs = hourly_h2_export_quantity(uhs, agg=\"sum\")\n",
    "q_wo  = hourly_h2_export_quantity(woUHS, agg=\"sum\")\n",
    "\n",
    "# Align snapshots\n",
    "idx = q_uhs.index.intersection(q_wo.index)\n",
    "q_uhs = q_uhs.loc[idx]\n",
    "q_wo  = q_wo.loc[idx]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Dual-axis plot (MWh/h and kg/h via LHV)\n",
    "# ============================================================\n",
    "\n",
    "H2_LHV_KWH_PER_KG = 33.33\n",
    "KG_PER_MWH = 1000.0 / H2_LHV_KWH_PER_KG  # â 30.0 kg/MWh\n",
    "\n",
    "fig, ax_left = plt.subplots(figsize=(14, 5))\n",
    "\n",
    "# Left axis: MWh/h\n",
    "l1, = ax_left.plot(q_uhs.index, q_uhs.values, label=\"uhs 2050\", linewidth=1.8)\n",
    "l2, = ax_left.plot(q_wo.index,  q_wo.values,  label=\"woUHS 2050\", linewidth=1.8)\n",
    "\n",
    "ax_left.set_title(\"Hourly Hâ export quantity â 2050\")\n",
    "ax_left.set_xlabel(\"Snapshot\")\n",
    "ax_left.set_ylabel(\"Export quantity [MWhââ / h]\")\n",
    "ax_left.grid(True, alpha=0.25)\n",
    "\n",
    "# Right axis: kg/h (LHV)\n",
    "ax_right = ax_left.twinx()\n",
    "ymin, ymax = ax_left.get_ylim()\n",
    "ax_right.set_ylim(ymin * KG_PER_MWH, ymax * KG_PER_MWH)\n",
    "ax_right.set_ylabel(\"Export quantity [kg Hâ / h (LHV)]\")\n",
    "\n",
    "# Legend below plot\n",
    "ax_left.legend(\n",
    "    handles=[l1, l2],\n",
    "    labels=[\"uhs 2050\", \"woUHS 2050\"],\n",
    "    loc=\"upper center\",\n",
    "    bbox_to_anchor=(0.5, -0.18),\n",
    "    ncol=2,\n",
    "    frameon=True\n",
    ")\n",
    "\n",
    "fig.subplots_adjust(bottom=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1262f1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate export quantitys to monthly sums and plot them for uhs and woUHS next to each other\n",
    "def h2_export_buses(net) -> pd.Index:\n",
    "    names = pd.Index(net.buses.index.astype(str))\n",
    "    s = names.to_series(index=net.buses.index)\n",
    "    m1 = s.str.contains(r\"\\bh2\\s*export\\b\", case=False, na=False)\n",
    "    m2 = s.str.contains(r\"\\bexport\\s*bus\\b\", case=False, na=False) & s.str.contains(r\"\\bh2\\b\", case=False, na=False)\n",
    "    return net.buses.index[m1 | m2]\n",
    "\n",
    "\n",
    "def hourly_h2_export_quantity(net, agg=\"sum\") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Hourly H2 export quantity time series [MWh/h] (i.e., MW).\n",
    "    Uses all links that feed into the H2 export bus (bus1 in export buses).\n",
    "    \"\"\"\n",
    "    buses = h2_export_buses(net)\n",
    "    if len(buses) == 0:\n",
    "        raise ValueError(\"No H2 export buses found. Adjust heuristic in h2_export_buses().\")\n",
    "\n",
    "    links = net.links.copy()\n",
    "    export_links = links[links.bus1.isin(buses)]\n",
    "    if export_links.empty:\n",
    "        raise ValueError(\"No links feeding the H2 export bus found.\")\n",
    "\n",
    "    p1 = net.links_t.p1[export_links.index]  # MW\n",
    "\n",
    "    # Robust sign handling\n",
    "    pos = p1.clip(lower=0).sum().sum()\n",
    "    neg = (-p1).clip(lower=0).sum().sum()\n",
    "    flow = p1.clip(lower=0) if pos >= neg else (-p1).clip(lower=0)\n",
    "\n",
    "    s = flow.sum(axis=1) if agg == \"sum\" else flow.mean(axis=1)\n",
    "    s.name = \"H2 export quantity [MWh/h]\"\n",
    "    return s\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Snapshot weights -> hours per snapshot (needed for correct monthly MWh)\n",
    "# ============================================================\n",
    "\n",
    "def snapshot_hours(net) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Returns hours per snapshot as a Series indexed by net.snapshots.\n",
    "    Uses net.snapshot_weightings['generators'] if present, else 1 hour per snapshot.\n",
    "    \"\"\"\n",
    "    if hasattr(net, \"snapshot_weightings\") and net.snapshot_weightings is not None:\n",
    "        try:\n",
    "            if \"generators\" in net.snapshot_weightings:\n",
    "                w = net.snapshot_weightings[\"generators\"].copy()\n",
    "                # In PyPSA-Earth this is typically hours; keep as-is.\n",
    "                return w.reindex(net.snapshots)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return pd.Series(1.0, index=net.snapshots)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Monthly aggregation: sum_t (MW * hours) => MWh per month\n",
    "# ============================================================\n",
    "\n",
    "def monthly_export_mwh(net) -> pd.Series:\n",
    "    q = hourly_h2_export_quantity(net, agg=\"sum\")         # MW\n",
    "    h = snapshot_hours(net).reindex(q.index).fillna(0.0)  # hours\n",
    "    e = q * h                                             # MWh per snapshot\n",
    "\n",
    "    # Ensure DateTimeIndex for resample\n",
    "    if not isinstance(e.index, pd.DatetimeIndex):\n",
    "        e.index = pd.to_datetime(e.index)\n",
    "\n",
    "    m = e.resample(\"MS\").sum()  # Month Start frequency\n",
    "    m.name = \"Monthly H2 export [MWh]\"\n",
    "    return m\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Compute monthly sums for both scenarios\n",
    "# ============================================================\n",
    "\n",
    "m_uhs = monthly_export_mwh(uhs)\n",
    "m_wo  = monthly_export_mwh(woUHS)\n",
    "\n",
    "# Align months\n",
    "months = m_uhs.index.union(m_wo.index)\n",
    "m_uhs = m_uhs.reindex(months).fillna(0.0)\n",
    "m_wo  = m_wo.reindex(months).fillna(0.0)\n",
    "\n",
    "# Convert to TWh for nicer axis\n",
    "t_uhs = m_uhs / 1e6\n",
    "t_wo  = m_wo  / 1e6\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Plot: side-by-side bars per month (uhs vs woUHS)\n",
    "# ============================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "\n",
    "x = np.arange(len(months))\n",
    "width = 0.42\n",
    "\n",
    "ax.bar(x - width/2, t_uhs.values, width=width, label=\"uhs 2050\")\n",
    "ax.bar(x + width/2, t_wo.values,  width=width, label=\"woUHS 2050\")\n",
    "\n",
    "ax.set_title(\"Monthly Hâ export quantities (sum) â 2050\")\n",
    "ax.set_ylabel(\"Exported energy [TWh$_{H_2}$]\")\n",
    "ax.set_xlabel(\"Month\")\n",
    "ax.grid(True, axis=\"y\", alpha=0.25)\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([d.strftime(\"%b\") for d in months], rotation=0)\n",
    "\n",
    "# Legend below the plot\n",
    "ax.legend(\n",
    "    loc=\"upper center\",\n",
    "    bbox_to_anchor=(0.5, -0.18),\n",
    "    ncol=2,\n",
    "    frameon=True\n",
    ")\n",
    "\n",
    "fig.subplots_adjust(bottom=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f13d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _h2_store_groups(net):\n",
    "    \"\"\"\n",
    "    Return indices for different H2 store groups.\n",
    "    \"\"\"\n",
    "    stores = net.stores.copy()\n",
    "\n",
    "    h2_mask = stores.carrier.astype(str).str.contains(\"H2\", case=False, na=False)\n",
    "\n",
    "    uhs = stores.index[stores.carrier == \"H2 UHS\"]\n",
    "    other_h2 = stores.index[h2_mask & (stores.carrier != \"H2 UHS\")]\n",
    "\n",
    "    return uhs, other_h2\n",
    "\n",
    "\n",
    "def _plot_h2_store_totals_subplot(ax, net, title_prefix):\n",
    "    \"\"\"\n",
    "    Plot only aggregated H2 storage levels:\n",
    "      - Total UHS\n",
    "      - Total H2 Store Tank (non-UHS)\n",
    "      - Total H2 Stores (all)\n",
    "    \"\"\"\n",
    "    if not hasattr(net, \"stores_t\") or not hasattr(net.stores_t, \"e\"):\n",
    "        raise ValueError(\"net.stores_t.e not found â store time series missing.\")\n",
    "\n",
    "    uhs_idx, other_idx = _h2_store_groups(net)\n",
    "\n",
    "    if len(uhs_idx) + len(other_idx) == 0:\n",
    "        raise ValueError(\"No H2 stores found.\")\n",
    "\n",
    "    e = net.stores_t.e.loc[:, uhs_idx.union(other_idx)]  # MWh\n",
    "\n",
    "    total_uhs = e[uhs_idx].sum(axis=1) if len(uhs_idx) > 0 else None\n",
    "    total_other = e[other_idx].sum(axis=1) if len(other_idx) > 0 else None\n",
    "    total_all = e.sum(axis=1)\n",
    "\n",
    "    # --- Plot lines\n",
    "    if total_uhs is not None:\n",
    "        ax.plot(\n",
    "            total_uhs.index,\n",
    "            total_uhs.values,\n",
    "            linewidth=3.0,\n",
    "            color=\"black\",\n",
    "            label=\"Total UHS\"\n",
    "        )\n",
    "\n",
    "    if total_other is not None:\n",
    "        ax.plot(\n",
    "            total_other.index,\n",
    "            total_other.values,\n",
    "            linewidth=3.0,\n",
    "            linestyle=\"--\",\n",
    "            label=\"Total H2 Store Tank\"\n",
    "        )\n",
    "\n",
    "    ax.plot(\n",
    "        total_all.index,\n",
    "        total_all.values,\n",
    "        linewidth=3.5,\n",
    "        linestyle=\":\",\n",
    "        label=\"Total H2 Stores\"\n",
    "    )\n",
    "\n",
    "    # --- Formatting\n",
    "    ax.set_title(f\"{title_prefix}: Hydrogen Storage Inventory Levels\")\n",
    "    ax.set_ylabel(\"Stored Energy [MWh$_{H_2}$]\")\n",
    "    ax.grid(True, alpha=0.25)\n",
    "\n",
    "    ax.legend(\n",
    "        loc=\"upper center\",\n",
    "        bbox_to_anchor=(0.5, -0.18),\n",
    "        ncol=3,\n",
    "        frameon=True\n",
    "    )\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Two subplots: uhs vs woUHS\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    2, 1,\n",
    "    figsize=(30, 10),\n",
    "    sharex=True\n",
    ")\n",
    "\n",
    "_plot_h2_store_totals_subplot(axes[0], uhs, \"uhs\")\n",
    "_plot_h2_store_totals_subplot(axes[1], woUHS, \"woUHS\")\n",
    "\n",
    "axes[1].set_xlabel(\"Time\")\n",
    "\n",
    "fig.suptitle(\n",
    "    \"Time Series of Hydrogen Storage Inventory Levels\",\n",
    "    fontsize=16,\n",
    "    y=0.98\n",
    ")\n",
    "\n",
    "fig.subplots_adjust(hspace=0.6, bottom=0.12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a1c51a",
   "metadata": {},
   "source": [
    "##### Hourly Export Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c162de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def h2_export_buses(net) -> pd.Index:\n",
    "    \"\"\"\n",
    "    Identify H2 export buses (robust heuristic for PyPSA-Earth):\n",
    "    - bus name contains 'H2 export'\n",
    "    - OR contains 'export bus' and 'H2'\n",
    "    \"\"\"\n",
    "    names = pd.Index(net.buses.index.astype(str))\n",
    "    s = names.to_series(index=net.buses.index)\n",
    "    m1 = s.str.contains(r\"\\bh2\\s*export\\b\", case=False, na=False)\n",
    "    m2 = s.str.contains(r\"\\bexport\\s*bus\\b\", case=False, na=False) & s.str.contains(r\"\\bh2\\b\", case=False, na=False)\n",
    "    return net.buses.index[m1 | m2]\n",
    "\n",
    "\n",
    "def hourly_export_marginal_price(net, agg=\"mean\") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Hourly marginal price time series [â¬/MWh] at H2 export bus(es).\n",
    "    If multiple export buses exist, aggregates across buses per snapshot.\n",
    "    \"\"\"\n",
    "    if not hasattr(net, \"buses_t\") or not hasattr(net.buses_t, \"marginal_price\"):\n",
    "        raise ValueError(\"net.buses_t.marginal_price not found (no marginal prices stored).\")\n",
    "\n",
    "    buses = h2_export_buses(net)\n",
    "    if len(buses) == 0:\n",
    "        raise ValueError(\"No H2 export buses found. Adjust h2_export_buses().\")\n",
    "\n",
    "    mp = net.buses_t.marginal_price[buses]  # snapshots x buses (DataFrame or Series)\n",
    "\n",
    "    if isinstance(mp, pd.Series):\n",
    "        s = mp.copy()\n",
    "    else:\n",
    "        if agg == \"mean\":\n",
    "            s = mp.mean(axis=1)\n",
    "        elif agg == \"median\":\n",
    "            s = mp.median(axis=1)\n",
    "        elif agg == \"min\":\n",
    "            s = mp.min(axis=1)\n",
    "        elif agg == \"max\":\n",
    "            s = mp.max(axis=1)\n",
    "        else:\n",
    "            raise ValueError(\"agg must be one of: mean, median, min, max\")\n",
    "\n",
    "    s.name = f\"H2 export marginal price ({agg}) [â¬/MWh]\"\n",
    "    return s\n",
    "\n",
    "\n",
    "def hourly_h2_export_quantity(net, agg=\"sum\") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Hourly H2 export quantity [MWh/h] (i.e., MW) as flow into export bus(es).\n",
    "    Uses all links feeding into the export bus (bus1 in export buses).\n",
    "    \"\"\"\n",
    "    buses = h2_export_buses(net)\n",
    "    if len(buses) == 0:\n",
    "        raise ValueError(\"No H2 export buses found. Adjust h2_export_buses().\")\n",
    "\n",
    "    links = net.links.copy()\n",
    "    export_links = links[links.bus1.isin(buses)]\n",
    "    if export_links.empty:\n",
    "        raise ValueError(\"No links feeding the H2 export bus found.\")\n",
    "\n",
    "    p1 = net.links_t.p1[export_links.index]  # MW\n",
    "\n",
    "    # Robust sign handling: choose direction with larger total positive flow\n",
    "    pos = p1.clip(lower=0).sum().sum()\n",
    "    neg = (-p1).clip(lower=0).sum().sum()\n",
    "    flow = p1.clip(lower=0) if pos >= neg else (-p1).clip(lower=0)\n",
    "\n",
    "    if agg == \"sum\":\n",
    "        s = flow.sum(axis=1)\n",
    "    elif agg == \"mean\":\n",
    "        s = flow.mean(axis=1)\n",
    "    else:\n",
    "        raise ValueError(\"agg must be 'sum' or 'mean'\")\n",
    "\n",
    "    s.name = \"H2 export quantity [MWh/h]\"\n",
    "    return s\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Hourly export revenue (â¬/h): quantity [MWh/h] * price [â¬/MWh]\n",
    "# ============================================================\n",
    "\n",
    "def hourly_export_revenue(net, price_agg=\"mean\") -> pd.Series:\n",
    "    q = hourly_h2_export_quantity(net, agg=\"sum\")          # MWh/h\n",
    "    p = hourly_export_marginal_price(net, agg=price_agg)   # â¬/MWh\n",
    "\n",
    "    idx = q.index.intersection(p.index)\n",
    "    q = q.loc[idx]\n",
    "    p = p.loc[idx]\n",
    "\n",
    "    rev = q * p  # â¬/h\n",
    "    rev.name = \"H2 export revenue [â¬/h]\"\n",
    "    return rev\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Compute + align both scenarios\n",
    "# ============================================================\n",
    "\n",
    "rev_uhs = hourly_export_revenue(uhs, price_agg=\"mean\")\n",
    "rev_wo  = hourly_export_revenue(woUHS, price_agg=\"mean\")\n",
    "\n",
    "idx = rev_uhs.index.intersection(rev_wo.index)\n",
    "rev_uhs = rev_uhs.loc[idx]\n",
    "rev_wo  = rev_wo.loc[idx]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Plot (one line per scenario)\n",
    "# ============================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "\n",
    "ax.plot(rev_uhs.index, rev_uhs.values / 1e6, label=\"uhs 2050\", linewidth=1.8)\n",
    "ax.plot(rev_wo.index,  rev_wo.values  / 1e6, label=\"woUHS 2050\", linewidth=1.8)\n",
    "\n",
    "ax.set_title(\"Hourly Hâ export revenue â 2050\")\n",
    "ax.set_xlabel(\"Snapshot\")\n",
    "ax.set_ylabel(\"Export revenue [Mâ¬/h]\")\n",
    "ax.grid(True, alpha=0.25)\n",
    "\n",
    "# Legend below plot\n",
    "ax.legend(\n",
    "    loc=\"upper center\",\n",
    "    bbox_to_anchor=(0.5, -0.18),\n",
    "    ncol=2,\n",
    "    frameon=True\n",
    ")\n",
    "\n",
    "fig.subplots_adjust(bottom=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9aa552",
   "metadata": {},
   "source": [
    "#### Supply stabilizing effect of H2 Stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1338a087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ensure_dt_index(x):\n",
    "    if not isinstance(x.index, pd.DatetimeIndex):\n",
    "        x = x.copy()\n",
    "        x.index = pd.to_datetime(x.index)\n",
    "    return x\n",
    "\n",
    "\n",
    "def _h2_buses(net) -> pd.Index:\n",
    "    \"\"\"Project convention: hydrogen buses are those with carrier == 'H2'.\"\"\"\n",
    "    return net.buses.index[net.buses.carrier == \"H2\"]\n",
    "\n",
    "\n",
    "def _h2_store_ids(net) -> pd.Index:\n",
    "    \"\"\"All H2-related stores by store carrier name (includes H2 UHS and H2 tanks).\"\"\"\n",
    "    if not hasattr(net, \"stores\") or net.stores.empty:\n",
    "        return pd.Index([])\n",
    "    return net.stores.index[net.stores.carrier.astype(str).str.contains(\"H2\", case=False, na=False)]\n",
    "\n",
    "\n",
    "def _link_net_injection_to_h2(net, link_idx: pd.Index) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Net injection into H2 buses from a given subset of links [MW].\n",
    "    Positive => net injection into H2 buses. Negative => net withdrawal from H2 buses.\n",
    "    Uses: injection at a bus is approximately -p_k for that port.\n",
    "    \"\"\"\n",
    "    h2 = _h2_buses(net)\n",
    "    s = pd.Series(0.0, index=net.snapshots)\n",
    "\n",
    "    for k in range(5):\n",
    "        bus_col = f\"bus{k}\"\n",
    "        p_col = f\"p{k}\"\n",
    "        if bus_col in net.links.columns and hasattr(net.links_t, p_col):\n",
    "            # Only consider selected links\n",
    "            present = net.links.index.intersection(link_idx)\n",
    "            if len(present) == 0:\n",
    "                continue\n",
    "\n",
    "            # Only ports where this port bus is H2\n",
    "            mask = net.links.loc[present, bus_col].isin(h2)\n",
    "            if mask.any():\n",
    "                idx = present[mask.values]\n",
    "                pk = getattr(net.links_t, p_col)[idx]  # snapshots x links\n",
    "                inj = (-pk).sum(axis=1)               # injection into H2 buses from these ports\n",
    "                s = s.add(inj, fill_value=0.0)\n",
    "\n",
    "    return _ensure_dt_index(s)\n",
    "\n",
    "\n",
    "def _is_h2_bus(net, buses: pd.Series) -> pd.Series:\n",
    "    h2 = set(_h2_buses(net))\n",
    "    return buses.isin(h2)\n",
    "\n",
    "\n",
    "def _final_h2_offtake_links(net, production_carriers, pipeline_carriers) -> pd.Index:\n",
    "    \"\"\"\n",
    "    Links that represent *final* offtake from the H2 system:\n",
    "    - at least one port connected to an H2 bus\n",
    "    - at least one port connected to a non-H2 bus (i.e., crosses the H2 boundary)\n",
    "    - exclude production tech carriers (electrolysis/SMR etc.)\n",
    "    - exclude H2-H2 pipelines (internal transport)\n",
    "    \"\"\"\n",
    "    links = net.links.copy()\n",
    "\n",
    "    # Identify per-link whether it touches H2 and non-H2 buses\n",
    "    touches_h2 = pd.Series(False, index=links.index)\n",
    "    touches_non_h2 = pd.Series(False, index=links.index)\n",
    "\n",
    "    for k in range(5):\n",
    "        bus_col = f\"bus{k}\"\n",
    "        if bus_col in links.columns:\n",
    "            b = links[bus_col]\n",
    "            m_h2 = _is_h2_bus(net, b)\n",
    "            touches_h2 |= m_h2\n",
    "            touches_non_h2 |= ~m_h2 & b.notna()\n",
    "\n",
    "    crosses_boundary = touches_h2 & touches_non_h2\n",
    "\n",
    "    # Exclusions\n",
    "    is_prod = links.carrier.isin(production_carriers)\n",
    "    is_pipe = links.carrier.isin(pipeline_carriers)\n",
    "\n",
    "    idx = links.index[crosses_boundary & (~is_prod) & (~is_pipe)]\n",
    "    return idx\n",
    "\n",
    "\n",
    "def _production_links(net, production_carriers) -> pd.Index:\n",
    "    \"\"\"Links that are considered primary H2 producers.\"\"\"\n",
    "    links = net.links.copy()\n",
    "    idx = links.index[links.carrier.isin(production_carriers)]\n",
    "    return idx\n",
    "\n",
    "\n",
    "def _h2_store_power(net) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Total H2-store power [MW]:\n",
    "      + = discharge (injection to H2)\n",
    "      - = charge (withdrawal from H2)\n",
    "    \"\"\"\n",
    "    sids = _h2_store_ids(net)\n",
    "    if len(sids) == 0:\n",
    "        return _ensure_dt_index(pd.Series(0.0, index=net.snapshots))\n",
    "\n",
    "    if not hasattr(net, \"stores_t\") or not hasattr(net.stores_t, \"p\"):\n",
    "        raise ValueError(\"net.stores_t.p not found â store power time series missing.\")\n",
    "\n",
    "    s = net.stores_t.p[sids].sum(axis=1)\n",
    "    return _ensure_dt_index(s)\n",
    "\n",
    "\n",
    "def _h2_store_energy(net) -> pd.Series:\n",
    "    \"\"\"Total H2-store energy level [MWh].\"\"\"\n",
    "    sids = _h2_store_ids(net)\n",
    "    if len(sids) == 0:\n",
    "        return _ensure_dt_index(pd.Series(0.0, index=net.snapshots))\n",
    "\n",
    "    if not hasattr(net, \"stores_t\") or not hasattr(net.stores_t, \"e\"):\n",
    "        raise ValueError(\"net.stores_t.e not found â store energy time series missing.\")\n",
    "\n",
    "    s = net.stores_t.e[sids].sum(axis=1)\n",
    "    return _ensure_dt_index(s)\n",
    "\n",
    "\n",
    "def _plotA_signals(\n",
    "    net,\n",
    "    production_carriers=(\"H2 Electrolysis\", \"SMR\", \"SMR CC\"),\n",
    "    pipeline_carriers=(\"H2 pipeline\", \"H2 pipeline repurposed\")\n",
    "):\n",
    "    \"\"\"\n",
    "    Build corrected Plot A signals:\n",
    "      Supply   = primary H2 production into H2 buses (from selected production carriers)\n",
    "      Demand   = final H2 offtake crossing from H2 buses to non-H2 buses (excluding production & pipelines)\n",
    "      Storage  = store charge/discharge from stores_t.p\n",
    "      Level    = store inventory from stores_t.e\n",
    "    \"\"\"\n",
    "    prod_idx = _production_links(net, production_carriers)\n",
    "    off_idx  = _final_h2_offtake_links(net, production_carriers, pipeline_carriers)\n",
    "\n",
    "    net_inj_prod = _link_net_injection_to_h2(net, prod_idx)   # MW, expected >=0\n",
    "    net_inj_off  = _link_net_injection_to_h2(net, off_idx)    # MW, expected <=0 (withdrawal)\n",
    "\n",
    "    supply = net_inj_prod.clip(lower=0.0)\n",
    "    demand = (-net_inj_off).clip(lower=0.0)\n",
    "\n",
    "    store_p = _h2_store_power(net)\n",
    "    store_e = _h2_store_energy(net)\n",
    "\n",
    "    return dict(\n",
    "        supply=supply,                                  # MW\n",
    "        demand=demand,                                  # MW\n",
    "        storage_discharge=store_p.clip(lower=0.0),       # MW\n",
    "        storage_charge=(-store_p).clip(lower=0.0),       # MW\n",
    "        storage_level=store_e                            # MWh\n",
    "    )\n",
    "\n",
    "\n",
    "def _slice_signals(sig: dict, start=None, end=None) -> dict:\n",
    "    idx = sig[\"supply\"].index\n",
    "    if start is None:\n",
    "        start = idx.min()\n",
    "    else:\n",
    "        start = pd.to_datetime(start)\n",
    "    if end is None:\n",
    "        end = idx.max()\n",
    "    else:\n",
    "        end = pd.to_datetime(end)\n",
    "\n",
    "    return {k: v.loc[start:end] for k, v in sig.items()}, start, end\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Corrected Plot A with configurable time window\n",
    "# ============================================================\n",
    "\n",
    "def plot_A_corrected(\n",
    "    uhs_net,\n",
    "    wo_net,\n",
    "    start=None,\n",
    "    end=None,\n",
    "    production_carriers=(\"H2 Electrolysis\", \"SMR\", \"SMR CC\"),\n",
    "    pipeline_carriers=(\"H2 pipeline\", \"H2 pipeline repurposed\")\n",
    "):\n",
    "    u = _plotA_signals(uhs_net, production_carriers, pipeline_carriers)\n",
    "    w = _plotA_signals(wo_net,  production_carriers, pipeline_carriers)\n",
    "\n",
    "    # Align time index across both scenarios\n",
    "    common = u[\"supply\"].index.intersection(w[\"supply\"].index)\n",
    "    for sig in (u, w):\n",
    "        for k in sig:\n",
    "            sig[k] = sig[k].loc[common]\n",
    "\n",
    "    # Slice (configurable window)\n",
    "    u, s, e = _slice_signals(u, start=start, end=end)\n",
    "    w, _, _ = _slice_signals(w, start=s, end=e)\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        2, 2, figsize=(18, 7.5), sharex=\"col\",\n",
    "        gridspec_kw={\"height_ratios\": [1.2, 1.0]}\n",
    "    )\n",
    "\n",
    "    # ---- Top row: flows\n",
    "    for ax, sig, title in zip(axes[0], [u, w], [\"uhs\", \"woUHS\"]):\n",
    "        ax.plot(sig[\"supply\"].index, sig[\"supply\"].values,\n",
    "                linewidth=1.8, label=\"H2 supply (primary production into H2 buses)\")\n",
    "        # ax.plot(sig[\"demand\"].index, sig[\"demand\"].values,\n",
    "                # linewidth=1.8, label=\"H2 demand (final offtake from H2 buses)\")\n",
    "\n",
    "        ax.fill_between(sig[\"storage_discharge\"].index, 0, sig[\"storage_discharge\"].values,\n",
    "                        alpha=0.12, label=\"Storage discharge (+)\")\n",
    "        ax.fill_between(sig[\"storage_charge\"].index, 0, sig[\"storage_charge\"].values,\n",
    "                        alpha=0.12, label=\"Storage charge (-)\")\n",
    "\n",
    "        ax.set_title(f\"{title}: H2 supply / storage operation\")\n",
    "        ax.set_ylabel(\"Power [MW$_{H2}$]\")\n",
    "        ax.grid(True, alpha=0.25)\n",
    "\n",
    "    # ---- Bottom row: inventory\n",
    "    for ax, sig, title in zip(axes[1], [u, w], [\"uhs\", \"woUHS\"]):\n",
    "        ax.plot(sig[\"storage_level\"].index, sig[\"storage_level\"].values,\n",
    "                linewidth=1.8, label=\"Total H2 store level\")\n",
    "        ax.set_title(f\"{title}: Total H2 storage inventory\")\n",
    "        ax.set_ylabel(\"Energy [MWh$_{H2}$]\")\n",
    "        ax.grid(True, alpha=0.25)\n",
    "        ax.set_xlabel(\"Time\")\n",
    "\n",
    "    # ---- Figure-level legend below\n",
    "    handles, labels = [], []\n",
    "    for ax in [axes[0, 0], axes[1, 0]]:\n",
    "        h, l = ax.get_legend_handles_labels()\n",
    "        for hh, ll in zip(h, l):\n",
    "            if ll not in labels:\n",
    "                handles.append(hh)\n",
    "                labels.append(ll)\n",
    "\n",
    "    fig.legend(\n",
    "        handles, labels,\n",
    "        loc=\"upper center\",\n",
    "        bbox_to_anchor=(0.5, -0.02),\n",
    "        ncol=4,\n",
    "        frameon=True\n",
    "    )\n",
    "\n",
    "    fig.suptitle(f\"Hydrogen supplyâstorage dynamics\", y=0.98)\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(bottom=0.18)\n",
    "    for ax in axes.flatten():\n",
    "        ax.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%b-%d\"))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plot_A_corrected(uhs, woUHS, start=\"2013-01-01\", end=\"2013-01-15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbeb56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lcos_scatter_kg_zoom(\n",
    "    lcos_df,\n",
    "    zoom_mode=\"p99\",          # \"p99\" (robust) or \"manual\"\n",
    "    y_max_kg=None,            # only used if zoom_mode=\"manual\"\n",
    "    annotate_top_n=6,\n",
    "    title=\"LCOS of H2 storages: cost vs utilization (â¬/kg, zoomed)\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Scatter plot:\n",
    "      x = full_cycles_per_year\n",
    "      y = LCOS_EUR_per_kg\n",
    "      size = e_nom_used_MWh (proxy for scale)\n",
    "      color = carrier\n",
    "      dashed line = weighted-average LCOS (â¬/kg) (throughput-weighted)\n",
    "\n",
    "    Zoom:\n",
    "      - zoom_mode=\"p99\": y-limit = 99th percentile (caps extreme outliers)\n",
    "      - zoom_mode=\"manual\": y-limit = y_max_kg\n",
    "    \"\"\"\n",
    "    df = lcos_df.copy()\n",
    "    if \"LCOS_EUR_per_kg\" not in df.columns:\n",
    "        raise ValueError(\"Expected column 'LCOS_EUR_per_kg' in lcos_df.\")\n",
    "    if \"full_cycles_per_year\" not in df.columns:\n",
    "        raise ValueError(\"Expected column 'full_cycles_per_year' in lcos_df.\")\n",
    "    if \"e_nom_used_MWh\" not in df.columns:\n",
    "        raise ValueError(\"Expected column 'e_nom_used_MWh' in lcos_df.\")\n",
    "    if \"carrier\" not in df.columns:\n",
    "        raise ValueError(\"Expected column 'carrier' in lcos_df.\")\n",
    "\n",
    "    # Weighted avg LCOS line (â¬/kg)\n",
    "    wavg_kg = df.attrs.get(\"weighted_LCOS_EUR_per_kg\", None)\n",
    "    if wavg_kg is None:\n",
    "        # fallback: compute from discharged_MWh if present\n",
    "        if \"discharged_MWh\" in df.columns:\n",
    "            eps = 1e-9\n",
    "            wavg_mwh = float((df[\"LCOS_EUR_per_MWh\"] * df[\"discharged_MWh\"]).sum() / (df[\"discharged_MWh\"].sum() + eps))\n",
    "            wavg_kg = wavg_mwh * (33.33 / 1000.0)\n",
    "\n",
    "    # Marker size scaling\n",
    "    size = df[\"e_nom_used_MWh\"].values.astype(float)\n",
    "    s_min, s_max = np.percentile(size, 5), np.percentile(size, 95)\n",
    "    s_scaled = 30 + 220 * (np.clip(size, s_min, s_max) - s_min) / max(s_max - s_min, 1e-9)\n",
    "\n",
    "    # Determine zoom limit\n",
    "    y = df[\"LCOS_EUR_per_kg\"].values.astype(float)\n",
    "    if zoom_mode == \"p99\":\n",
    "        y_cap = float(np.nanpercentile(y, 99))\n",
    "        # ensure we still see the weighted average line comfortably\n",
    "        if wavg_kg is not None:\n",
    "            y_cap = max(y_cap, 1.6 * float(wavg_kg))\n",
    "    elif zoom_mode == \"manual\":\n",
    "        if y_max_kg is None:\n",
    "            raise ValueError(\"For zoom_mode='manual' you must set y_max_kg.\")\n",
    "        y_cap = float(y_max_kg)\n",
    "    else:\n",
    "        raise ValueError(\"zoom_mode must be 'p99' or 'manual'.\")\n",
    "\n",
    "    # Plot by carrier for clean legend\n",
    "    carriers = list(pd.unique(df[\"carrier\"].astype(str)))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10.5, 6))\n",
    "\n",
    "    for carr in carriers:\n",
    "        m = df[\"carrier\"].astype(str) == carr\n",
    "        ax.scatter(\n",
    "            df.loc[m, \"full_cycles_per_year\"].values,\n",
    "            df.loc[m, \"LCOS_EUR_per_kg\"].values,\n",
    "            s=s_scaled[m.values],\n",
    "            alpha=0.78,\n",
    "            label=carr\n",
    "        )\n",
    "\n",
    "    # Weighted-average line\n",
    "    if wavg_kg is not None:\n",
    "        ax.axhline(float(wavg_kg), linewidth=1.6, linestyle=\"--\", label=\"Weighted avg LCOS\")\n",
    "\n",
    "    ax.set_xlabel(\"Full cycles per year [-]\")\n",
    "    ax.set_ylabel(\"LCOS [â¬/kg discharged] (LHV)\")\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True, alpha=0.25)\n",
    "\n",
    "    # Zoom\n",
    "    ax.set_ylim(0, y_cap)\n",
    "\n",
    "    # Annotate (highest within zoom window, so labels focus on relevant outliers)\n",
    "    if annotate_top_n and annotate_top_n > 0:\n",
    "        dfa = df[df[\"LCOS_EUR_per_kg\"] <= y_cap].copy()\n",
    "        top = dfa.sort_values(\"LCOS_EUR_per_kg\", ascending=False).head(annotate_top_n)\n",
    "        for name, row in top.iterrows():\n",
    "            ax.annotate(\n",
    "                str(name),\n",
    "                (row[\"full_cycles_per_year\"], row[\"LCOS_EUR_per_kg\"]),\n",
    "                textcoords=\"offset points\",\n",
    "                xytext=(6, 6),\n",
    "                ha=\"left\",\n",
    "                fontsize=9\n",
    "            )\n",
    "\n",
    "    # Legend below plot\n",
    "    ax.legend(\n",
    "        loc=\"upper center\",\n",
    "        bbox_to_anchor=(0.5, -0.18),\n",
    "        ncol=min(4, len(carriers) + 1),\n",
    "        frameon=True\n",
    "    )\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(bottom=0.22)\n",
    "    plt.show()\n",
    "\n",
    "def _snapshot_weights_hours(net):\n",
    "    \"\"\"\n",
    "    Returns hours per snapshot (usually 1 for hourly, or net.snapshot_weightings['generators'] in PyPSA-Earth).\n",
    "    \"\"\"\n",
    "    if hasattr(net, \"snapshot_weightings\") and net.snapshot_weightings is not None:\n",
    "        try:\n",
    "            if \"generators\" in net.snapshot_weightings:\n",
    "                return net.snapshot_weightings[\"generators\"].reindex(net.snapshots)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return pd.Series(1.0, index=net.snapshots)\n",
    "\n",
    "def lcos_h2_stores(\n",
    "    net,\n",
    "    include_carriers_regex=r\"H2\",        # include store carriers containing \"H2\"\n",
    "    exclude_carriers_regex=None,         # optional exclusion regex\n",
    "    h2_lhv_kwh_per_kg=33.33,             # LHV for â¬/kg conversion\n",
    "    min_selected_mwh=1e-6,               # selection threshold for e_nom(_opt)\n",
    "    include_variable_opex=True           # include store marginal_cost on discharged energy\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes levelized cost of storage service (LCOS) per selected H2 store.\n",
    "\n",
    "    LCOS definition (storage service):\n",
    "      LCOS = (annualized CAPEX + variable OPEX) / discharged_energy\n",
    "\n",
    "    Assumptions:\n",
    "      - net.stores.capital_cost is annualized (common in PyPSA-Earth).\n",
    "      - discharged_energy is sum over positive store power p (MW) * snapshot_hours.\n",
    "\n",
    "    Returns a DataFrame indexed by store name, with:\n",
    "      carrier, bus, e_nom_used_MWh, capex_annual_EUR, discharged_MWh,\n",
    "      var_opex_annual_EUR, LCOS_EUR_per_MWh, LCOS_EUR_per_kg, full_cycles_per_year\n",
    "\n",
    "    Also stores in df.attrs:\n",
    "      weighted_LCOS_EUR_per_MWh, weighted_LCOS_EUR_per_kg (throughput-weighted)\n",
    "    \"\"\"\n",
    "    if not hasattr(net, \"stores\") or net.stores.empty:\n",
    "        raise ValueError(\"net.stores is empty or missing.\")\n",
    "\n",
    "    stores = net.stores.copy()\n",
    "    carriers = stores[\"carrier\"].astype(str)\n",
    "\n",
    "    mask = carriers.str.contains(include_carriers_regex, case=False, na=False)\n",
    "    if exclude_carriers_regex:\n",
    "        mask &= ~carriers.str.contains(exclude_carriers_regex, case=False, na=False)\n",
    "\n",
    "    st = stores[mask].copy()\n",
    "    if st.empty:\n",
    "        raise ValueError(\"No stores matched the include/exclude carrier filters.\")\n",
    "\n",
    "    # Capacity column\n",
    "    e_col = \"e_nom_opt\" if \"e_nom_opt\" in st.columns else \"e_nom\"\n",
    "    st[\"e_nom_used_MWh\"] = st[e_col].fillna(0.0)\n",
    "\n",
    "    # Selected/built stores\n",
    "    st = st[st[\"e_nom_used_MWh\"] > min_selected_mwh].copy()\n",
    "    if st.empty:\n",
    "        raise ValueError(\"No selected/built H2 stores found (e_nom_opt/e_nom ~ 0).\")\n",
    "\n",
    "    # Dispatch time series\n",
    "    if not hasattr(net, \"stores_t\") or not hasattr(net.stores_t, \"p\"):\n",
    "        raise ValueError(\"net.stores_t.p not found â store dispatch time series missing.\")\n",
    "\n",
    "    w = _snapshot_weights_hours(net)\n",
    "\n",
    "    # Discharged energy (MWh) = sum_t max(p,0) * hours\n",
    "    p = net.stores_t.p[st.index]  # MW\n",
    "    discharged_MWh = (p.clip(lower=0.0).mul(w, axis=0)).sum(axis=0)\n",
    "\n",
    "    # Annualized CAPEX\n",
    "    capex_annual = st[\"e_nom_used_MWh\"] * st[\"capital_cost\"].fillna(0.0)\n",
    "\n",
    "    # Variable OPEX on discharged energy\n",
    "    if include_variable_opex and \"marginal_cost\" in st.columns:\n",
    "        mc = st[\"marginal_cost\"].fillna(0.0)  # â¬/MWh\n",
    "        var_opex_annual = discharged_MWh * mc\n",
    "    else:\n",
    "        var_opex_annual = pd.Series(0.0, index=st.index)\n",
    "\n",
    "    eps = 1e-9\n",
    "    lcos_eur_per_mwh = (capex_annual + var_opex_annual) / (discharged_MWh + eps)\n",
    "\n",
    "    # â¬/MWh -> â¬/kg using LHV\n",
    "    mwh_per_kg = h2_lhv_kwh_per_kg / 1000.0\n",
    "    lcos_eur_per_kg = lcos_eur_per_mwh * mwh_per_kg\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"carrier\": st[\"carrier\"].astype(str),\n",
    "        \"bus\": st[\"bus\"].astype(str) if \"bus\" in st.columns else \"\",\n",
    "        \"e_nom_used_MWh\": st[\"e_nom_used_MWh\"],\n",
    "        \"capital_cost_EUR_per_MWhcap_a\": st[\"capital_cost\"],\n",
    "        \"capex_annual_EUR\": capex_annual,\n",
    "        \"discharged_MWh\": discharged_MWh,\n",
    "        \"marginal_cost_EUR_per_MWh\": st[\"marginal_cost\"] if \"marginal_cost\" in st.columns else np.nan,\n",
    "        \"var_opex_annual_EUR\": var_opex_annual,\n",
    "        \"LCOS_EUR_per_MWh\": lcos_eur_per_mwh,\n",
    "        \"LCOS_EUR_per_kg\": lcos_eur_per_kg,\n",
    "    }, index=st.index)\n",
    "\n",
    "    out[\"full_cycles_per_year\"] = out[\"discharged_MWh\"] / (out[\"e_nom_used_MWh\"] + eps)\n",
    "\n",
    "    # Throughput-weighted average LCOS\n",
    "    weighted_mwh = float(\n",
    "        (out[\"LCOS_EUR_per_MWh\"] * out[\"discharged_MWh\"]).sum() / (out[\"discharged_MWh\"].sum() + eps)\n",
    "    )\n",
    "    out.attrs[\"weighted_LCOS_EUR_per_MWh\"] = weighted_mwh\n",
    "    out.attrs[\"weighted_LCOS_EUR_per_kg\"] = weighted_mwh * mwh_per_kg\n",
    "\n",
    "    return out.sort_values(\"LCOS_EUR_per_MWh\")\n",
    "\n",
    "lcos_all = lcos_h2_stores(\n",
    "    uhs,\n",
    "    include_carriers_regex=r\"H2\",    # all H2-related store carriers\n",
    "    exclude_carriers_regex=None,\n",
    "    include_variable_opex=True\n",
    ")\n",
    "\n",
    "\n",
    "plot_lcos_scatter_kg_zoom(lcos_all, zoom_mode=\"manual\", y_max_kg=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6b5fba",
   "metadata": {},
   "source": [
    "#### Show PV and Wind Potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19409ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SETTINGS\n",
    "# ============================================================\n",
    "\n",
    "net = uhs\n",
    "\n",
    "# Adjust carriers to your network naming\n",
    "WIND_CARRIERS = [\"onwind\", \"offwind-ac\", \"offwind-dc\", \"wind\"]\n",
    "SOLAR_CARRIERS = [\"solar\", \"solar rooftop\", \"pv\"]\n",
    "\n",
    "# Choose how to aggregate multiple buses per polygon:\n",
    "#   \"mean\"          -> simple average of bus FLH in the polygon\n",
    "#   \"cap_weighted\"  -> capacity-weighted average (recommended)\n",
    "AGG_METHOD = \"cap_weighted\"\n",
    "\n",
    "# Optional: choose which polygon id/name column to show in titles / debugging\n",
    "# If you don't know, set to None; code will still work.\n",
    "REGION_NAME_COL = None  # e.g. \"NAME_1\" or \"name\" depending on your gadm_shapes\n",
    "\n",
    "FIGSIZE = (10, 8)\n",
    "\n",
    "# You must have:\n",
    "#   gadm_shapes : GeoDataFrame with polygons, CRS EPSG:4326 (or will be converted)\n",
    "# already loaded in your notebook.\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# HELPERS\n",
    "# ============================================================\n",
    "\n",
    "def _snapshot_weights(net):\n",
    "    if hasattr(net, \"snapshot_weightings\") and net.snapshot_weightings is not None:\n",
    "        try:\n",
    "            if \"generators\" in net.snapshot_weightings:\n",
    "                return net.snapshot_weightings[\"generators\"]\n",
    "        except Exception:\n",
    "            pass\n",
    "    return pd.Series(1.0, index=net.snapshots)\n",
    "\n",
    "\n",
    "def _bus_points_gdf(net):\n",
    "    \"\"\"Bus points as GeoDataFrame (EPSG:4326).\"\"\"\n",
    "    buses = net.buses.copy()\n",
    "    buses = buses.dropna(subset=[\"x\", \"y\"])\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        buses,\n",
    "        geometry=gpd.points_from_xy(buses[\"x\"], buses[\"y\"]),\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "    return gdf\n",
    "\n",
    "\n",
    "def flh_by_bus(net, carriers):\n",
    "    \"\"\"\n",
    "    Full-load hours per bus for given generator carriers:\n",
    "      FLH_bus = sum(E_gen_bus) / sum(P_nom_bus)\n",
    "    Returns:\n",
    "      flh (Series indexed by bus)\n",
    "      p_bus (Series indexed by bus) installed capacity [MW] used for weighting\n",
    "    \"\"\"\n",
    "    w = _snapshot_weights(net)\n",
    "\n",
    "    gens = net.generators.copy()\n",
    "    gens = gens[gens.carrier.astype(str).isin(carriers)].copy()\n",
    "    if gens.empty:\n",
    "        return pd.Series(dtype=float), pd.Series(dtype=float)\n",
    "\n",
    "    pnom_col = \"p_nom_opt\" if \"p_nom_opt\" in gens.columns else \"p_nom\"\n",
    "    p_nom = gens[pnom_col].fillna(0.0)\n",
    "\n",
    "    # Production time series [MW]\n",
    "    p = net.generators_t.p[gens.index]\n",
    "    e_mwh = (p.mul(w, axis=0)).sum(axis=0)  # MWh/a per generator\n",
    "\n",
    "    # Aggregate to bus\n",
    "    e_bus = e_mwh.groupby(gens[\"bus\"]).sum()\n",
    "    p_bus = p_nom.groupby(gens[\"bus\"]).sum()\n",
    "\n",
    "    flh = (e_bus / p_bus.replace(0.0, np.nan)).dropna()\n",
    "    p_bus = p_bus.reindex(flh.index).fillna(0.0)\n",
    "\n",
    "    return flh, p_bus\n",
    "\n",
    "\n",
    "def aggregate_bus_metric_to_polygons(gadm_shapes, bus_gdf, metric_bus, weight_bus=None, agg_method=\"cap_weighted\"):\n",
    "    \"\"\"\n",
    "    Spatial join bus points -> polygons, then aggregate bus metric to polygon level.\n",
    "\n",
    "    Returns a copy of gadm_shapes with new column 'value' (polygon-level metric).\n",
    "    \"\"\"\n",
    "    # Ensure CRS match\n",
    "    poly = gadm_shapes.copy()\n",
    "    if poly.crs is None:\n",
    "        poly = poly.set_crs(\"EPSG:4326\")\n",
    "    if bus_gdf.crs is None:\n",
    "        bus_gdf = bus_gdf.set_crs(\"EPSG:4326\")\n",
    "    if poly.crs != bus_gdf.crs:\n",
    "        bus_gdf = bus_gdf.to_crs(poly.crs)\n",
    "\n",
    "    # Prepare bus dataframe for join\n",
    "    b = bus_gdf.loc[metric_bus.index].copy()\n",
    "    b[\"metric\"] = metric_bus\n",
    "    if weight_bus is not None:\n",
    "        b[\"weight\"] = weight_bus.reindex(metric_bus.index).fillna(0.0)\n",
    "    else:\n",
    "        b[\"weight\"] = 1.0\n",
    "\n",
    "    # Spatial join: assign each bus point to a polygon\n",
    "    joined = gpd.sjoin(b[[\"metric\", \"weight\", \"geometry\"]], poly, how=\"inner\", predicate=\"within\")\n",
    "    # joined has index_right = polygon index\n",
    "    if joined.empty:\n",
    "        out = poly.copy()\n",
    "        out[\"value\"] = np.nan\n",
    "        return out\n",
    "\n",
    "    if agg_method == \"mean\":\n",
    "        poly_val = joined.groupby(\"index_right\")[\"metric\"].mean()\n",
    "\n",
    "    elif agg_method == \"cap_weighted\":\n",
    "        # weighted mean: sum(metric*weight) / sum(weight)\n",
    "        num = (joined[\"metric\"] * joined[\"weight\"]).groupby(joined[\"index_right\"]).sum()\n",
    "        den = joined[\"weight\"].groupby(joined[\"index_right\"]).sum().replace(0.0, np.nan)\n",
    "        poly_val = (num / den)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"agg_method must be 'mean' or 'cap_weighted'\")\n",
    "\n",
    "    out = poly.copy()\n",
    "    out[\"value\"] = poly_val.reindex(out.index)\n",
    "    return out\n",
    "\n",
    "\n",
    "def plot_polygon_map(gdf_polys, title, cmap=\"viridis\"):\n",
    "    fig, ax = plt.subplots(figsize=FIGSIZE)\n",
    "\n",
    "    # Base polygons in light gray if NaN\n",
    "    gdf_polys.plot(ax=ax, color=\"whitesmoke\", edgecolor=\"black\", linewidth=0.4)\n",
    "\n",
    "    # Colored overlay where value exists\n",
    "    gdf_polys.dropna(subset=[\"value\"]).plot(\n",
    "        ax=ax,\n",
    "        column=\"value\",\n",
    "        cmap=cmap,\n",
    "        legend=True,\n",
    "        legend_kwds={\"label\": \"Full-load hours [h/a]\"},\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=0.4\n",
    "    )\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# RUN: WIND + SOLAR maps\n",
    "# ============================================================\n",
    "\n",
    "# 1) Prepare bus points once\n",
    "bus_gdf = _bus_points_gdf(net)\n",
    "\n",
    "# 2) WIND FLH per bus\n",
    "wind_present = [c for c in WIND_CARRIERS if c in set(net.generators.carrier.astype(str).unique())]\n",
    "if len(wind_present) == 0:\n",
    "    print(\"No WIND carriers found. Available generator carriers:\\n\", net.generators.carrier.unique())\n",
    "else:\n",
    "    flh_wind, p_wind_bus = flh_by_bus(net, wind_present)\n",
    "    wind_polys = aggregate_bus_metric_to_polygons(\n",
    "        gadm_shapes, bus_gdf, flh_wind, weight_bus=p_wind_bus, agg_method=AGG_METHOD\n",
    "    )\n",
    "    plot_polygon_map(wind_polys, f\"Wind full-load hours by region (GADM) â {AGG_METHOD}\")\n",
    "\n",
    "# 3) SOLAR FLH per bus\n",
    "solar_present = [c for c in SOLAR_CARRIERS if c in set(net.generators.carrier.astype(str).unique())]\n",
    "if len(solar_present) == 0:\n",
    "    print(\"No SOLAR carriers found. Available generator carriers:\\n\", net.generators.carrier.unique())\n",
    "else:\n",
    "    flh_solar, p_solar_bus = flh_by_bus(net, solar_present)\n",
    "    solar_polys = aggregate_bus_metric_to_polygons(\n",
    "        gadm_shapes, bus_gdf, flh_solar, weight_bus=p_solar_bus, agg_method=AGG_METHOD\n",
    "    )\n",
    "    plot_polygon_map(solar_polys, f\"Solar full-load hours by region (GADM) â {AGG_METHOD}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8e53f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "solar = xr.open_dataset(solar_path)\n",
    "wind = xr.open_dataset(onwind_path)\n",
    "\n",
    "def plot_voronoi(n, carrier, voronoi, cmap, projection, title=None, filename=None):\n",
    "    g = n.generators.loc[n.generators.carrier == carrier]\n",
    "    br = gpd.read_file(f\"../../../pypsa-earth/resources/UHS/bus_regions/regions_{voronoi}.geojson\").set_index(\"name\")\n",
    "    br_area = br.to_crs(\"ESRI:54009\")\n",
    "    br_area = br_area.geometry.area * 1e-6\n",
    "    br[\"p_nom_max\"] = g.groupby(\"bus\").sum().p_nom_max / br_area\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 4), subplot_kw={\"projection\": projection})\n",
    "    plt.rcParams.update({\"font.size\": 10})\n",
    "    br.plot(\n",
    "        ax=ax,\n",
    "        column=\"p_nom_max\",\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        linewidth=0.25,\n",
    "        edgecolor=\"k\",\n",
    "        cmap=cmap,\n",
    "        vmin=0,\n",
    "        vmax=br[\"p_nom_max\"].max(),\n",
    "        legend=True,\n",
    "        legend_kwds={\"label\": r\"potential density\"},\n",
    "    )\n",
    "    ax.coastlines()\n",
    "    ax.add_feature(cartopy.feature.BORDERS.with_scale(\"110m\"))\n",
    "    ax.set_extent(country_coordinates, crs=ccrs.PlateCarree()) \n",
    "    \n",
    "    if title is not None:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2149e1d8",
   "metadata": {},
   "source": [
    "#### Wind potentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c695b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "logging.getLogger(\"pypsa.io\").setLevel(logging.ERROR)\n",
    "plot_voronoi(\n",
    "    pypsa.Network(network_path),\n",
    "    \"onwind\",\n",
    "    \"onshore\",\n",
    "    \"Blues\",\n",
    "    ccrs.PlateCarree(),\n",
    "    title=\"Onshore Wind Potential Density [MW/km2]\",\n",
    ")\n",
    "warnings.simplefilter(action='default', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dca019c",
   "metadata": {},
   "source": [
    "#### Solar potentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b401c514",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "logging.getLogger(\"pypsa.io\").setLevel(logging.ERROR)\n",
    "plot_voronoi(\n",
    "    pypsa.Network(network_path),\n",
    "    \"solar\",\n",
    "    \"onshore\",\n",
    "    \"OrRd\",\n",
    "    ccrs.PlateCarree(),\n",
    "    title=\"Solar Photovoltaic Potential Density [MW/km2]\",\n",
    ")\n",
    "warnings.simplefilter(action='default', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69bd468",
   "metadata": {},
   "source": [
    "#### Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82993ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _store_energy_capacity(net, idx):\n",
    "    \"\"\"Energy capacity [MWh] using e_nom_opt if available, else e_nom.\"\"\"\n",
    "    st = net.stores.loc[idx]\n",
    "    if \"e_nom_opt\" in st.columns:\n",
    "        return st[\"e_nom_opt\"].fillna(0.0)\n",
    "    return st[\"e_nom\"].fillna(0.0)\n",
    "\n",
    "\n",
    "def _h2_store_ids(net):\n",
    "    \"\"\"All H2-related stores by carrier name containing 'H2'.\"\"\"\n",
    "    if not hasattr(net, \"stores\") or net.stores.empty:\n",
    "        return pd.Index([])\n",
    "    return net.stores.index[net.stores.carrier.astype(str).str.contains(\"H2\", case=False, na=False)]\n",
    "\n",
    "\n",
    "def _uhs_store_ids(net, uhs_carrier=\"H2 UHS\"):\n",
    "    \"\"\"UHS stores (carrier == 'H2 UHS').\"\"\"\n",
    "    if not hasattr(net, \"stores\") or net.stores.empty:\n",
    "        return pd.Index([])\n",
    "    return net.stores.index[net.stores.carrier == uhs_carrier]\n",
    "\n",
    "\n",
    "def h2_storage_capacities_gwh(net, uhs_carrier=\"H2 UHS\"):\n",
    "    \"\"\"\n",
    "    Returns (uhs_gwh, non_uhs_gwh, total_gwh).\n",
    "    \"\"\"\n",
    "    h2_all = _h2_store_ids(net)\n",
    "    uhs_idx = _uhs_store_ids(net, uhs_carrier=uhs_carrier)\n",
    "    non_uhs_idx = h2_all.difference(uhs_idx)\n",
    "\n",
    "    total_mwh = float(_store_energy_capacity(net, h2_all).sum()) if len(h2_all) else 0.0\n",
    "    uhs_mwh   = float(_store_energy_capacity(net, uhs_idx).sum()) if len(uhs_idx) else 0.0\n",
    "    non_mwh   = float(_store_energy_capacity(net, non_uhs_idx).sum()) if len(non_uhs_idx) else 0.0\n",
    "\n",
    "    return uhs_mwh / 1e3, non_mwh / 1e3, total_mwh / 1e3\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Build table for all 8 scenarios\n",
    "# ------------------------------------------------------------\n",
    "scen_list = [\n",
    "    (\"UHS1\",      uhs1),\n",
    "    (\"woUHS1\",    woUHS1),\n",
    "    (\"UHS10\",     uhs10),\n",
    "    (\"woUHS10\",   woUHS10),\n",
    "    (\"UHS24\",     uhswotm),      # 24 nodes = your normal scenario\n",
    "    (\"woUHS24\",   woUHSwotm),\n",
    "    (\"UHS100\",    uhs100),\n",
    "    (\"woUHS100\",  woUHS100),\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for name, net in scen_list:\n",
    "    uhs_gwh, non_uhs_gwh, total_gwh = h2_storage_capacities_gwh(net, uhs_carrier=\"H2 UHS\")\n",
    "    rows.append({\n",
    "        \"Scenario\": name,\n",
    "        \"UHS [GWh]\": uhs_gwh,\n",
    "        \"H2 Store (non-UHS) [GWh]\": non_uhs_gwh,\n",
    "        \"Total H2 Stores [GWh]\": total_gwh,\n",
    "    })\n",
    "\n",
    "cap_df = pd.DataFrame(rows).set_index(\"Scenario\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Plot: stacked bars for UHS + non-UHS, with total overlay line\n",
    "# ------------------------------------------------------------\n",
    "fig, ax = plt.subplots(figsize=(13, 6))\n",
    "\n",
    "x = np.arange(len(cap_df.index))\n",
    "uhs_vals = cap_df[\"UHS [GWh]\"].values\n",
    "non_vals = cap_df[\"H2 Store (non-UHS) [GWh]\"].values\n",
    "tot_vals = cap_df[\"Total H2 Stores [GWh]\"].values\n",
    "\n",
    "# Stacked bars: UHS + non-UHS = total\n",
    "b1 = ax.bar(x, uhs_vals, label=\"UHS (H2 UHS)\")\n",
    "b2 = ax.bar(x, non_vals, bottom=uhs_vals, label=\"H2 Stores (non-UHS)\")\n",
    "\n",
    "# Total line (same as top of stack; helps readability)\n",
    "ax.plot(x, tot_vals, linewidth=2.0, label=\"Total H2 Stores\")\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(cap_df.index.tolist(), rotation=20, ha=\"right\")\n",
    "ax.set_ylabel(\"Energy capacity [GWh]\")\n",
    "ax.set_title(\"Hydrogen storage energy capacities across scenarios (2050)\")\n",
    "ax.grid(True, axis=\"y\", alpha=0.25)\n",
    "\n",
    "# Legend below plot (single legend)\n",
    "ax.legend(\n",
    "    loc=\"upper center\",\n",
    "    bbox_to_anchor=(0.5, -0.18),\n",
    "    ncol=3,\n",
    "    frameon=True\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(bottom=0.24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d495c942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ensure_dt_index(x):\n",
    "    if not isinstance(x.index, pd.DatetimeIndex):\n",
    "        x = x.copy()\n",
    "        x.index = pd.to_datetime(x.index)\n",
    "    return x\n",
    "\n",
    "\n",
    "def _h2_buses(net) -> pd.Index:\n",
    "    \"\"\"Project convention: hydrogen buses are those with carrier == 'H2'.\"\"\"\n",
    "    return net.buses.index[net.buses.carrier == \"H2\"]\n",
    "\n",
    "\n",
    "def _h2_store_ids(net) -> pd.Index:\n",
    "    \"\"\"All H2-related stores by store carrier name (includes H2 UHS and H2 tanks).\"\"\"\n",
    "    if not hasattr(net, \"stores\") or net.stores.empty:\n",
    "        return pd.Index([])\n",
    "    return net.stores.index[net.stores.carrier.astype(str).str.contains(\"H2\", case=False, na=False)]\n",
    "\n",
    "\n",
    "def _link_net_injection_to_h2(net, link_idx: pd.Index) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Net injection into H2 buses from a given subset of links [MW].\n",
    "    Positive => net injection into H2 buses. Negative => net withdrawal from H2 buses.\n",
    "    Uses: injection at a bus is approximately -p_k for that port.\n",
    "    \"\"\"\n",
    "    h2 = _h2_buses(net)\n",
    "    s = pd.Series(0.0, index=net.snapshots)\n",
    "\n",
    "    present = net.links.index.intersection(link_idx)\n",
    "    if len(present) == 0:\n",
    "        return _ensure_dt_index(s)\n",
    "\n",
    "    for k in range(5):\n",
    "        bus_col = f\"bus{k}\"\n",
    "        p_col = f\"p{k}\"\n",
    "        if bus_col in net.links.columns and hasattr(net.links_t, p_col):\n",
    "            mask = net.links.loc[present, bus_col].isin(h2)\n",
    "            if mask.any():\n",
    "                idx = present[mask.values]\n",
    "                pk = getattr(net.links_t, p_col)[idx]  # snapshots x links\n",
    "                inj = (-pk).sum(axis=1)               # injection into H2 buses from these ports\n",
    "                s = s.add(inj, fill_value=0.0)\n",
    "\n",
    "    return _ensure_dt_index(s)\n",
    "\n",
    "\n",
    "def _is_h2_bus(net, buses: pd.Series) -> pd.Series:\n",
    "    h2 = set(_h2_buses(net))\n",
    "    return buses.isin(h2)\n",
    "\n",
    "\n",
    "def _final_h2_offtake_links(net, production_carriers, pipeline_carriers) -> pd.Index:\n",
    "    \"\"\"\n",
    "    Links that represent *final* offtake from the H2 system:\n",
    "    - touches at least one H2 bus\n",
    "    - touches at least one non-H2 bus (crosses boundary)\n",
    "    - excludes production carriers and pipeline carriers\n",
    "    \"\"\"\n",
    "    links = net.links.copy()\n",
    "\n",
    "    touches_h2 = pd.Series(False, index=links.index)\n",
    "    touches_non_h2 = pd.Series(False, index=links.index)\n",
    "\n",
    "    for k in range(5):\n",
    "        bus_col = f\"bus{k}\"\n",
    "        if bus_col in links.columns:\n",
    "            b = links[bus_col]\n",
    "            m_h2 = _is_h2_bus(net, b)\n",
    "            touches_h2 |= m_h2\n",
    "            touches_non_h2 |= (~m_h2) & b.notna()\n",
    "\n",
    "    crosses_boundary = touches_h2 & touches_non_h2\n",
    "    is_prod = links.carrier.isin(production_carriers)\n",
    "    is_pipe = links.carrier.isin(pipeline_carriers)\n",
    "\n",
    "    return links.index[crosses_boundary & (~is_prod) & (~is_pipe)]\n",
    "\n",
    "\n",
    "def _production_links(net, production_carriers) -> pd.Index:\n",
    "    \"\"\"Links that are considered primary H2 producers.\"\"\"\n",
    "    return net.links.index[net.links.carrier.isin(production_carriers)]\n",
    "\n",
    "\n",
    "def _h2_store_power(net) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Total H2-store power [MW]:\n",
    "      + = discharge (injection to H2)\n",
    "      - = charge (withdrawal from H2)\n",
    "    \"\"\"\n",
    "    sids = _h2_store_ids(net)\n",
    "    if len(sids) == 0:\n",
    "        return _ensure_dt_index(pd.Series(0.0, index=net.snapshots))\n",
    "\n",
    "    if not hasattr(net, \"stores_t\") or not hasattr(net.stores_t, \"p\"):\n",
    "        raise ValueError(\"net.stores_t.p not found â store power time series missing.\")\n",
    "\n",
    "    s = net.stores_t.p[sids].sum(axis=1)\n",
    "    return _ensure_dt_index(s)\n",
    "\n",
    "\n",
    "def _h2_store_energy(net) -> pd.Series:\n",
    "    \"\"\"Total H2-store energy level [MWh].\"\"\"\n",
    "    sids = _h2_store_ids(net)\n",
    "    if len(sids) == 0:\n",
    "        return _ensure_dt_index(pd.Series(0.0, index=net.snapshots))\n",
    "\n",
    "    if not hasattr(net, \"stores_t\") or not hasattr(net.stores_t, \"e\"):\n",
    "        raise ValueError(\"net.stores_t.e not found â store energy time series missing.\")\n",
    "\n",
    "    s = net.stores_t.e[sids].sum(axis=1)\n",
    "    return _ensure_dt_index(s)\n",
    "\n",
    "\n",
    "def _plotA_signals(\n",
    "    net,\n",
    "    production_carriers=(\"H2 Electrolysis\", \"SMR\", \"SMR CC\"),\n",
    "    pipeline_carriers=(\"H2 pipeline\", \"H2 pipeline repurposed\")\n",
    "):\n",
    "    \"\"\"\n",
    "    Supply   = primary H2 production into H2 buses (from selected production carriers)\n",
    "    Demand   = final H2 offtake crossing boundary (computed but not plotted by default)\n",
    "    Storage  = store charge/discharge from stores_t.p\n",
    "    Level    = store inventory from stores_t.e\n",
    "    \"\"\"\n",
    "    prod_idx = _production_links(net, production_carriers)\n",
    "    off_idx  = _final_h2_offtake_links(net, production_carriers, pipeline_carriers)\n",
    "\n",
    "    net_inj_prod = _link_net_injection_to_h2(net, prod_idx)   # MW\n",
    "    net_inj_off  = _link_net_injection_to_h2(net, off_idx)    # MW (expected negative for offtake)\n",
    "\n",
    "    supply = net_inj_prod.clip(lower=0.0)\n",
    "    demand = (-net_inj_off).clip(lower=0.0)\n",
    "\n",
    "    store_p = _h2_store_power(net)\n",
    "    store_e = _h2_store_energy(net)\n",
    "\n",
    "    return dict(\n",
    "        supply=supply,                                  # MW\n",
    "        demand=demand,                                  # MW\n",
    "        storage_discharge=store_p.clip(lower=0.0),       # MW\n",
    "        storage_charge=(-store_p).clip(lower=0.0),       # MW\n",
    "        storage_level=store_e                            # MWh\n",
    "    )\n",
    "\n",
    "\n",
    "def _slice_signals(sig: dict, start=None, end=None) -> dict:\n",
    "    idx = sig[\"supply\"].index\n",
    "    if start is None:\n",
    "        start = idx.min()\n",
    "    else:\n",
    "        start = pd.to_datetime(start)\n",
    "    if end is None:\n",
    "        end = idx.max()\n",
    "    else:\n",
    "        end = pd.to_datetime(end)\n",
    "\n",
    "    return {k: v.loc[start:end] for k, v in sig.items()}, start, end\n",
    "\n",
    "\n",
    "def plot_A_temporal_matching_sensitivity(\n",
    "    uhs_tm, wo_tm, uhs_no_tm, wo_no_tm,\n",
    "    start=None, end=None,\n",
    "    production_carriers=(\"H2 Electrolysis\", \"SMR\", \"SMR CC\"),\n",
    "    pipeline_carriers=(\"H2 pipeline\", \"H2 pipeline repurposed\")\n",
    "):\n",
    "    \"\"\"\n",
    "    One figure comparing temporal matching ON vs OFF, for UHS vs woUHS.\n",
    "    \"\"\"\n",
    "    # Build signals\n",
    "    sigs = {\n",
    "        \"TM on â UHS\": _plotA_signals(uhs_tm, production_carriers, pipeline_carriers),\n",
    "        \"TM on â woUHS\": _plotA_signals(wo_tm, production_carriers, pipeline_carriers),\n",
    "        \"TM off â UHS\": _plotA_signals(uhs_no_tm, production_carriers, pipeline_carriers),\n",
    "        \"TM off â woUHS\": _plotA_signals(wo_no_tm, production_carriers, pipeline_carriers),\n",
    "    }\n",
    "\n",
    "    # Align common time index across all four\n",
    "    common = None\n",
    "    for s in sigs.values():\n",
    "        common = s[\"supply\"].index if common is None else common.intersection(s[\"supply\"].index)\n",
    "    for name in sigs:\n",
    "        for k in sigs[name]:\n",
    "            sigs[name][k] = sigs[name][k].loc[common]\n",
    "\n",
    "    # Slice once (shared window)\n",
    "    any_sig = next(iter(sigs.values()))\n",
    "    sliced_any, s, e = _slice_signals(any_sig, start=start, end=end)\n",
    "    for name in sigs:\n",
    "        sigs[name], _, _ = _slice_signals(sigs[name], start=s, end=e)\n",
    "\n",
    "    # Figure: 2 rows x 4 columns\n",
    "    titles = list(sigs.keys())\n",
    "    fig, axes = plt.subplots(\n",
    "        2, 4, figsize=(22, 7.8),\n",
    "        sharex=True,\n",
    "        gridspec_kw={\"height_ratios\": [1.15, 1.0]}\n",
    "    )\n",
    "\n",
    "    # Row 1: flows\n",
    "    for j, title in enumerate(titles):\n",
    "        ax = axes[0, j]\n",
    "        sig = sigs[title]\n",
    "\n",
    "        ax.plot(sig[\"supply\"].index, sig[\"supply\"].values, linewidth=1.7,\n",
    "                label=\"H2 supply (primary production into H2 buses)\")\n",
    "        ax.fill_between(sig[\"storage_discharge\"].index, 0, sig[\"storage_discharge\"].values,\n",
    "                        alpha=0.12, label=\"Storage discharge (+)\")\n",
    "        ax.fill_between(sig[\"storage_charge\"].index, 0, sig[\"storage_charge\"].values,\n",
    "                        alpha=0.12, label=\"Storage charge (-)\")\n",
    "\n",
    "        ax.set_title(title)\n",
    "        ax.set_ylabel(\"Power [MW$_{H2}$]\" if j == 0 else \"\")\n",
    "        ax.grid(True, alpha=0.25)\n",
    "\n",
    "    # Row 2: inventory\n",
    "    for j, title in enumerate(titles):\n",
    "        ax = axes[1, j]\n",
    "        sig = sigs[title]\n",
    "\n",
    "        ax.plot(sig[\"storage_level\"].index, sig[\"storage_level\"].values, linewidth=1.7,\n",
    "                label=\"Total H2 store level\")\n",
    "\n",
    "        ax.set_title(\"Inventory\")\n",
    "        ax.set_ylabel(\"Energy [MWh$_{H2}$]\" if j == 0 else \"\")\n",
    "        ax.grid(True, alpha=0.25)\n",
    "\n",
    "        # Month-day formatting without year\n",
    "        ax.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%b-%d\"))\n",
    "        ax.set_xlabel(\"Time\")\n",
    "\n",
    "    # Shared legend below figure (unique labels)\n",
    "    handles, labels = [], []\n",
    "    for ax in [axes[0, 0], axes[1, 0]]:\n",
    "        h, l = ax.get_legend_handles_labels()\n",
    "        for hh, ll in zip(h, l):\n",
    "            if ll not in labels:\n",
    "                handles.append(hh)\n",
    "                labels.append(ll)\n",
    "\n",
    "    fig.legend(\n",
    "        handles, labels,\n",
    "        loc=\"upper center\",\n",
    "        bbox_to_anchor=(0.5, -0.02),\n",
    "        ncol=3,\n",
    "        frameon=True\n",
    "    )\n",
    "\n",
    "    fig.suptitle(\"Hydrogen supplyâstorage dynamics: temporal matching ON vs OFF\", y=0.98)\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(bottom=0.16)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Run (EXACT variable names you stated)\n",
    "# temporal matching ON  : uhs, woUHS\n",
    "# temporal matching OFF : uhswotm, woUHSwotm\n",
    "# ============================================================\n",
    "\n",
    "plot_A_temporal_matching_sensitivity(\n",
    "    uhs_tm=uhs,\n",
    "    wo_tm=woUHS,\n",
    "    uhs_no_tm=uhswotm,\n",
    "    wo_no_tm=woUHSwotm,\n",
    "    start=\"2013-01-01\",\n",
    "    end=\"2013-01-15\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pypsa-earth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
